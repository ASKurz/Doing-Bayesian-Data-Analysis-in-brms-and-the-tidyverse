
@article{aczelDiscussionPointsBayesian2020,
  title = {Discussion Points for {{Bayesian}} Inference},
  author = {Aczel, Balazs and Hoekstra, Rink and Gelman, Andrew and Wagenmakers, Eric-Jan and Klugkist, Irene G. and Rouder, Jeffrey N. and Vandekerckhove, Joachim and Lee, Michael D. and Morey, Richard D. and Vanpaemel, Wolf and Dienes, Zoltan and {van Ravenzwaaij}, Don},
  year = {2020},
  month = jan,
  journal = {Nature Human Behaviour},
  pages = {1--3},
  publisher = {{Nature Publishing Group}},
  issn = {2397-3374},
  doi = {10.1038/s41562-019-0807-z},
  url = {https://www.researchgate.net/publication/338849264_Discussion_points_for_Bayesian_inference},
  urldate = {2020-05-18},
  abstract = {Why is there no consensual way of conducting Bayesian analyses? We present a summary of agreements and disagreements of the authors on several discussion points regarding Bayesian inference. We also provide a thinking guideline to assist researchers in conducting Bayesian inference in the social and behavioural sciences.},
  copyright = {2020 Springer Nature Limited},
  langid = {english},
  file = {/Users/solomonkurz/Zotero/storage/LPH5KWXL/s41562-019-0807-z.html}
}

@book{agrestiFoundationsLinearGeneralized2015,
  title = {Foundations of Linear and Generalized Linear Models},
  author = {Agresti, Alan},
  year = {2015},
  month = jan,
  publisher = {{John Wiley \& Sons}},
  url = {https://www.wiley.com/en-us/Foundations+of+Linear+and+Generalized+Linear+Models-p-9781118730034},
  abstract = {A valuable overview of the most important ideas and results in statistical modeling Written by a highly-experienced author, Foundations of Linear and Generalized Linear Models is a clear and comprehensive guide to the key concepts and results of linearstatistical models. The book presents a broad, in-depth overview of the most commonly usedstatistical models by discussing the theory underlying the models, R software applications,and examples with crafted models to elucidate key ideas and promote practical modelbuilding. The book begins by illustrating the fundamentals of linear models, such as how the model-fitting projects the data onto a model vector subspace and how orthogonal decompositions of the data yield information about the effects of explanatory variables. Subsequently, the book covers the most popular generalized linear models, which include binomial and multinomial logistic regression for categorical data, and Poisson and negative binomial loglinear models for count data. Focusing on the theoretical underpinnings of these models, Foundations ofLinear and Generalized Linear Models also features:  An introduction to quasi-likelihood methods that require weaker distributional assumptions, such as generalized estimating equation methods An overview of linear mixed models and generalized linear mixed models with random effects for clustered correlated data, Bayesian modeling, and extensions to handle problematic cases such as high dimensional problems Numerous examples that use R software for all text data analyses More than 400 exercises for readers to practice and extend the theory, methods, and data analysis A supplementary website with datasets for the examples and exercises  An invaluable textbook for upper-undergraduate and graduate-level students in statistics and biostatistics courses, Foundations of Linear and Generalized Linear Models is also an excellent reference for practicing statisticians and biostatisticians, as well as anyone who is interested in learning about the most important statistical models for analyzing data.},
  googlebooks = {dgIzBgAAQBAJ},
  isbn = {978-1-118-73005-8},
  langid = {english},
  keywords = {Mathematics / Probability \& Statistics / General,Mathematics / Probability \& Statistics / Stochastic Processes}
}

@article{atkinsTutorialOnCount2013,
  title = {A Tutorial on Count Regression and Zero-Altered Count Models for Longitudinal Substance Use Data.},
  author = {Atkins, David C and Baldwin, Scott A and Zheng, Cheng and Gallop, Robert J and Neighbors, Clayton},
  year = {2013},
  journal = {Psychology of Addictive Behaviors},
  volume = {27},
  number = {1},
  pages = {166},
  publisher = {{American Psychological Association}},
  doi = {10.1037/a0029508},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3513584/pdf/nihms396181.pdf}
}

@article{batesFittingLinearMixedeffects2015,
  title = {Fitting Linear Mixed-Effects Models Using Lme4},
  author = {Bates, Douglas and M{\"a}chler, Martin and Bolker, Ben and Walker, Steve},
  year = {2015},
  journal = {Journal of Statistical Software},
  volume = {67},
  number = {1},
  pages = {1--48},
  doi = {10.18637/jss.v067.i01}
}

@article{bayesLIIEssaySolving1763,
  title = {{{LII}}. {{An}} Essay towards Solving a Problem in the Doctrine of Chances. {{By}} the Late {{Rev}}. {{Mr}}. {{Bayes}}, {{FRS}} Communicated by {{Mr}}. {{Price}}, in a Letter to {{John Canton}}, {{AMFR S}}},
  author = {Bayes, Thomas},
  year = {1763},
  journal = {Philosophical transactions of the Royal Society of London},
  number = {53},
  pages = {370--418},
  publisher = {{The Royal Society London}},
  url = {https://royalsocietypublishing.org/doi/pdf/10.1098/rstl.1763.0053},
  file = {/Users/solomonkurz/Zotero/storage/EMMHAP35/Bayes - 1763 - LII. An essay towards solving a problem in the doc.pdf;/Users/solomonkurz/Zotero/storage/JISQSW2F/rstl.1763.html}
}

@misc{BibTeX2020,
  title = {{{BibTeX}}},
  year = {2020},
  url = {http://www.bibtex.org/},
  urldate = {2020-05-19},
  file = {/Users/solomonkurz/Zotero/storage/PMDJYC3M/www.bibtex.org.html}
}

@article{bliss1934method,
  title = {The Method of Probits.},
  author = {Bliss, Chester I},
  year = {1934},
  journal = {Science},
  publisher = {{American Assn for the Advancement of Science}},
  doi = {10.1126/science.79.2037.38},
  url = {https://science.sciencemag.org/content/79/2037/38}
}

@article{bolgerCausalProcessesPsychology2019,
  title = {Causal Processes in Psychology Are Heterogeneous},
  author = {Bolger, Niall and Zee, Katherine S. and {Rossignac-Milon}, Maya and Hassin, Ran R.},
  year = {2019},
  journal = {Journal of Experimental Psychology: General},
  volume = {148},
  number = {4},
  pages = {601--618},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-2222(Electronic),0096-3445(Print)},
  doi = {10.1037/xge0000558},
  url = {https://www.researchgate.net/profile/Niall_Bolger/publication/332358948_Causal_processes_in_psychology_are_heterogeneous/links/5cd9b471a6fdccc9ddaa7879/Causal-processes-in-psychology-are-heterogeneous.pdf},
  abstract = {All experimenters know that human and animal subjects do not respond uniformly to experimental treatments. Yet theories and findings in experimental psychology either ignore this causal effect heterogeneity or treat it as uninteresting error. This is the case even when data are available to examine effect heterogeneity directly, in within-subjects designs where experimental effects can be examined subject by subject. Using data from four repeated-measures experiments, we show that effect heterogeneity can be modeled readily, that its discovery presents exciting opportunities for theory and methods, and that allowing for it in study designs is good research practice. This evidence suggests that experimenters should work from the assumption that causal effects are heterogeneous. Such a working assumption will be of particular benefit, given the increasing diversity of subject populations in psychology. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
  keywords = {Experimental Methods,Experimental Psychology,Experimenters,Homogeneity of Variance,Models,Repeated Measures,Theory Formulation},
  file = {/Users/solomonkurz/Zotero/storage/CAWSDRIT/2019-19962-002.html}
}

@article{braumoellerHypothesisTestingMultiplicative2004,
  title = {Hypothesis Testing and Multiplicative Interaction Terms},
  author = {Braumoeller, Bear F.},
  year = {2004},
  month = oct,
  journal = {International Organization},
  volume = {58},
  number = {4},
  pages = {807--820},
  publisher = {{Cambridge University Press}},
  issn = {1531-5088, 0020-8183},
  doi = {10.1017/S0020818304040251},
  url = {https://www.cambridge.org/core/journals/international-organization/article/hypothesis-testing-and-multiplicative-interaction-terms/5AE39EABAA8F26582C65F0D3FAD153D8},
  urldate = {2020-05-16},
  abstract = {When a statistical equation incorporates a multiplicative term in an attempt to model interaction effects, the statistical significance of the lower-order coefficients is largely useless for the typical purposes of hypothesis testing. This fact remains largely unappreciated in political science, however. This brief article explains this point, provides examples, and offers some suggestions for more meaningful interpretation.I am grateful to Tim McDaniel, Anne Sartori, and Beth Simmons for comments on a previous draft.},
  langid = {english},
  file = {/Users/solomonkurz/Zotero/storage/BPTHF27L/Braumoeller - 2004 - Hypothesis Testing and Multiplicative Interaction .pdf;/Users/solomonkurz/Zotero/storage/FZWUA73C/5AE39EABAA8F26582C65F0D3FAD153D8.html}
}

@book{brms2021RM,
  title = {{{brms}} Reference Manual, {{Version}} 2.15.0},
  author = {B{\"u}rkner, Paul-Christian},
  year = {2021},
  url = {https://CRAN.R-project.org/package=brms/brms.pdf}
}

@book{bryanHappyGitGitHub2020,
  title = {Happy {{Git}} and {{GitHub}} for the {{useR}}},
  author = {Bryan, Jenny and {the STAT 545 TAs} and Hester, Jim},
  year = {2020},
  url = {https://happygitwithr.com}
}

@article{Bürkner2021Define,
  title = {Define Custom Response Distributions with Brms},
  author = {B{\"u}rkner, Paul-Christian},
  year = {2021},
  month = mar,
  url = {https://CRAN.R-project.org/package=brms/vignettes/brms_customfamilies.html}
}

@article{Bürkner2021Distributional,
  title = {Estimating Distributional Models with Brms},
  author = {B{\"u}rkner, Paul-Christian},
  year = {2021},
  month = mar,
  url = {https://CRAN.R-project.org/package=brms/vignettes/brms_distreg.html}
}

@article{Bürkner2021Multivariate,
  title = {Estimating Multivariate Models with Brms},
  author = {B{\"u}rkner, Paul-Christian},
  year = {2021},
  month = mar,
  url = {https://CRAN.R-project.org/package=brms/vignettes/brms_multivariate.html}
}

@article{Bürkner2021Non_linear,
  title = {Estimating Non-Linear Models with Brms},
  author = {B{\"u}rkner, Paul-Christian},
  year = {2021},
  month = mar,
  url = {https://CRAN.R-project.org/package=brms/vignettes/brms_nonlinear.html}
}

@article{Bürkner2021Parameterization,
  title = {Parameterization of Response Distributions in Brms},
  author = {B{\"u}rkner, Paul-Christian},
  year = {2021},
  month = mar,
  url = {https://CRAN.R-project.org/package=brms/vignettes/brms_families.html}
}

@article{burknerAdvancedBayesianMultilevel2018,
  title = {Advanced {{Bayesian}} Multilevel Modeling with the {{R}} Package Brms},
  author = {B{\"u}rkner, Paul-Christian},
  year = {2018},
  journal = {The R Journal},
  volume = {10},
  number = {1},
  pages = {395--411},
  doi = {10.32614/RJ-2018-017}
}

@article{burknerBayesianItemResponse2020,
  title = {Bayesian Item Response Modeling in {{R}} with Brms and {{Stan}}},
  author = {B{\"u}rkner, Paul-Christian},
  year = {2020},
  month = feb,
  journal = {arXiv:1905.09501 [stat]},
  eprint = {1905.09501},
  eprinttype = {arxiv},
  primaryclass = {stat},
  url = {http://arxiv.org/abs/1905.09501},
  urldate = {2020-05-18},
  abstract = {Item Response Theory (IRT) is widely applied in the human sciences to model persons' responses on a set of items measuring one or more latent constructs. While several R packages have been developed that implement IRT models, they tend to be restricted to respective prespecified classes of models. Further, most implementations are frequentist while the availability of Bayesian methods remains comparably limited. We demonstrate how to use the R package brms together with the probabilistic programming language Stan to specify and fit a wide range of Bayesian IRT models using flexible and intuitive multilevel formula syntax. Further, item and person parameters can be related in both a linear or non-linear manner. Various distributions for categorical, ordinal, and continuous responses are supported. Users may even define their own custom response distribution for use in the presented framework. Common IRT model classes that can be specified natively in the presented framework include 1PL and 2PL logistic models optionally also containing guessing parameters, graded response and partial credit ordinal models, as well as drift diffusion models of response times coupled with binary decisions. Posterior distributions of item and person parameters can be conveniently extracted and post-processed. Model fit can be evaluated and compared using Bayes factors and efficient cross-validation procedures.},
  archiveprefix = {arXiv},
  keywords = {Statistics - Computation},
  file = {/Users/solomonkurz/Zotero/storage/T5WVXMPA/Bürkner - 2020 - Bayesian Item Response Modeling in R with brms and.pdf;/Users/solomonkurz/Zotero/storage/KYB42QN2/1905.html}
}

@article{burknerBrmsPackageBayesian2017,
  title = {{{brms}}: {{An R}} Package for {{Bayesian}} Multilevel Models Using {{Stan}}},
  author = {B{\"u}rkner, Paul-Christian},
  year = {2017},
  journal = {Journal of Statistical Software},
  volume = {80},
  number = {1},
  pages = {1--28},
  doi = {10.18637/jss.v080.i01}
}

@article{burknerOrdinalRegressionModels2019,
  title = {Ordinal Regression Models in Psychology: {{A}} Tutorial},
  shorttitle = {Ordinal {{Regression Models}} in {{Psychology}}},
  author = {B{\"u}rkner, Paul-Christian and Vuorre, Matti},
  year = {2019},
  month = mar,
  journal = {Advances in Methods and Practices in Psychological Science},
  volume = {2},
  number = {1},
  pages = {77--101},
  publisher = {{SAGE Publications Inc}},
  issn = {2515-2459},
  doi = {10.1177/2515245918823199},
  url = {https://doi.org/10.1177/2515245918823199},
  urldate = {2020-05-18},
  abstract = {Ordinal variables, although extremely common in psychology, are almost exclusively analyzed with statistical models that falsely assume them to be metric. This practice can lead to distorted effect-size estimates, inflated error rates, and other problems. We argue for the application of ordinal models that make appropriate assumptions about the variables under study. In this Tutorial, we first explain the three major classes of ordinal models: the cumulative, sequential, and adjacent-category models. We then show how to fit ordinal models in a fully Bayesian framework with the R package brms, using data sets on opinions about stem-cell research and time courses of marriage. The appendices provide detailed mathematical derivations of the models and a discussion of censored ordinal models. Compared with metric models, ordinal models provide better theoretical interpretation and numerical inference from ordinal data, and we recommend their widespread adoption in psychology.},
  langid = {english}
}

@article{campbell2021re,
  title = {Re: {{Linde}} et al.(2021)\textendash{{The Bayes}} Factor, {{HDI-ROPE}} and Frequentist Equivalence Testing Are Actually All Equivalent},
  author = {Campbell, Harlan and Gustafson, Paul},
  year = {2021},
  journal = {arXiv preprint arXiv:2104.07834},
  eprint = {2104.07834},
  eprinttype = {arxiv},
  url = {https://arxiv.org/abs/2104.07834},
  archiveprefix = {arXiv}
}

@article{carifio2007ten,
  title = {Ten Common Misunderstandings, Misconceptions, Persistent Myths and Urban Legends about {{Likert}} Scales and {{Likert}} Response Formats and Their Antidotes},
  author = {Carifio, James and Perla, Rocco J},
  year = {2007},
  journal = {Journal of Social Sciences},
  volume = {3},
  number = {3},
  pages = {106--116},
  url = {https://thescipub.com/pdf/10.3844/jssp.2007.106.116.pdf}
}

@article{carifioResolving50yearDebate2008,
  title = {Resolving the 50-Year Debate around Using and Misusing {{Likert}} Scales},
  author = {Carifio, James and Perla, Rocco},
  year = {2008},
  journal = {Medical Education},
  volume = {42},
  number = {12},
  pages = {1150--1152},
  issn = {1365-2923},
  doi = {10.1111/j.1365-2923.2008.03172.x},
  url = {Resolving the 50-year debate around using and misusing Likert scales},
  urldate = {2020-05-18},
  copyright = {\textcopyright{} Blackwell Publishing Ltd 2008},
  langid = {english},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1365-2923.2008.03172.x},
  file = {/Users/solomonkurz/Zotero/storage/L3VGQJRR/j.1365-2923.2008.03172.html}
}

@article{carpenterStanProbabilisticProgramming2017,
  title = {Stan: {{A}} Probabilistic Programming Language},
  author = {Carpenter, Bob and Gelman, Andrew and Hoffman, Matthew D and Lee, Daniel and Goodrich, Ben and Betancourt, Michael and Brubaker, Marcus and Guo, Jiqiang and Li, Peter and Riddell, Allen},
  year = {2017},
  journal = {Journal of statistical software},
  volume = {76},
  number = {1},
  publisher = {{Columbia Univ., New York, NY (United States); Harvard Univ., Cambridge, MA \ldots}},
  doi = {10.18637/jss.v076.i01},
  url = {https://www.osti.gov/servlets/purl/1430202}
}

@inproceedings{carvalho2009handling,
  title = {Handling Sparsity via the Horseshoe},
  booktitle = {Artificial Intelligence and Statistics},
  author = {Carvalho, Carlos M and Polson, Nicholas G and Scott, James G},
  year = {2009},
  pages = {73--80},
  url = {http://proceedings.mlr.press/v5/carvalho09a/carvalho09a.pdf}
}

@article{casellaExplainingGibbsSampler1992,
  title = {Explaining the {{Gibbs}} Sampler},
  author = {Casella, George and George, Edward I.},
  year = {1992},
  month = aug,
  journal = {The American Statistician},
  volume = {46},
  number = {3},
  pages = {167--174},
  publisher = {{Taylor \& Francis}},
  issn = {0003-1305},
  doi = {10.1080/00031305.1992.10475878},
  url = {https://ecommons.cornell.edu/bitstream/handle/1813/31670/BU-1098-MA.Revised.pdf?sequence=1},
  urldate = {2020-06-11},
  abstract = {Computer-intensive algorithms, such as the Gibbs sampler, have become increasingly popular statistical tools, both in applied and theoretical work. The properties of such algorithms, however, may sometimes not be obvious. Here we give a simple explanation of how and why the Gibbs sampler works. We analytically establish its properties in a simple case and provide insight for more complicated cases. There are also a number of examples.},
  keywords = {Data augmentation,Markov chains,Monte Carlo methods,Resampling techniques},
  annotation = {\_eprint: https://www.tandfonline.com/doi/pdf/10.1080/00031305.1992.10475878},
  file = {/Users/solomonkurz/Zotero/storage/7G3SEDKK/Casella and George - 1992 - Explaining the Gibbs Sampler.pdf;/Users/solomonkurz/Zotero/storage/SFZUD4XZ/00031305.1992.html}
}

@article{chandramouliCommentaryGronauWagenmakers2019,
  title = {Commentary on {{Gronau}} and {{Wagenmakers}}},
  author = {Chandramouli, Suyog H and Shiffrin, Richard M},
  year = {2019},
  journal = {Computational Brain \& Behavior},
  volume = {2},
  number = {1},
  pages = {12--21},
  publisher = {{Springer}},
  url = {https://doi.org/10.1007/s42113-018-0017-1}
}

@article{chenMonteCarloEstimation1999,
  title = {Monte {{Carlo}} Estimation of {{Bayesian}} Credible and {{HPD}} Intervals},
  author = {Chen, Ming-Hui and Shao, Qi-Man},
  year = {1999},
  month = mar,
  journal = {Journal of Computational and Graphical Statistics},
  volume = {8},
  number = {1},
  pages = {69--92},
  publisher = {{Taylor \& Francis}},
  issn = {1061-8600},
  doi = {10.1080/10618600.1999.10474802},
  url = {https://www.researchgate.net/publication/2442323_Monte_Carlo_Estimation_of_Bayesian_Credible_and_HPD_Intervals},
  urldate = {2020-05-18},
  abstract = {This article considers how to estimate Bayesian credible and highest probability density (HPD) intervals for parameters of interest and provides a simple Monte Carlo approach to approximate these Bayesian intervals when a sample of the relevant parameters can be generated from their respective marginal posterior distribution using a Markov chain Monte Carlo (MCMC) sampling algorithm. We also develop a Monte Carlo method to compute HPD intervals for the parameters of interest from the desired posterior distribution using a sample from an importance sampling distribution. We apply our methodology to a Bayesian hierarchical model that has a posterior density containing analytically intractable integrals that depend on the (hyper) parameters. We further show that our methods are useful not only for calculating the HPD intervals for the parameters of interest but also for computing the HPD intervals for functions of the parameters. Necessary theory is developed and illustrative examples\textemdash including a simulation study\textemdash are given.},
  file = {/Users/solomonkurz/Zotero/storage/A37BJW48/10618600.1999.html}
}

@incollection{chenMonteCarloGap2003,
  title = {A {{Monte Carlo}} Gap Test in Computing {{HPD}} Regions},
  booktitle = {Development of {{Modern Statistics}} and {{Related Topics}}},
  author = {Chen, Ming-Hui and He, Xuming and Shao, Qi-Man and Xu, Hai},
  year = {2003},
  month = jun,
  series = {Series in {{Biostatistics}}},
  volume = {Volume 1},
  pages = {38--52},
  publisher = {{World Scientific}},
  doi = {10.1142/9789812796707_0004},
  url = {https://www.researchgate.net/publication/264969946_A_Monte_Carlo_gap_test_in_computing_HPD_regions},
  urldate = {2020-05-18},
  isbn = {978-981-238-395-2},
  file = {/Users/solomonkurz/Zotero/storage/ZSZ4HUD3/9789812796707_0004.html}
}

@article{chungNondegeneratePenalizedLikelihood2013,
  title = {A Nondegenerate Penalized Likelihood Estimator for Variance Parameters in Multilevel Models},
  author = {Chung, Yeojin and {Rabe-Hesketh}, Sophia and Dorie, Vincent and Gelman, Andrew and Liu, Jingchen},
  year = {2013},
  month = oct,
  journal = {Psychometrika},
  volume = {78},
  number = {4},
  pages = {685--709},
  issn = {0033-3123, 1860-0980},
  doi = {10.1007/s11336-013-9328-2},
  url = {http://link.springer.com/10.1007/s11336-013-9328-2},
  urldate = {2020-05-17},
  langid = {english}
}

@book{cohenStatisticalPowerAnalysis1988,
  title = {Statistical Power Analysis for the Behavioral Sciences},
  author = {Cohen, Jacob},
  year = {1988},
  edition = {2nd Edition},
  publisher = {{Routledge}},
  doi = {10.4324/9780203771587},
  url = {https://www.taylorfrancis.com/books/9780203771587},
  urldate = {2020-05-16},
  isbn = {978-0-203-77158-7},
  langid = {english},
  file = {/Users/solomonkurz/Zotero/storage/P6QDI9KH/Cohen - 2013 - Statistical Power Analysis for the Behavioral Scie.pdf;/Users/solomonkurz/Zotero/storage/CCGXJI5G/9780203771587.html}
}

@book{cummingUnderstandingTheNewStatistics2012,
  title = {Understanding the New Statistics: {{Effect}} Sizes, Confidence Intervals, and Meta-Analysis},
  author = {Cumming, Geoff},
  year = {2012},
  publisher = {{Routledge}},
  url = {https://www.routledge.com/Understanding-The-New-Statistics-Effect-Sizes-Confidence-Intervals-and/Cumming/p/book/9780415879682},
  isbn = {978-0-415-87967-5}
}

@book{daleHistoryInverseProbability2012,
  title = {A History of Inverse Probability: {{From Thomas Bayes}} to {{Karl Pearson}}},
  author = {Dale, Andrew I},
  year = {2012},
  publisher = {{Springer Science \& Business Media}},
  url = {https://www.springer.com/gp/book/9780387988078}
}

@article{duaneHybridMonteCarlo1987,
  title = {Hybrid {{Monte Carlo}}},
  author = {Duane, Simon and Kennedy, A. D. and Pendleton, Brian J. and Roweth, Duncan},
  year = {1987},
  month = sep,
  journal = {Physics Letters B},
  volume = {195},
  number = {2},
  pages = {216--222},
  issn = {0370-2693},
  doi = {10.1016/0370-2693(87)91197-X},
  url = {http://www.sciencedirect.com/science/article/pii/037026938791197X},
  urldate = {2020-05-16},
  abstract = {We present a new method for the numerical simulation of lattice field theory. A hybrid (molecular dynamics/Langevin) algorithm is used to guide a Monte Carlo simulation. There are no discretization errors even for large step sizes. The method is especially efficient for systems such as quantum chromodynamics which contain fermionic degrees of freedom. Detailed results are presented for four-dimensional compact quantum electrodynamics including the dynamical effects of electrons.},
  langid = {english},
  file = {/Users/solomonkurz/Zotero/storage/SUYZYUWV/037026938791197X.html}
}

@article{eckhardtStanUlamJohn1987,
  title = {Stan {{Ulam}}, {{John}} von {{Neumann}} and the {{Monte Carlo}} Method},
  author = {Eckhardt, Roger},
  year = {1987},
  journal = {Argonne, USA},
  url = {https://library.sciencemadness.org/lanl1_a/lib-www/pubs/00326867.pdf}
}

@article{efronSteinParadoxStatistics1977,
  title = {Stein's Paradox in Statistics},
  author = {Efron, Bradley and Morris, Carl},
  year = {1977},
  journal = {Scientific American},
  volume = {236},
  number = {5},
  pages = {119--127},
  publisher = {{Scientific American, a division of Nature America, Inc.}},
  issn = {0036-8733},
  doi = {10.1038/scientificamerican0577-119},
  url = {https://www.jstor.org/stable/24954030},
  urldate = {2020-05-17}
}

@article{enders2007centering,
  title = {Centering Predictor Variables in Cross-Sectional Multilevel Models: {{A}} New Look at an Old Issue.},
  author = {Enders, Craig K and Tofighi, Davood},
  year = {2007},
  journal = {Psychological methods},
  volume = {12},
  number = {2},
  pages = {121},
  publisher = {{American Psychological Association}},
  doi = {10.1037/1082-989X.12.2.121},
  url = {https://www.researchgate.net/publication/6274186_Centering_Predictor_Variables_in_Cross-Sectional_Multilevel_Models_A_New_Look_at_An_Old_Issue}
}

@incollection{endersCenteringPredictorsContextual2013,
  title = {Centering Predictors and Contextual Effects},
  booktitle = {The {{SAGE Handbook}} of {{Multilevel Modeling}}},
  author = {Enders, Craig},
  editor = {Scott, Marc and Simonoff, Jeffrey and Marx, Brian},
  year = {2013},
  pages = {89--108},
  publisher = {{SAGE Publications Ltd}},
  address = {{1 Oliver's Yard,~55 City Road,~London~EC1Y 1SP~United Kingdom}},
  doi = {10.4135/9781446247600.n6},
  url = {http://methods.sagepub.com/book/the-sage-handbook-of-multilevel-modeling/n6.xml},
  urldate = {2020-05-16},
  isbn = {978-0-85702-564-7 978-1-4462-4760-0}
}

@incollection{fernandesUncertaintyDisplaysUsing2018,
  title = {Uncertainty Displays Using Quantile Dotplots or {{CDFs}} Improve Transit Decision-Making},
  booktitle = {Proceedings of the 2018 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Fernandes, Michael and Walls, Logan and Munson, Sean and Hullman, Jessica and Kay, Matthew},
  year = {2018},
  month = apr,
  pages = {1--12},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  url = {https://doi.org/10.1145/3173574.3173718},
  urldate = {2020-09-05},
  abstract = {Everyday predictive systems typically present point predictions, making it hard for people to account for uncertainty when making decisions. Evaluations of uncertainty displays for transit prediction have assessed people's ability to extract probabilities, but not the quality of their decisions. In a controlled, incentivized experiment, we had subjects decide when to catch a bus using displays with textual uncertainty, uncertainty visualizations, or no-uncertainty (control). Frequency-based visualizations previously shown to allow people to better extract probabilities (quantile dotplots) yielded better decisions. Decisions with quantile dotplots with 50 outcomes were(1) better on average, having expected payoffs 97\% of optimal(95\% CI: [95\%,98\%]), 5 percentage points more than control (95\% CI: [2,8]); and (2) more consistent, having within-subject standard deviation of 3 percentage points (95\% CI:[2,4]), 4 percentage points less than control (95\% CI: [2,6]).Cumulative distribution function plots performed nearly as well, and both outperformed textual uncertainty, which was sensitive to the probability interval communicated. We discuss implications for real time transit predictions and possible generalization to other domains.},
  isbn = {978-1-4503-5620-6},
  keywords = {cumulative distribution plots,dotplots,mobileinterfaces,transit predictions,uncertainty visualization}
}

@article{fernandezGGMCMCAnalysisofMCMC2016,
  title = {{{ggmcmc}}: {{Analysis}} of {{MCMC}} Samples and {{Bayesian}} Inference},
  author = {{Fern{\'a}ndez i Mar{\'i}n}, Xavier},
  year = {2016},
  journal = {Journal of Statistical Software},
  volume = {70},
  number = {9},
  pages = {1--20},
  doi = {10.18637/jss.v070.i09}
}

@book{fisherStatisticalMethodsResearch1925,
  title = {Statistical Methods for Research Workers, 11th Ed. Rev},
  author = {Fisher, R.A.},
  year = {1925},
  series = {Statistical Methods for Research Workers, 11th Ed. Rev},
  publisher = {{Edinburgh}},
  address = {{Oliver and Boyd}},
  url = {https://psycnet.apa.org/record/1925-15003-000},
  abstract = {Contains revisions of probability formulas and treatment of correlations.  Harvard Book List (edited) 1955 \#94 (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  file = {/Users/solomonkurz/Zotero/storage/L7DDMNLC/1925-15003-000.html}
}

@article{gabry2019visualization,
  title = {Visualization in {{Bayesian}} Workflow},
  author = {Gabry, Jonah and Simpson, Daniel and Vehtari, Aki and Betancourt, Michael and Gelman, Andrew},
  year = {2019},
  journal = {Journal of the Royal Statistical Society: Series A (Statistics in Society)},
  volume = {182},
  number = {2},
  pages = {389--402},
  publisher = {{Wiley Online Library}},
  doi = {10.1111/rssa.12378},
  url = {https://arxiv.org/abs/1709.01449}
}

@misc{gabryGraphicalPosteriorPredictive2019,
  title = {Graphical Posterior Predictive Checks Using the Bayesplot Package},
  author = {Gabry, Jonah},
  year = {2019},
  month = nov,
  url = {https://CRAN.R-project.org/package=bayesplot/vignettes/graphical-ppcs.html}
}

@article{gabryPlottingMCMCDraws2019,
  title = {Plotting {{MCMC}} Draws Using the Bayesplot Package},
  author = {Gabry, Jonah},
  year = {2020},
  month = may,
  url = {https://CRAN.R-project.org/package=bayesplot/vignettes/plotting-mcmc-draws.html},
  urldate = {2020-05-26},
  langid = {english}
}

@article{gelman2012we,
  title = {Why We (Usually) Don't Have to Worry about Multiple Comparisons},
  author = {Gelman, Andrew and Hill, Jennifer and Yajima, Masanao},
  year = {2012},
  journal = {Journal of Research on Educational Effectiveness},
  volume = {5},
  number = {2},
  pages = {189--211},
  publisher = {{Taylor \& Francis}},
  doi = {10.1080/19345747.2011.618213},
  url = {https://arxiv.org/pdf/0907.2478.pdf}
}

@book{gelman2013bayesian,
  title = {Bayesian Data Analysis},
  author = {Gelman, Andrew and Carlin, John B and Stern, Hal S and Dunson, David B and Vehtari, Aki and Rubin, Donald B},
  year = {2013},
  edition = {Third Edition},
  publisher = {{CRC press}},
  url = {https://stat.columbia.edu/~gelman/book/}
}

@article{gelmanAnalysisVarianceWhy2005,
  title = {Analysis of Variance--{{Why}} It Is More Important than Ever},
  author = {Gelman, Andrew},
  year = {2005},
  month = feb,
  journal = {Annals of Statistics},
  volume = {33},
  number = {1},
  pages = {1--53},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {0090-5364, 2168-8966},
  doi = {10.1214/009053604000001048},
  url = {https://projecteuclid.org/download/pdfview_1/euclid.aos/1112967698},
  urldate = {2020-05-18},
  abstract = {Analysis of variance (ANOVA) is an extremely important method in exploratory and confirmatory data analysis. Unfortunately, in complex problems (e.g., split-plot designs), it is not always easy to set up an appropriate ANOVA. We propose a hierarchical analysis that automatically gives the correct ANOVA comparisons even in complex scenarios. The inferences for all means and variances are performed under a model with a separate batch of effects for each row of the ANOVA table. We connect to classical ANOVA by working with finite-sample variance components: fixed and random effects models are characterized by inferences about existing levels of a factor and new levels, respectively. We also introduce a new graphical display showing inferences about the standard deviations of each batch of effects. We illustrate with two examples from our applied data analysis, first illustrating the usefulness of our hierarchical computations and displays, and second showing how the ideas of ANOVA are helpful in understanding a previously fit hierarchical model.},
  langid = {english},
  mrnumber = {MR2157795},
  zmnumber = {1064.62082},
  keywords = {ANOVA,Bayesian inference,fixed effects,hierarchical model,linear regression,multilevel model,random effects,variance components},
  file = {/Users/solomonkurz/Zotero/storage/2U3XQY5J/Gelman - 2005 - Analysis of variance—why it is more important than.pdf;/Users/solomonkurz/Zotero/storage/SQ6DDNZI/1112967698.html}
}

@article{gelmanPriorDistributionsVariance2006,
  title = {Prior Distributions for Variance Parameters in Hierarchical Models (Comment on Article by {{Browne}} and {{Draper}})},
  author = {Gelman, Andrew},
  year = {2006},
  month = sep,
  journal = {Bayesian Analysis},
  volume = {1},
  number = {3},
  pages = {515--534},
  publisher = {{International Society for Bayesian Analysis}},
  issn = {1936-0975, 1931-6690},
  doi = {10.1214/06-BA117A},
  url = {https://projecteuclid.org/euclid.ba/1340371048},
  urldate = {2020-05-17},
  abstract = {Various noninformative prior distributions have been suggested for scale parameters in hierarchical models. We construct a new folded-noncentral-ttt family of conditionally conjugate priors for hierarchical standard deviation parameters, and then consider noninformative and weakly informative priors in this family. We use an example to illustrate serious problems with the inverse-gamma family of "noninformative" prior distributions. We suggest instead to use a uniform prior on the hierarchical standard deviation, using the half-ttt family when the number of groups is small and in other settings where a weakly informative prior is desired. We also illustrate the use of the half-ttt family for hierarchical modeling of multiple variance parameters such as arise in the analysis of variance.},
  langid = {english},
  mrnumber = {MR2221284},
  zmnumber = {1331.62139},
  keywords = {Bayesian inference,conditional conjugacy,folded-noncentral-$t$ distribution,half-$t$ distribution,hierarchical model,multilevel model,noninformative prior distribution,weakly informative prior distribution},
  file = {/Users/solomonkurz/Zotero/storage/LNB63KFA/Gelman - 2006 - Prior distributions for variance parameters in hie.pdf;/Users/solomonkurz/Zotero/storage/AJT3SYSS/1340371048.html}
}

@article{gelmanRsquaredBayesianRegression2019,
  title = {R-Squared for {{Bayesian}} Regression Models},
  author = {Gelman, Andrew and Goodrich, Ben and Gabry, Jonah and Vehtari, Aki},
  year = {2019},
  month = jul,
  journal = {The American Statistician},
  volume = {73},
  number = {3},
  pages = {307--309},
  issn = {0003-1305, 1537-2731},
  doi = {10.1080/00031305.2018.1549100},
  url = {https://www.tandfonline.com/doi/full/10.1080/00031305.2018.1549100},
  urldate = {2020-05-16},
  langid = {english}
}

@article{gerardLimitsRetrospectivePower1998,
  title = {Limits of Retrospective Power Analysis},
  author = {Gerard, Patrick and Smith, David and Weerakkody, Govinda},
  year = {1998},
  month = apr,
  journal = {The Journal of Wildlife Management},
  volume = {62},
  pages = {801},
  doi = {10.2307/3802357},
  url = {https://www.researchgate.net/publication/273104134_Limits_of_Retrospective_Power_Analysis},
  abstract = {Power analysis after study completion has been suggested to interpret study results. We present 3 methods of estimating power and discuss their limitations. We use simulation studies to show that estimated power can be biased, extremely variable, and severely bounded. We endorse the practice of computing power to detect a biologically meaningful difference as a tool for study planning but suggest that calculation of confidence intervals on the parameter of interest is the appropriate way to gauge the strength and biological meaning of study results.},
  file = {/Users/solomonkurz/Zotero/storage/RLMXTUWI/Gerard et al. - 1998 - Limits of Retrospective Power Analysis.pdf}
}

@book{grolemundDataScience2017,
  title = {R for Data Science},
  author = {Grolemund, Garrett and Wickham, Hadley},
  year = {2017},
  publisher = {{O'Reilly}},
  url = {https://r4ds.had.co.nz}
}

@article{gronauLimitationsBayesianLeaveoneout2019,
  title = {Limitations of {{Bayesian}} Leave-One-out Cross-Validation for Model Selection},
  author = {Gronau, Quentin F and Wagenmakers, Eric-Jan},
  year = {2019},
  journal = {Computational brain \& behavior},
  volume = {2},
  number = {1},
  pages = {1--11},
  publisher = {{Springer}},
  url = {https://doi.org/10.1007/s42113-018-0011-7}
}

@article{gronauRejoinderMoreLimitations2019,
  title = {Rejoinder: {{More}} Limitations of {{Bayesian}} Leave-One-out Cross-Validation},
  author = {Gronau, Quentin F and Wagenmakers, Eric-Jan},
  year = {2019},
  journal = {Computational brain \& behavior},
  volume = {2},
  number = {1},
  pages = {35--47},
  publisher = {{Springer}},
  url = {https://doi.org/10.1007/s42113-018-0022-4}
}

@article{guber1999getting,
  title = {Getting What You Pay for: {{The}} Debate over Equity in Public School Expenditures},
  author = {Guber, Deborah, L},
  year = {1999},
  journal = {Journal of Statistics Education},
  volume = {7},
  number = {2},
  url = {https://www.semanticscholar.org/paper/Getting-What-You-Pay-For-The-Debate-Over-Equity-in-Guber/29c30e9dc77b56340faa5e6ad35e0741a5a83d49}
}

@incollection{hamakerWhyResearchersShould2012,
  title = {Why Researchers Should Think "within-Person": {{A}} Paradigmatic Rationale},
  shorttitle = {Why Researchers Should Think "within-Person"},
  booktitle = {Handbook of Research Methods for Studying Daily Life},
  author = {Hamaker, Ellen L.},
  year = {2012},
  pages = {43--61},
  publisher = {{The Guilford Press}},
  address = {{New York, NY, US}},
  url = {https://www.guilford.com/books/Handbook-of-Research-Methods-for-Studying-Daily-Life/Mehl-Conner/9781462513055},
  abstract = {This chapter presents reasoning for taking an alternative research approach to the study of processes that unfold within individuals over time as part of their daily lives. To this end I focus on three issues. First, I present a brief historical account that shows the large-sample approach is not necessarily the only appropriate research approach in psychology. Second, I discuss the limitations of this approach, specifically, if our interest is in studying psychological processes that take place within individuals. Finally, I discuss several alternatives to the standard large-sample approach that allow us to take a closer and more detailed look at the processes as they are occurring in daily life. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
  isbn = {978-1-60918-747-7 978-1-60918-749-1},
  keywords = {Cognitive Processes,Experiences (Events),Experimental Psychologists,Experimentation,History,Methodology,Personality Processes},
  file = {/Users/solomonkurz/Zotero/storage/7IAKF3TS/2012-05165-003.html}
}

@article{hanleySexualActivityLifespan1994,
  title = {Sexual Activity and the Lifespan of Male Fruitflies: {{A}} Dataset That Gets Attention},
  shorttitle = {Sexual {{Activity}} and the {{Lifespan}} of {{Male Fruitflies}}},
  author = {Hanley, A, James and Shapiro, H, Stanley},
  year = {1994},
  month = jul,
  journal = {Journal of Statistics Education},
  volume = {2},
  number = {1},
  pages = {null},
  publisher = {{Taylor \& Francis}},
  issn = {null},
  doi = {10.1080/10691898.1994.11910467},
  url = {https://doi.org/10.1080/10691898.1994.11910467},
  urldate = {2020-05-19},
  abstract = {This dataset contains observations on five groups of male fruitflies \textendash\textendash{} 25 fruitflies in each group \textendash\textendash{} from an experiment designed to test if increased reproduction reduces longevity for male fruitflies. (Such a cost has already been established for females.) The five groups are: males forced to live alone, males assigned to live with one or eight interested females, and males assigned to live with one or eight non-receptive females. The observations on each fly were longevity, thorax length, and the percentage of each day spent sleeping. The structure of the experiment provokes lively discussion on experimental design and on contrasts, and gives students opportunities to understand and verbalize what we mean by the term ``statistical interaction.'' Because the variable thorax length has a strong effect on survival, it is important to take it into account to increase the precision of between-group contrasts, even though it is distributed similarly across groups. The dataset can also be used to illustrate techniques of survival analysis.},
  keywords = {Analysis of covariance,Experiment,Longevity,Precision,Regression,Survival analysis},
  annotation = {\_eprint: https://doi.org/10.1080/10691898.1994.11910467},
  file = {/Users/solomonkurz/Zotero/storage/3XL9TZQK/A and H - 1994 - Sexual Activity and the Lifespan of Male Fruitflie.pdf;/Users/solomonkurz/Zotero/storage/5G6CU48Y/10691898.1994.html}
}

@misc{heynsBetterBibTeXZotero2020,
  title = {Better {{BibTeX}} for Zotero},
  author = {Heyns, Emiliano},
  year = {2020},
  url = {https://retorque.re/zotero-better-bibtex/},
  urldate = {2020-05-19}
}

@artwork{HokusaiGreatWaveOffKanagawa1820,
  title = {The Great Wave off {{Kanagawa}}},
  author = {Hokusai, Katsushika},
  year = {1820}
}

@article{hyndmanComputingGraphingHighest1996,
  title = {Computing and Graphing Highest Density Regions},
  author = {Hyndman, Rob J.},
  year = {1996},
  month = may,
  journal = {The American Statistician},
  volume = {50},
  number = {2},
  pages = {120--126},
  publisher = {{Taylor \& Francis}},
  issn = {0003-1305},
  doi = {10.1080/00031305.1996.10474359},
  url = {https://amstat.tandfonline.com/doi/abs/10.1080/00031305.1996.10474359},
  urldate = {2020-05-18},
  abstract = {Many statistical methods involve summarizing a probability distribution by a region of the sample space covering a specified probability. One method of selecting such a region is to require it to contain points of relatively high density. Highest density regions are particularly useful for displaying multimodal distributions and, in such cases, may consist of several disjoint subsets\textemdash one for each local mode. In this paper, I propose a simple method for computing a highest density region from any given (possibly multivariate) density f(x) that is bounded and continuous in x. Several examples of the use of highest density regions in statistical graphics are also given. A new form of boxplot is proposed based on highest density regions; versions in one and two dimensions are given. Highest density regions in higher dimensions are also discussed and plotted.},
  file = {/Users/solomonkurz/Zotero/storage/RTPEUENN/00031305.1996.html}
}

@artwork{jeanRiftScull2009,
  title = {{{RIFT SCULL}}},
  author = {Jean, James},
  year = {2009}
}

@book{jeffreysTheoryProbability1961,
  title = {Theory of Probability},
  author = {Jeffreys, Harold},
  year = {1961},
  publisher = {{Oxford University Press}},
  url = {https://global.oup.com/academic/product/theory-of-probability-9780198503682?cc=us&lang=en&}
}

@article{kassBayesFactors1995,
  title = {Bayes Factors},
  author = {Kass, Robert E and Raftery, Adrian E},
  year = {1995},
  journal = {Journal of the American Statistical Association},
  volume = {90},
  number = {430},
  pages = {773--795},
  publisher = {{Taylor \& Francis}},
  url = {https://www.stat.washington.edu/raftery/Research/PDF/kass1995.pdf}
}

@misc{kayExtractingVisualizingTidy2020,
  title = {Extracting and Visualizing Tidy Draws from Brms Models},
  author = {Kay, Matthew},
  year = {2020},
  month = jun,
  url = {https://mjskay.github.io/tidybayes/articles/tidy-brms.html},
  urldate = {2020-05-17},
  abstract = {tidybayes},
  langid = {english},
  file = {/Users/solomonkurz/Zotero/storage/NT83AM3T/tidy-brms.html}
}

@misc{kaySlabIntervalStats2020,
  title = {Slab + Interval Stats and Geoms},
  author = {Kay, Matthew},
  year = {2020},
  month = jul,
  url = {https://mjskay.github.io/ggdist/articles/slabinterval.html},
  urldate = {2020-05-15},
  abstract = {ggdist},
  langid = {english},
  file = {/Users/solomonkurz/Zotero/storage/SDV77RJR/slabinterval.html}
}

@inproceedings{kayWhenIshMy2016,
  title = {When (Ish) Is My Bus? {{User-centered}} Visualizations of Uncertainty in Everyday, Mobile Predictive Systems},
  shorttitle = {When (Ish) Is {{My Bus}}?},
  booktitle = {Proceedings of the 2016 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Kay, Matthew and Kola, Tara and Hullman, Jessica R. and Munson, Sean A.},
  year = {2016},
  month = may,
  series = {{{CHI}} '16},
  pages = {5092--5103},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/2858036.2858558},
  url = {https://doi.org/10.1145/2858036.2858558},
  urldate = {2020-09-05},
  abstract = {Users often rely on realtime predictions in everyday contexts like riding the bus, but may not grasp that such predictions are subject to uncertainty. Existing uncertainty visualizations may not align with user needs or how they naturally reason about probability. We present a novel mobile interface design and visualization of uncertainty for transit predictions on mobile phones based on discrete outcomes. To develop it, we identified domain specific design requirements for visualizing uncertainty in transit prediction through: 1) a literature review, 2) a large survey of users of a popular realtime transit application, and 3) an iterative design process. We present several candidate visualizations of uncertainty for realtime transit predictions in a mobile context, and we propose a novel discrete representation of continuous outcomes designed for small screens, quantile dotplots. In a controlled experiment we find that quantile dotplots reduce the variance of probabilistic estimates by \textasciitilde 1.15 times compared to density plots and facilitate more confident estimation by end-users in the context of realtime transit prediction scenarios.},
  isbn = {978-1-4503-3362-7},
  keywords = {dotplots,end-user visualization,mobile interfac-es,transit predictions,uncertainty visualization}
}

@article{kelley2012effect,
  title = {On Effect Size},
  author = {Kelley, Ken and Preacher, Kristopher J},
  year = {2012},
  journal = {Psychological methods},
  volume = {17},
  number = {2},
  pages = {137},
  publisher = {{American Psychological Association}},
  doi = {10.1037/a0028086},
  url = {https://www3.nd.edu/~kkelley/publications/articles/Kelley_and_Preacher_Psychological_Methods_2012.pdf}
}

@article{kleinPracticalGuideTransparency2018,
  title = {A Practical Guide for Transparency in Psychological Science.},
  author = {Klein, O. and Hardwicke, T. E. and Aust, F. and Breuer, J. and Danielsson, H. and Hofelich Mohr, A. and IJzerman, H. and Nilsonne, G. and Vanpaemel, W. and Frank, M. C.},
  year = {2018},
  month = jun,
  journal = {Collabra: Psychology},
  volume = {4},
  number = {1},
  pages = {1--15},
  publisher = {{The Regents of the University of California}},
  issn = {2474-7394},
  doi = {10.1525/collabra.158},
  url = {https://lirias.kuleuven.be/1999530},
  urldate = {2020-05-18},
  abstract = {\textcopyright{} 2018 The Author(s). The credibility of scientific claims depends upon the transparency of the research products upon which they are based (e.g., study protocols, data, materials, and analysis scripts). As psychology navigates a period of unprecedented introspection, user-friendly tools and services that support open science have flourished. However, the plethora of decisions and choices involved can be bewildering. Here we provide a practical guide to help researchers navigate the process of preparing and sharing the products of their research (e.g., choosing a repository, preparing their research products for sharing, structuring folders, etc.). Being an open scientist means adopting a few straightforward research management practices, which lead to less error prone, reproducible research workflows. Further, this adoption can be piecemeal \textendash{} each incremental step towards complete transparency adds positive value. Transparent research practices not only improve the efficiency of individual researchers, they enhance the credibility of the knowledge generated by the scientific community.},
  langid = {english},
  file = {/Users/solomonkurz/Zotero/storage/439IHJWF/Klein et al. - 2018 - A practical guide for transparency in psychologica.pdf;/Users/solomonkurz/Zotero/storage/AKE5WGPW/1999530.html}
}

@book{kolmogorovFoundationsTheoryProbability1956,
  title = {Foundations of the Theory of Probability: {{Second English Edition}}},
  author = {Kolmogorov, Andre{\textbackslash}u{\i} Nikolaevich and {Bharucha-Reid}, Albert T},
  year = {1956},
  publisher = {{Chelsea Publishing Company}},
  url = {https://www.york.ac.uk/depts/maths/histstat/kolmogorov_foundations.pdf}
}

@article{kruschkeBayesianNewStatistics2018,
  title = {{{The Bayesian New Statistics}}: {{Hypothesis}} Testing, Estimation, Meta-Analysis, and Power Analysis from a {{Bayesian}} Perspective},
  shorttitle = {The {{Bayesian New Statistics}}},
  author = {Kruschke, John K. and Liddell, Torrin M.},
  year = {2018},
  month = feb,
  journal = {Psychonomic Bulletin \& Review},
  volume = {25},
  number = {1},
  pages = {178--206},
  issn = {1531-5320},
  doi = {10.3758/s13423-016-1221-4},
  url = {https://link.springer.com/content/pdf/10.3758/s13423-016-1221-4.pdf},
  urldate = {2020-05-18},
  abstract = {In the practice of data analysis, there is a conceptual distinction between hypothesis testing, on the one hand, and estimation with quantified uncertainty on the other. Among frequentists in psychology, a shift of emphasis from hypothesis testing to estimation has been dubbed ``the New Statistics'' (Cumming 2014). A second conceptual distinction is between frequentist methods and Bayesian methods. Our main goal in this article is to explain how Bayesian methods achieve the goals of the New Statistics better than frequentist methods. The article reviews frequentist and Bayesian approaches to hypothesis testing and to estimation with confidence or credible intervals. The article also describes Bayesian approaches to meta-analysis, randomized controlled trials, and power analysis.},
  langid = {english},
  file = {/Users/solomonkurz/Zotero/storage/SRKQT967/Kruschke and Liddell - 2018 - The Bayesian New Statistics Hypothesis testing, e.pdf}
}

@book{kruschkeDoingBayesianData2015,
  title = {Doing {{Bayesian}} Data Analysis: {{A}} Tutorial with {{R}}, {{JAGS}}, and {{Stan}}},
  author = {Kruschke, John K.},
  year = {2015},
  publisher = {{Academic Press}},
  url = {https://sites.google.com/site/doingbayesiandataanalysis/}
}

@article{kruschkePosteriorPredictiveChecks2013,
  title = {Posterior Predictive Checks Can and Should Be {{Bayesian}}: {{Comment}} on {{Gelman}} and {{Shalizi}}, `{{Philosophy}} and the Practice of {{Bayesian}} Statistics'},
  shorttitle = {Posterior Predictive Checks Can and Should Be {{Bayesian}}},
  author = {Kruschke, John K.},
  year = {2013},
  journal = {British Journal of Mathematical and Statistical Psychology},
  volume = {66},
  number = {1},
  pages = {45--56},
  issn = {2044-8317},
  doi = {10.1111/j.2044-8317.2012.02063.x},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.2044-8317.2012.02063.x},
  urldate = {2020-05-18},
  abstract = {Bayesian inference is conditional on the space of models assumed by the analyst. The posterior distribution indicates only which of the available parameter values are less bad than the others, without indicating whether the best available parameter values really fit the data well. A posterior predictive check is important to assess whether the posterior predictions of the least bad parameters are discrepant from the actual data in systematic ways. Gelman and Shalizi (2012a) assert that the posterior predictive check, whether done qualitatively or quantitatively, is non-Bayesian. I suggest that the qualitative posterior predictive check might be Bayesian, and the quantitative posterior predictive check should be Bayesian. In particular, I show that the `Bayesian p-value', from which an analyst attempts to reject a model without recourse to an alternative model, is ambiguous and inconclusive. Instead, the posterior predictive check, whether qualitative or quantitative, should be consummated with Bayesian estimation of an expanded model. The conclusion agrees with Gelman and Shalizi regarding the importance of the posterior predictive check for breaking out of an initially assumed space of models. Philosophically, the conclusion allows the liberation to be completely Bayesian instead of relying on a non-Bayesian deus ex machina. Practically, the conclusion cautions against use of the Bayesian p-value in favour of direct model expansion and Bayesian evaluation.},
  copyright = {\textcopyright{} 2012 The British Psychological Society},
  langid = {english},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.2044-8317.2012.02063.x},
  file = {/Users/solomonkurz/Zotero/storage/T32AK4DC/j.2044-8317.2012.02063.html}
}

@book{kurzStatisticalRethinkingBrms2020,
  title = {Statistical Rethinking with Brms, {{ggplot2}}, and the Tidyverse},
  author = {Kurz, A. Solomon},
  year = {2020},
  month = oct,
  edition = {version 1.2.0},
  doi = {10.5281/zenodo.3693202},
  url = {https://bookdown.org/content/3890/},
  urldate = {2020-05-16},
  abstract = {This project is an attempt to re-express the code in McElreath's textbook. His models are re-fit in brms, plots are redone with ggplot2, and the general data wrangling code predominantly follows the tidyverse style.},
  file = {/Users/solomonkurz/Zotero/storage/MTCXZRHZ/3890.html}
}

@book{kurzStatisticalRethinkingSecondEd2021,
  title = {Statistical Rethinking with Brms, {{ggplot2}}, and the Tidyverse: {{Second Edition}}},
  author = {Kurz, A. Solomon},
  year = {2021},
  month = mar,
  edition = {version 0.2.0},
  url = {https://bookdown.org/content/4857/},
  urldate = {2021-04-14},
  abstract = {This book is an attempt to re-express the code in the second edition of McElreath's textbook, 'Statistical rethinking.' His models are re-fit in brms, plots are redone with ggplot2, and the general data wrangling code predominantly follows the tidyverse style.}
}

@article{lakensEquivalenceTestingPsychological2018,
  title = {Equivalence Testing for Psychological Research: {{A}} Tutorial},
  shorttitle = {Equivalence Testing for Psychological Research},
  author = {Lakens, Dani{\"e}l and Scheel, Anne M. and Isager, Peder M.},
  year = {2018},
  journal = {Advances in Methods and Practices in Psychological Science},
  volume = {1},
  number = {2},
  pages = {259--269},
  publisher = {{Sage Publications Sage CA: Los Angeles, CA}},
  doi = {10.1177/2515245918770963},
  file = {/Users/solomonkurz/Zotero/storage/ARE8PRAA/Lakens et al. - 2018 - Equivalence testing for psychological research A .pdf;/Users/solomonkurz/Zotero/storage/X8WDV6SQ/2515245918770963.html}
}

@article{lakensEquivalenceTestingSecond2018,
  title = {Equivalence Testing and the Second Generation P-Value},
  author = {Lakens, Dani{\"e}l and Delacre, Marie},
  year = {2018},
  month = aug,
  publisher = {{PsyArXiv}},
  doi = {10.31234/osf.io/7k6ay},
  url = {https://psyarxiv.com/7k6ay/},
  urldate = {2020-05-16},
  abstract = {To move beyond the limitations of null-hypothesis tests, statistical approaches have been developed where the observed data is compared against a range of values that are equivalent to the absence of a meaningful effect. Specifying a range of values around zero allows researchers to statistically reject the presence of effects large enough to matter, and prevents practically insignificant effects from being interpreted as a statistically significant difference. We compare the behavior of the recently proposed second generation p-value (Blume, D'Agostino McGowan, Dupont, \& Greevy, 2018) with the more established Two One-Sided Tests (TOST) equivalence testing procedure (Schuirmann, 1987). We show that the two approaches yield almost identical results under optimal conditions. Under suboptimal conditions (e.g., when the confidence interval is wider than the equivalence range, or when confidence intervals are asymmetric) the second generation p-value becomes difficult to interpret as a descriptive statistic. The second generation p-value is interpretable in a dichotomous manner (i.e., when the SGPV equals 0 or 1 because the confidence intervals lies completely within or outside of the equivalence range), but this dichotomous interpretation does not require calculations. We conclude that equivalence tests yield more consistent p-values, distinguish between datasets that yield the same second generation p-value, and allow for easier control of Type I and Type II error rates.},
  file = {/Users/solomonkurz/Zotero/storage/8NTJHU7N/Lakens and Delacre - 2018 - Equivalence Testing and the Second Generation P-Va.pdf;/Users/solomonkurz/Zotero/storage/UVGXMXC9/7k6ay.html}
}

@article{lakensImprovingInferencesNull2020,
  title = {Improving Inferences about Null Effects with {{Bayes}} Factors and Equivalence Tests},
  author = {Lakens, Dani{\"e}l and McLatchie, Neil and Isager, Peder M and Scheel, Anne M and Dienes, Zoltan},
  editor = {Isaacowitz, Derek},
  year = {2020},
  month = jan,
  journal = {The Journals of Gerontology: Series B},
  volume = {75},
  number = {1},
  pages = {45--57},
  issn = {1079-5014, 1758-5368},
  doi = {10.1093/geronb/gby065},
  url = {https://academic.oup.com/psychsocgerontology/article/75/1/45/5033832},
  urldate = {2020-05-16},
  abstract = {Abstract             Researchers often conclude an effect is absent when a null-hypothesis significance test yields a nonsignificant p value. However, it is neither logically nor statistically correct to conclude an effect is absent when a hypothesis test is not significant. We present two methods to evaluate the presence or absence of effects: Equivalence testing (based on frequentist statistics) and Bayes factors (based on Bayesian statistics). In four examples from the gerontology literature, we illustrate different ways to specify alternative models that can be used to reject the presence of a meaningful or predicted effect in hypothesis tests. We provide detailed explanations of how to calculate, report, and interpret Bayes factors and equivalence tests. We also discuss how to design informative studies that can provide support for a null model or for the absence of a meaningful effect. The conceptual differences between Bayes factors and equivalence tests are discussed, and we also note when and why they might lead to similar or different inferences in practice. It is important that researchers are able to falsify predictions or can quantify the support for predicted null effects. Bayes factors and equivalence tests provide useful statistical tools to improve inferences about null effects.},
  langid = {english},
  file = {/Users/solomonkurz/Zotero/storage/RAXAMC8E/Lakens et al. - 2020 - Improving Inferences About Null Effects With Bayes.pdf}
}

@article{leeModelingIndividualDifferences2005,
  title = {Modeling Individual Differences in Cognition},
  author = {Lee, Michael D. and Webb, Michael R.},
  year = {2005},
  month = aug,
  journal = {Psychonomic Bulletin \& Review},
  volume = {12},
  number = {4},
  pages = {605--621},
  issn = {1069-9384, 1531-5320},
  doi = {10.3758/BF03196751},
  url = {http://link.springer.com/10.3758/BF03196751},
  urldate = {2020-05-16},
  langid = {english},
  file = {/Users/solomonkurz/Zotero/storage/7GYW7HR7/Lee and Webb - 2005 - Modeling individual differences in cognition.pdf}
}

@book{leglerBroadeningYourStatistical2019,
  title = {Broadening Your Statistical Horizons: {{Generalized}} Linear Models and Multilevel Models},
  author = {Legler, Julie and Roback, Paul},
  year = {2019},
  url = {https://bookdown.org/roback/bookdown-bysh/}
}

@article{likertTechniqueMeasurementAttitudes1932,
  title = {A Technique for the Measurement of Attitudes},
  author = {Likert, R.},
  year = {1932},
  journal = {Archives of Psychology},
  volume = {22  140},
  pages = {55--55},
  url = {https://legacy.voteview.com/pdf/Likert_1932.pdf},
  abstract = {The project conceived in 1929 by Gardner Murphy and the writer aimed first to present a wide array of problems having to do with five major "attitude areas"\textemdash international relations, race relations, economic conflict, political conflict, and religion. The kind of questionnaire material falls into four classes: yes-no, multiple choice, propositions to be responded to by degrees of approval, and a series of brief newspaper narratives to be approved or disapproved in various degrees. The monograph aims to describe a technique rather than to give results. The appendix, covering ten pages, shows the method of constructing an attitude scale. A bibliography is also given. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  file = {/Users/solomonkurz/Zotero/storage/3VW2VGT5/1933-01885-001.html}
}

@article{linde2021DecisionsAboutequivalence,
  title = {Decisions about Equivalence: {{A}} Comparison of {{TOST, HDI-ROPE}}, and the {{Bayes}} Factor.},
  author = {Linde, Maximilian and Tendeiro, Jorge N and Selker, Ravi and Wagenmakers, Eric-Jan and {van Ravenzwaaij}, Don},
  year = {2021},
  journal = {Psychological Methods},
  publisher = {{American Psychological Association}},
  doi = {10.1037/met0000402}
}

@article{liuBayesFactorsPrior2008,
  title = {Bayes Factors: {{Prior}} Sensitivity and Model Generalizability},
  author = {Liu, Charles C and Aitkin, Murray},
  year = {2008},
  journal = {Journal of Mathematical Psychology},
  volume = {52},
  number = {6},
  pages = {362--375},
  publisher = {{Elsevier}},
  url = {https://doi.org/10.1016/j.jmp.2008.03.002}
}

@book{luceIndividualChoiceBehavior2012,
  title = {Individual Choice Behavior: {{A}} Theoretical Analysis},
  shorttitle = {Individual {{Choice Behavior}}},
  author = {Luce, R. Duncan},
  year = {2012},
  month = jun,
  publisher = {{Courier Corporation}},
  abstract = {This influential treatise presents upper-level undergraduates and graduate students with a mathematical analysis of choice behavior. It begins with the statement of a general axiom upon which the rest of the book rests; the following three chapters, which may be read independently of each other, are devoted to applications of the theory to substantive problems: psychophysics, utility, and learning.Applications to psychophysics include considerations of time- and space-order effects, the Fechnerian assumption, the power law and its relation to discrimination data, interaction of continua, discriminal processes, signal detectability theory, and ranking of stimuli. The next major theme, utility theory, features unusual results that suggest an experiment to test the theory. The final chapters explore learning-related topics, analyzing the stochastic theories of learning as the basic approach\textemdash with the exception that distributions of response strengths are assumed to be transformed rather than response probabilities. The author arrives at three classes of learning operators, both linear and nonlinear, and the text concludes with a useful series of appendixes.},
  googlebooks = {ERQsKkPiKkkC},
  isbn = {978-0-486-15339-1},
  langid = {english},
  keywords = {Mathematics / Probability \& Statistics / General}
}

@article{luceLuceChoiceAxiom2008,
  title = {Luce's Choice Axiom},
  author = {Luce, R. Duncan},
  year = {2008},
  month = dec,
  journal = {Scholarpedia},
  volume = {3},
  number = {12},
  pages = {8077},
  issn = {1941-6016},
  doi = {10.4249/scholarpedia.8077},
  url = {http://www.scholarpedia.org/article/Luce%27s_choice_axiom},
  urldate = {2020-05-18},
  langid = {english},
  file = {/Users/solomonkurz/Zotero/storage/PMGIVY8Z/Luce's_choice_axiom.html}
}

@book{mackay2003information,
  title = {Information Theory, Inference and Learning Algorithms},
  author = {MacKay, David JC},
  year = {2003},
  publisher = {{Cambridge University Press}},
  url = {https://www.inference.org.uk/itprnn/book.pdf}
}

@article{martoneDataSharingPsychology2018,
  title = {Data Sharing in Psychology},
  author = {Martone, Maryann E. and {Garcia-Castro}, Alexander and VandenBos, Gary R.},
  year = {2018},
  journal = {The American psychologist},
  volume = {73},
  number = {2},
  pages = {111--125},
  issn = {0003-066X},
  doi = {10.1037/amp0000242},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5920518/pdf/nihms935471.pdf},
  urldate = {2020-05-18},
  abstract = {Routine data sharing, defined here as the publication of the primary data and any supporting materials required to interpret the data acquired as part of a research study, is still in its infancy in psychology, as in many domains. Nevertheless, with increased scrutiny on reproducibility and more funder mandates requiring sharing of data, the issues surrounding data sharing are moving beyond whether data sharing is a benefit or a bane to science, to what data should be shared and how. Here, we present an overview of these issues, specifically focusing on the sharing of so-called ``long tail'' data, that is, data generated by individual laboratories as part of largely hypothesis-driven research. We draw on experiences in other domains to discuss attitudes towards data sharing, cost-benefits, best practices and infrastructure. We argue that the publishing of data sets is an integral component of 21st century scholarship. Moreover, although not all issues around how and what to share have been resolved, a consensus on principles and best practices for effective data sharing and the infrastructure for sharing many types of data are largely in place.},
  pmcid = {PMC5920518},
  pmid = {29481105},
  file = {/Users/solomonkurz/Zotero/storage/JXPYAVVI/Martone et al. - 2018 - Data Sharing in Psychology.pdf}
}

@book{MASS2002,
  title = {Modern Applied Statistics with {{S}}},
  author = {Venables, W. N. and Ripley, B. D.},
  year = {2002},
  edition = {Fourth Edition},
  publisher = {{Springer}},
  address = {{New York}},
  url = {http://www.stats.ox.ac.uk/pub/MASS4}
}

@book{mcelreathStatisticalRethinkingBayesian2015,
  title = {Statistical Rethinking: {{A Bayesian}} Course with Examples in {{R}} and {{Stan}}},
  author = {McElreath, Richard},
  year = {2015},
  publisher = {{CRC press}},
  url = {https://xcelab.net/rm/statistical-rethinking/}
}

@book{mcelreathStatisticalRethinkingBayesian2020,
  title = {Statistical Rethinking: {{A Bayesian}} Course with Examples in {{R}} and {{Stan}}},
  shorttitle = {Statistical {{Rethinking}}},
  author = {McElreath, Richard},
  year = {2020},
  month = mar,
  edition = {Second Edition},
  publisher = {{CRC Press}},
  url = {https://xcelab.net/rm/statistical-rethinking/},
  abstract = {Statistical Rethinking: A Bayesian Course with Examples in R and Stan builds your knowledge of and confidence in making inferences from data. Reflecting the need for scripting in today's model-based statistics, the book pushes you to perform step-by-step calculations that are usually automated. This unique computational approach ensures that you understand enough of the details to make reasonable choices and interpretations in your own modeling work.  The text presents causal inference and generalized linear multilevel models from a simple Bayesian perspective that builds on information theory and maximum entropy. The core material ranges from the basics of regression to advanced multilevel models. It also presents measurement error, missing data, and Gaussian process models for spatial and phylogenetic confounding.  The second edition emphasizes the directed acyclic graph (DAG) approach to causal inference, integrating DAGs into many examples. The new edition also contains new material on the design of prior distributions, splines, ordered categorical predictors, social relations models, cross-validation, importance sampling, instrumental variables, and Hamiltonian Monte Carlo. It ends with an entirely new chapter that goes beyond generalized linear modeling, showing how domain-specific scientific models can be built into statistical analyses.  Features   Integrates working code into the main text   Illustrates concepts through worked data analysis examples   Emphasizes understanding assumptions and how assumptions are reflected in code   Offers more detailed explanations of the mathematics in optional sections   Presents examples of using the dagitty R package to analyze causal graphs   Provides the rethinking R package on the author's website and on GitHub},
  isbn = {978-0-429-63914-2},
  langid = {english},
  keywords = {Mathematics / Probability \& Statistics / General}
}

@book{mcgrayneTheoryThatWould2011,
  title = {The Theory That Would Not Die: How {{Bayes}}' Rule Cracked the Enigma Code, Hunted down {{Russian}} Submarines, \& Emerged Triumphant from Two Centuries of Controversy},
  author = {McGrayne, Sharon Bertsch},
  year = {2011},
  publisher = {{Yale University Press}},
  url = {https://yalebooks.yale.edu/book/9780300188226/theory-would-not-die}
}

@article{Merkle2018blavaan,
  title = {{{blavaan}}: {{Bayesian}} Structural Equation Models via Parameter Expansion},
  author = {Merkle, Edgar C. and Rosseel, Yves},
  year = {2018},
  journal = {Journal of Statistical Software},
  volume = {85},
  number = {4},
  pages = {1--30},
  doi = {10.18637/jss.v085.i04}
}

@article{metropolisEquationStateCalculations1953,
  title = {Equation of State Calculations by Fast Computing Machines},
  author = {Metropolis, Nicholas and Rosenbluth, Arianna W and Rosenbluth, Marshall N and Teller, Augusta H and Teller, Edward},
  year = {1953},
  journal = {The journal of chemical physics},
  volume = {21},
  number = {6},
  pages = {1087--1092},
  publisher = {{American Institute of Physics}},
  doi = {10.1063/1.1699114},
  url = {https://bayes.wustl.edu/Manual/EquationOfState.pdf}
}

@article{millerWhatProbabilityReplicating2009,
  title = {What Is the Probability of Replicating a Statistically Significant Effect?},
  author = {Miller, Jeff},
  year = {2009},
  month = aug,
  journal = {Psychonomic Bulletin \& Review},
  volume = {16},
  number = {4},
  pages = {617--640},
  issn = {1069-9384, 1531-5320},
  doi = {10.3758/PBR.16.4.617},
  url = {http://link.springer.com/10.3758/PBR.16.4.617},
  urldate = {2020-05-16},
  langid = {english},
  file = {/Users/solomonkurz/Zotero/storage/6JP49JDB/Miller - 2009 - What is the probability of replicating a statistic.pdf}
}

@article{nakagawaCaseRetrospectiveStatistical2004,
  title = {The Case against Retrospective Statistical Power Analyses with an Introduction to Power Analysis},
  author = {Nakagawa, Shinichi and Foster, T. Mary},
  year = {2004},
  journal = {Acta Ethologica},
  volume = {7},
  number = {2},
  pages = {103--108},
  publisher = {{Springer}},
  address = {{Germany}},
  issn = {1437-9546(Electronic),0873-9749(Print)},
  doi = {10.1007/s10211-004-0095-z},
  url = {https://www.researchgate.net/publication/226772798_The_case_against_retrospective_statistical_power_analyses_with_an_introduction_to_power_analysis},
  abstract = {Statistical power analysis is an important tool for planning an experiment because this type of analysis allows researchers to identify an appropriate sample size for a particular experimental design. In recent years, it seems many biology journals have been encouraging researchers to calculate statistical power after their experiments when they have obtained non-significant results (hereafter, termed "retrospective power calculation or analysis" as opposed to "prospective power analysis", which is conducted pre-experimentally). The logic for retrospective power analysis for data interpretation is as follows. When a non-significant result is obtained (especially with small samples), we should examine the statistical power of the significance test. If the test had low statistical power (or a high Type-II error rate), we should reserve "acceptance" (or more properly "nonrejection") of H{$_0$}. The argument is that we may refer to the result as inconclusive because an increase in power (e.g. through an increase in sample size) might have produced a statistically significant result. On the other hand, if a nonsignificant result is obtained, despite high power (i.e. a low Type-II error rate), we can be fairly confident about the non-rejection of H{$_0$} (note that with results from null hypothesis significance testing, we can only reject or not reject H{$_0$}, but we cannot "accept" H{$_0$}-although the previously quoted sentence from Animal Behavior's instructions for authors seems to confuse this fact). Many researchers have both not recognized the serious logical flaw in retrospective power analysis when it is used for interpreting nonsignificant results and that an accurate understanding of power analysis has yet to be established among some researchers, especially among students in the study of animal behavior. The purpose of this article is-using the independent f-test as an example-to: (1) outline statistical power analysis and its components; (2) describe three common ways used to make retrospective power calculations and their logical flaws and shortcomings; (3) discuss solutions to the current situation and make recommendations. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Experimental Design,Null Hypothesis Testing,Statistical Analysis,Statistical Power,Type II Errors},
  file = {/Users/solomonkurz/Zotero/storage/SG5KXE2E/2005-06529-008.html}
}

@article{navarroDevilDeepBlue2019,
  title = {Between the Devil and the Deep Blue Sea: {{Tensions}} between Scientific Judgement and Statistical Model Selection},
  shorttitle = {Between the {{Devil}} and the {{Deep Blue Sea}}},
  author = {Navarro, Danielle J.},
  year = {2019},
  month = mar,
  journal = {Computational Brain \& Behavior},
  volume = {2},
  number = {1},
  pages = {28--34},
  issn = {2522-0861, 2522-087X},
  doi = {10.1007/s42113-018-0019-z},
  url = {http://link.springer.com/10.1007/s42113-018-0019-z},
  urldate = {2020-05-15},
  abstract = {Discussions of model selection in the psychological literature typically frame the issues as a question of statistical inference, with the goal being to determine which model makes the best predictions about data. Within this setting, advocates of leaveone-out cross-validation and Bayes factors disagree on precisely which prediction problem model selection questions should aim to answer. In this comment, I discuss some of these issues from a scientific perspective. What goal does model selection serve when all models are known to be systematically wrong? How might ``toy problems'' tell a misleading story? How does the scientific goal of explanation align with (or differ from) traditional statistical concerns? I do not offer answers to these questions, but hope to highlight the reasons why psychological researchers cannot avoid asking them.},
  langid = {english},
  file = {/Users/solomonkurz/Zotero/storage/3D6FMZVD/Navarro - 2019 - Between the Devil and the Deep Blue Sea Tensions .pdf}
}

@book{navarroLearningStatistics2019,
  title = {Learning Statistics with {{R}}},
  author = {Navarro, Danielle},
  year = {2019},
  url = {https://learningstatisticswithr.com},
  langid = {english}
}

@incollection{neal2011mcmc,
  title = {{{MCMC}} Using {{Hamiltonian}} Dynamics},
  booktitle = {Handbook of {{Markov}} Chain {{Monte Carlo}}},
  author = {Neal, R},
  editor = {Brooks, Steve and Gelman, Andrew and Jones, Galin and Meng, Xiao-Li},
  year = {2011},
  pages = {116--162},
  publisher = {{London, United Kingdom: Chapman \& Hall/CRC Press}},
  url = {https://arxiv.org/pdf/1206.1901.pdf}
}

@article{nealImprovedAcceptanceProcedure1994,
  title = {An Improved Acceptance Procedure for the Hybrid {{Monte Carlo}} Algorithm},
  author = {Neal, Radford M.},
  year = {1994},
  month = mar,
  journal = {Journal of Computational Physics},
  volume = {111},
  number = {1},
  pages = {194--203},
  issn = {0021-9991},
  doi = {10.1006/jcph.1994.1054},
  url = {http://www.sciencedirect.com/science/article/pii/S0021999184710540},
  urldate = {2020-05-16},
  abstract = {The probability of accepting a candidate move in the hybrid Monte Carlo algorithm can be increased by considering a transition to be between windows of several states at the beginning and end of the trajectory, with a particular state within the selected window then being chosen according to the Boltzmann probabilities. The detailed balance condition used to justify the algorithm still holds with this procedure, provided the start state is randomly positioned within its window. The new procedure is shown empirically to significantly improve the acceptance rate for a test system of uncoupled oscillators. It also allows expectations to be estimated using data from all states in the windows, rather than just states that are accepted.},
  langid = {english},
  file = {/Users/solomonkurz/Zotero/storage/4G66CMT3/Neal - 1994 - An Improved Acceptance Procedure for the Hybrid Mo.pdf;/Users/solomonkurz/Zotero/storage/2RCV64ZH/S0021999184710540.html}
}

@article{nelder1972generalized,
  title = {Generalized Linear Models},
  author = {Nelder, John Ashworth and Wedderburn, Robert WM},
  year = {1972},
  journal = {Journal of the Royal Statistical Society: Series A (General)},
  volume = {135},
  number = {3},
  pages = {370--384},
  publisher = {{Wiley Online Library}},
  doi = {10.2307/2344614},
  url = {https://repository.rothamsted.ac.uk/download/25425465aa52d05e1a9e553b2daddeeffe15d0ba40f5f9b8937aaab5c3d29e1d/4410096/Nelder%201972.pdf}
}

@book{nicenboim2021introduction,
  title = {An Introduction to {{Bayesian}} Data Analysis for Cognitive Science},
  author = {Nicenboim, Bruno and Schad, Daniel and Vasishth, Shravan},
  year = {2021},
  url = {https://vasishth.github.io/bayescogsci/book/}
}

@article{normanLikertScalesLevels2010,
  title = {Likert Scales, Levels of Measurement and the ``Laws'' of Statistics},
  author = {Norman, Geoff},
  year = {2010},
  month = dec,
  journal = {Advances in Health Sciences Education},
  volume = {15},
  number = {5},
  pages = {625--632},
  issn = {1573-1677},
  doi = {10.1007/s10459-010-9222-y},
  url = {https://www.researchgate.net/publication/41420484_LIkert_scales_levels_of_measurement_adn_the_laws_of_statistics},
  urldate = {2020-05-18},
  abstract = {Reviewers of research reports frequently criticize the choice of statistical methods. While some of these criticisms are well-founded, frequently the use of various parametric methods such as analysis of variance, regression, correlation are faulted because: (a) the sample size is too small, (b) the data may not be normally distributed, or (c) The data are from Likert scales, which are ordinal, so parametric statistics cannot be used. In this paper, I dissect these arguments, and show that many studies, dating back to the 1930s consistently show that parametric statistics are robust with respect to violations of these assumptions. Hence, challenges like those above are unfounded, and parametric methods can be utilized without concern for ``getting the wrong answer''.},
  langid = {english}
}

@article{okeefeBriefReportPost2007,
  title = {Brief Report: {{Post}} Hoc Power, Observed Power, a Priori Power, Retrospective Power, Prospective Power, Achieved Power: {{Sorting}} out Appropriate Uses of Statistical Power Analyses},
  shorttitle = {Brief {{Report}}},
  author = {O'Keefe, Daniel J.},
  year = {2007},
  month = dec,
  journal = {Communication Methods and Measures},
  volume = {1},
  number = {4},
  pages = {291--299},
  issn = {1931-2458, 1931-2466},
  doi = {10.1080/19312450701641375},
  url = {http://www.dokeefe.net/pub/OKeefe07CMM-posthoc.pdf},
  urldate = {2020-05-16},
  langid = {english},
  file = {/Users/solomonkurz/Zotero/storage/5M3I5XMH/O'Keefe - 2007 - Brief Report Post Hoc Power, Observed Power, A Pr.pdf}
}

@article{Pedersen2020AddingAnnotation,
  title = {Adding Annotation and Style},
  author = {Pedersen, Thomas L},
  year = {2020},
  url = {https://patchwork.data-imaginist.com/articles/guides/annotation.html}
}

@article{Pedersen2020PlotAssembly,
  title = {Plot Assembly},
  author = {Pedersen, Thomas L},
  year = {2020},
  url = {https://patchwork.data-imaginist.com/articles/guides/assembly.html}
}

@misc{pedersenDrawPolygonsExpansion,
  title = {Draw Polygons with Expansion/Contraction and/or Rounded Corners \textemdash{} Geom\_shape},
  author = {Pedersen, Thomas Lin},
  url = {https://ggforce.data-imaginist.com/reference/geom_shape.html},
  urldate = {2020-09-11},
  abstract = {This geom is a cousin of ggplot2::geom\_polygon() with the added possibility of expanding or contracting the polygon by an absolute amount (e.g. 1 cm). Furthermore, it is possible to round the corners of the polygon, again by an absolute amount. The resulting geom reacts to resizing of the plot, so the expansion/contraction and corner radius will not get distorted. If no expansion/contraction or corner radius is specified, the geom falls back to geom\_polygon so there is no performance penality in using this instead of geom\_polygon.},
  langid = {english},
  file = {/Users/solomonkurz/Zotero/storage/MMJ6P7YD/geom_shape.html}
}

@article{pekReportingEffectSizes2018,
  title = {Reporting Effect Sizes in Original Psychological Research: {{A}} Discussion and Tutorial},
  author = {Pek, Jolynn and Flora, David B},
  year = {2018},
  journal = {Psychological Methods},
  volume = {23},
  number = {2},
  pages = {208},
  publisher = {{American Psychological Association}},
  doi = {https://doi.apa.org/fulltext/2017-10871-001.html}
}

@book{pengProgrammingDataScience2019,
  title = {R Programming for Data Science},
  author = {Peng, Roger D.},
  year = {2019},
  url = {https://bookdown.org/rdpeng/rprogdatascience/}
}

@article{piironenSparsityInformationRegularization2017,
  title = {Sparsity Information and Regularization in the Horseshoe and Other Shrinkage Priors},
  author = {Piironen, Juho and Vehtari, Aki},
  year = {2017},
  journal = {Electronic Journal of Statistics},
  volume = {11},
  number = {2},
  pages = {5018--5051},
  publisher = {{The Institute of Mathematical Statistics and the Bernoulli Society}},
  issn = {1935-7524},
  doi = {10.1214/17-EJS1337SI},
  url = {https://projecteuclid.org/euclid.ejs/1513306866},
  urldate = {2020-05-16},
  abstract = {The horseshoe prior has proven to be a noteworthy alternative for sparse Bayesian estimation, but has previously suffered from two problems. First, there has been no systematic way of specifying a prior for the global shrinkage hyperparameter based on the prior information about the degree of sparsity in the parameter vector. Second, the horseshoe prior has the undesired property that there is no possibility of specifying separately information about sparsity and the amount of regularization for the largest coefficients, which can be problematic with weakly identified parameters, such as the logistic regression coefficients in the case of data separation. This paper proposes solutions to both of these problems. We introduce a concept of effective number of nonzero parameters, show an intuitive way of formulating the prior for the global hyperparameter based on the sparsity assumptions, and argue that the previous default choices are dubious based on their tendency to favor solutions with more unshrunk parameters than we typically expect a priori. Moreover, we introduce a generalization to the horseshoe prior, called the regularized horseshoe, that allows us to specify a minimum level of regularization to the largest values. We show that the new prior can be considered as the continuous counterpart of the spike-and-slab prior with a finite slab width, whereas the original horseshoe resembles the spike-and-slab with an infinitely wide slab. Numerical experiments on synthetic and real world data illustrate the benefit of both of these theoretical advances.},
  langid = {english},
  mrnumber = {MR3738204},
  zmnumber = {06825039},
  keywords = {Bayesian inference,horseshoe prior,shrinkage priors,sparse estimation},
  file = {/Users/solomonkurz/Zotero/storage/3JJ5T858/Piironen and Vehtari - 2017 - Sparsity information and regularization in the hor.pdf;/Users/solomonkurz/Zotero/storage/SX6KLCX7/1513306866.html}
}

@article{plummerCODA2006,
  title = {{{CODA}}: {{Convergence}} Diagnosis and Output Analysis for {{MCMC}}},
  author = {Plummer, Martyn and Best, Nicky and Cowles, Kate and Vines, Karen},
  year = {2006},
  journal = {R News},
  volume = {6},
  number = {1},
  pages = {7--11},
  url = {https://journal.r-project.org/archive/},
  pdf = {https://www.r-project.org/doc/Rnews/Rnews{$_2$}006-1.pdf}
}

@book{R-base,
  title = {R: {{A}} Language and Environment for Statistical Computing},
  author = {{R Core Team}},
  year = {2020},
  publisher = {{R Foundation for Statistical Computing}},
  address = {{Vienna, Austria}},
  url = {https://www.R-project.org/}
}

@book{R-bayesplot,
  title = {{{bayesplot}}: {{Plotting}} for {{Bayesian}} Models},
  author = {Gabry, Jonah and Mahr, Tristan},
  year = {2021},
  url = {https://CRAN.R-project.org/package=bayesplot}
}

@book{R-beyonce,
  title = {{{beyonce}}: {{Beyonc\'e}} Colour Palettes for {{R}}},
  author = {Miller, David Lawrence},
  year = {2017},
  url = {https://github.com/dill/beyonce}
}

@book{R-blavaan,
  title = {{{blavaan}}: {{Bayesian}} Latent Variable Analysis},
  author = {Merkle, Edgar C. and Rosseel, Yves and Goodrich, Ben},
  year = {2020},
  url = {https://CRAN.R-project.org/package=blavaan}
}

@book{R-bookdown,
  title = {{{bookdown}}: {{Authoring}} Books and Technical Documents with {{R Markdown}}},
  author = {Xie, Yihui},
  year = {2020},
  url = {https://CRAN.R-project.org/package=bookdown}
}

@book{R-brms,
  title = {{{brms}}: {{Bayesian}} Regression Models Using '{{Stan}}'},
  author = {B{\"u}rkner, Paul-Christian},
  year = {2020},
  url = {https://CRAN.R-project.org/package=brms}
}

@manual{R-coda,
  type = {Manual},
  title = {{{coda}}: {{Output}} Analysis and Diagnostics for {{MCMC}}},
  author = {Plummer, Martyn and Best, Nicky and Cowles, Kate and Vines, Karen and Sarkar, Deepayan and Bates, Douglas and Almond, Russell and Magnusson, Arni},
  year = {2020},
  url = {https://CRAN.R-project.org/package=coda}
}

@manual{R-colorblindr,
  type = {Manual},
  title = {{{colorblindr}}: {{Simulate}} Colorblindness in {{R}} Figures},
  author = {McWhite, Claire D. and Wilke, Claus O.},
  year = {2021},
  url = {https://github.com/clauswilke/colorblindr}
}

@manual{R-cowplot,
  type = {Manual},
  title = {{{cowplot}}: {{Streamlined}} Plot Theme and Plot Annotations for 'Ggplot2'},
  author = {Wilke, Claus O.},
  year = {2020},
  url = {https://wilkelab.org/cowplot}
}

@manual{R-cowplot,
  type = {Manual},
  title = {{{cowplot}}: {{Streamlined}} Plot Theme and Plot Annotations for {{ggplot2}}},
  author = {Wilke, Claus O.},
  year = {2020},
  url = {https://wilkelab.org/cowplot/}
}

@book{R-cubelyr,
  title = {{{cubelyr}}: {{A}} Data Cube 'dplyr' Backend},
  author = {Wickham, Hadley},
  year = {2020},
  url = {https://CRAN.R-project.org/package=cubelyr}
}

@manual{R-directlabels,
  type = {Manual},
  title = {Directlabels: {{Direct}} Labels for Multicolor Plots},
  author = {Hocking, Toby Dylan},
  year = {2021},
  url = {https://CRAN.R-project.org/package=directlabels}
}

@book{R-dplyr,
  title = {{{dplyr}}: {{A}} Grammar of Data Manipulation},
  author = {Wickham, Hadley and Fran{\c c}ois, Romain and Henry, Lionel and M{\"u}ller, Kirill},
  year = {2020},
  url = {https://CRAN.R-project.org/package=dplyr}
}

@manual{R-fishualize,
  type = {Manual},
  title = {{{fishualize}}: {{Color}} Palettes Based on Fish Species},
  author = {Schiettekatte, Nina M. D. and Brandl, Simon J. and Casey, Jordan M.},
  year = {2021},
  url = {https://CRAN.R-project.org/package=fishualize}
}

@book{R-forcats,
  title = {{{forcats}}: {{Tools}} for Working with Categorical Variables (Factors)},
  author = {Wickham, Hadley},
  year = {2020},
  url = {https://CRAN.R-project.org/package=forcats}
}

@book{R-GGally,
  title = {{{GGally}}: {{Extension}} to {{'ggplot2'}}},
  author = {Schloerke, Barret and Crowley, Jason and {Di Cook} and Briatte, Francois and Marbach, Moritz and Thoen, Edwin and Elberg, Amos and Larmarange, Joseph},
  year = {2021},
  url = {https://CRAN.R-project.org/package=GGally}
}

@book{R-ggExtra,
  title = {{{ ggExtra}}: {{Add}} Marginal Histograms to '{{ggplot2}}', and More '{{ggplot2}}' Enhancements},
  author = {Attali, Dean and Baker, Christopher},
  year = {2019},
  url = {https://CRAN.R-project.org/package=ggExtra}
}

@manual{R-ggforce,
  type = {Manual},
  title = {{{ggforce}}: {{Accelerating}} '{{ggplot2}}'},
  author = {Pedersen, Thomas Lin},
  year = {2021},
  url = {https://CRAN.R-project.org/package=ggforce}
}

@manual{R-ggmcmc,
  type = {Manual},
  title = {{{ggmcmc}}: {{Tools}} for Analyzing {{MCMC}} Simulations from {{Bayesian}} Inference},
  author = {{Fern{\'a}ndez i Mar{\'i}n}, Xavier},
  year = {2020},
  url = {https://CRAN.R-project.org/package=ggmcmc}
}

@book{R-ggplot2,
  title = {{{ggplot2}}: {{Create}} Elegant Data Visualisations Using the Grammar of Graphics},
  author = {Wickham, Hadley and Chang, Winston and Henry, Lionel and Pedersen, Thomas Lin and Takahashi, Kohske and Wilke, Claus and Woo, Kara and Yutani, Hiroaki and Dunnington, Dewey},
  year = {2020},
  url = {https://CRAN.R-project.org/package=ggplot2}
}

@book{R-ggridges,
  title = {{{ggridges}}: {{Ridgeline Plots}} in '{{ggplot2}}'},
  author = {Wilke, Claus O.},
  year = {2021},
  url = {https://CRAN.R-project.org/package=ggridges}
}

@book{R-ggthemes,
  title = {{{ggthemes}}: {{Extra}} Themes, Scales and Geoms for {{'ggplot2'}}},
  author = {Arnold, Jeffrey B.},
  year = {2021},
  url = {https://CRAN.R-project.org/package=ggthemes}
}

@book{R-gridExtra,
  title = {{{gridExtra}}: {{Miscellaneous}} Functions for "Grid" Graphics},
  author = {Auguie, Baptiste},
  year = {2017},
  url = {https://CRAN.R-project.org/package=gridExtra}
}

@book{R-janitor,
  title = {{{janitor}}: {{Simple}} Tools for Examining and Cleaning Dirty Data},
  author = {Firke, Sam},
  year = {2020},
  url = {https://CRAN.R-project.org/package=janitor}
}

@manual{R-lisa,
  type = {Manual},
  title = {{{lisa}}: {{Color}} Palettes from Color Lisa},
  author = {Littlefield, Tyler},
  year = {2020},
  url = {https://CRAN.R-project.org/package=lisa}
}

@book{R-lme4,
  title = {{{lme4}}: {{Linear}} Mixed-Effects Models Using {{Eigen}}' and {{S4}}},
  author = {Bates, Douglas and Maechler, Martin and Bolker, Ben and Walker, Steven},
  year = {2020},
  url = {https://CRAN.R-project.org/package=lme4}
}

@book{R-MASS,
  title = {{{MASS}}: {{Support}} Functions and Datasets for Venables and Ripley's {{MASS}}},
  author = {Ripley, Brian},
  year = {2019},
  url = {https://CRAN.R-project.org/package=MASS}
}

@book{R-metRology,
  title = {{{metRology}}: {{Support}} for Metrological Applications},
  author = {Ellison., Stephen L R},
  year = {2018},
  url = {https://CRAN.R-project.org/package=metRology}
}

@manual{R-ochRe,
  type = {Manual},
  title = {{{ochRe}}: {{Australia-themed}} Colour Palettes},
  author = {Allan, Alicia and Cook, Di and Gayler, Ross and Kirk, Holly and Peng, Roger and Saber, Elle},
  year = {2017},
  url = {https://github.com/ropenscilabs/ochRe}
}

@manual{R-palettetown,
  type = {Manual},
  title = {{{palettetown}}: {{Use Pokemon}} Inspired Colour Palettes},
  author = {Lucas, Tim},
  year = {2016},
  url = {https://CRAN.R-project.org/package=palettetown}
}

@book{R-patchwork,
  title = {{{patchwork}}: {{The}} Composer of Plots},
  author = {Pedersen, Thomas Lin},
  year = {2019},
  url = {https://CRAN.R-project.org/package=patchwork}
}

@manual{R-PNWColors,
  type = {Manual},
  title = {{{PNWColors}}: {{Color}} Palettes Inspired by Nature in the {{US Pacific Northwest}}},
  author = {Lawlor, Jake},
  year = {2020},
  url = {https://CRAN.R-project.org/package=PNWColors}
}

@manual{R-posterior,
  type = {Manual},
  title = {{{posterior}}: {{Tools}} for Working with Posterior Distributions},
  author = {B{\"u}rkner, Paul-Christian and Gabry, Jonah and Kay, Matthew and Vehtari, Aki},
  year = {2021}
}

@book{R-psych,
  title = {{{psych}}: {{Procedures}} for Psychological, Psychometric, and Personality Research},
  author = {Revelle, William},
  year = {2021},
  url = {https://CRAN.R-project.org/package=psych}
}

@book{R-purrr,
  title = {{{purrr}}: {{Functional}} Programming Tools},
  author = {Henry, Lionel and Wickham, Hadley},
  year = {2020},
  url = {https://CRAN.R-project.org/package=purrr}
}

@book{R-readr,
  title = {{{readr}}: {{Read}} Rectangular Text Data},
  author = {Wickham, Hadley and Hester, Jim and Francois, Romain},
  year = {2018},
  url = {https://CRAN.R-project.org/package=readr}
}

@book{R-reshape2,
  title = {{{reshape2}}: {{Flexibly}} Reshape Data: {{A}} Reboot of the Reshape Package},
  author = {Wickham, Hadley},
  year = {2020},
  url = {https://CRAN.R-project.org/package=reshape2}
}

@book{R-santoku,
  title = {{{santoku}}: {{A}} Versatile Cutting Tool},
  author = {{Hugh-Jones}, David},
  year = {2020},
  url = {https://CRAN.R-project.org/package=santoku}
}

@manual{R-scico,
  type = {Manual},
  title = {{{scico}}: {{Colour}} Palettes Based on the Scientific Colour-Maps},
  author = {Pedersen, Thomas Lin and Crameri, Fabio},
  year = {2020},
  url = {https://CRAN.R-project.org/package=scico}
}

@book{R-stringr,
  title = {{{stringr}}: {{Simple}}, Consistent Wrappers for Common String Operations},
  author = {Wickham, Hadley},
  year = {2019},
  url = {https://CRAN.R-project.org/package=stringr}
}

@book{R-tibble,
  title = {{{tibble}}: {{Simple}} Data Frames},
  author = {M{\"u}ller, Kirill and Wickham, Hadley},
  year = {2020},
  url = {https://CRAN.R-project.org/package=tibble}
}

@book{R-tidybayes,
  title = {{{tidybayes}}: {{Tidy}} Data and 'geoms' for {{Bayesian}} Models},
  author = {Kay, Matthew},
  year = {2020},
  url = {https://mjskay.github.io/tidybayes/}
}

@book{R-tidyr,
  title = {{{tidyr}}: {{Tidy}} Messy Data},
  author = {Wickham, Hadley and Henry, Lionel},
  year = {2020},
  url = {https://CRAN.R-project.org/package=tidyr}
}

@book{R-tidyverse,
  title = {{{tidyverse}}: {{Easily}} Install and Load the 'Tidyverse'},
  author = {Wickham, Hadley},
  year = {2019},
  url = {https://CRAN.R-project.org/package=tidyverse}
}

@manual{R-viridis,
  type = {Manual},
  title = {{{viridis}}: {{Default}} Color Maps from 'Matplotlib'},
  author = {Garnier, Simon},
  year = {2021},
  url = {https://CRAN.R-project.org/package=viridis}
}

@article{rosaCloseLookTherapeutic1998,
  title = {A Close Look at Therapeutic Touch},
  author = {Rosa, Linda and Rosa, Emily and Sarner, Larry and Barrett, Stephen},
  year = {1998},
  journal = {JAMA},
  volume = {279},
  number = {13},
  pages = {1005--1010},
  publisher = {{American Medical Association}},
  doi = {10.1001/jama.279.13.1005}
}

@article{rouderDefaultBayesFactors2012,
  title = {Default {{Bayes}} Factors for {{ANOVA}} Designs},
  author = {Rouder, Jeffrey N. and Morey, Richard D. and Speckman, Paul L. and Province, Jordan M.},
  year = {2012},
  month = oct,
  journal = {Journal of Mathematical Psychology},
  volume = {56},
  number = {5},
  pages = {356--374},
  issn = {0022-2496},
  doi = {10.1016/j.jmp.2012.08.001},
  url = {http://pcl.missouri.edu/sites/default/files/Rouder.JMP_.2012.pdf},
  urldate = {2020-05-18},
  abstract = {Bayes factors have been advocated as superior to p-values for assessing statistical evidence in data. Despite the advantages of Bayes factors and the drawbacks of p-values, inference by p-values is still nearly ubiquitous. One impediment to the adoption of Bayes factors is a lack of practical development, particularly a lack of ready-to-use formulas and algorithms. In this paper, we discuss and expand a set of default Bayes factor tests for ANOVA designs. These tests are based on multivariate generalizations of Cauchy priors on standardized effects, and have the desirable properties of being invariant with respect to linear transformations of measurement units. Moreover, these Bayes factors are computationally convenient, and straightforward sampling algorithms are provided. We cover models with fixed, random, and mixed effects, including random interactions, and do so for within-subject, between-subject, and mixed designs. We extend the discussion to regression models with continuous covariates. We also discuss how these Bayes factors may be applied in nonlinear settings, and show how they are useful in differentiating between the power law and the exponential law of skill acquisition. In sum, the current development makes the computation of Bayes factors straightforward for the vast majority of designs in experimental psychology.},
  langid = {english},
  keywords = {Bayes factor,Bayesian statistics,Linear models,Model selection},
  file = {/Users/solomonkurz/Zotero/storage/2MM7ERU8/S0022249612000806.html}
}

@article{rouderWhatWhyHow2016,
  title = {The What, Why, and How of Born-Open Data},
  author = {Rouder, Jeffrey N.},
  year = {2016},
  month = sep,
  journal = {Behavior Research Methods},
  volume = {48},
  number = {3},
  pages = {1062--1069},
  issn = {1554-3528},
  doi = {10.3758/s13428-015-0630-z},
  url = {https://link.springer.com/content/pdf/10.3758/s13428-015-0630-z.pdf},
  urldate = {2020-05-18},
  abstract = {Although many researchers agree that scientific data should be open to scrutiny to ferret out poor analyses and outright fraud, most raw data sets are not available on demand. There are many reasons researchers do not open their data, and one is technical. It is often time consuming to prepare and archive data. In response, my laboratory has automated the process such that our data are archived the night they are created without any human approval or action. All data are versioned, logged, time stamped, and uploaded including aborted runs and data from pilot subjects. The archive is GitHub, github.com, the world's largest collection of open-source materials. Data archived in this manner are called born open. In this paper, I discuss the benefits of born-open data and provide a brief technical overview of the process. I also address some of the common concerns about opening data before publication.},
  langid = {english},
  file = {/Users/solomonkurz/Zotero/storage/T89ALUJW/Rouder - 2016 - The what, why, and how of born-open data.pdf}
}

@book{RStudio,
  title = {{{RStudio}}: {{Integrated}} Development Environment for {{R}}},
  author = {{RStudio Team}},
  year = {2020},
  publisher = {{RStudio, Inc.}},
  address = {{Boston, MA}},
  url = {http://www.rstudio.com/}
}

@article{shapiroSexualActivityLifespan1994,
  title = {Sexual Activity and the Lifespan of Male Fruitflies: {{A}} Dataset That Gets Attention},
  shorttitle = {Sexual {{Activity}} and the {{Lifespan}} of {{Male Fruitflies}}},
  author = {Shapiro, H, Stanley},
  year = {1994},
  month = jul,
  journal = {Journal of Statistics Education},
  volume = {2},
  number = {1},
  pages = {null},
  publisher = {{Taylor \& Francis}},
  issn = {null},
  doi = {10.1080/10691898.1994.11910467},
  url = {https://doi.org/10.1080/10691898.1994.11910467},
  urldate = {2020-05-17},
  abstract = {This dataset contains observations on five groups of male fruitflies \textendash\textendash{} 25 fruitflies in each group \textendash\textendash{} from an experiment designed to test if increased reproduction reduces longevity for male fruitflies. (Such a cost has already been established for females.) The five groups are: males forced to live alone, males assigned to live with one or eight interested females, and males assigned to live with one or eight non-receptive females. The observations on each fly were longevity, thorax length, and the percentage of each day spent sleeping. The structure of the experiment provokes lively discussion on experimental design and on contrasts, and gives students opportunities to understand and verbalize what we mean by the term ``statistical interaction.'' Because the variable thorax length has a strong effect on survival, it is important to take it into account to increase the precision of between-group contrasts, even though it is distributed similarly across groups. The dataset can also be used to illustrate techniques of survival analysis.},
  keywords = {Analysis of covariance,Experiment,Longevity,Precision,Regression,Survival analysis},
  annotation = {\_eprint: https://doi.org/10.1080/10691898.1994.11910467},
  file = {/Users/solomonkurz/Zotero/storage/9J3933SB/A and H - 1994 - Sexual Activity and the Lifespan of Male Fruitflie.pdf;/Users/solomonkurz/Zotero/storage/HIZI77AL/10691898.1994.html}
}

@article{skinnerCaseHistoryScientific1956,
  title = {A Case History in Scientific Method},
  author = {Skinner, B. F.},
  year = {1956},
  journal = {American Psychologist},
  volume = {11},
  number = {5},
  pages = {221--233},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1935-990X(Electronic),0003-066X(Print)},
  doi = {10.1037/h0047662},
  url = {https://pdfs.semanticscholar.org/a113/55f49947e4c77659ec9fa5c6b69bd7798194.pdf},
  abstract = {The case history in scientific method cited is autobiographical; Skinner relates certain relevant experiences in the development of some of his scientific contributions. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Experimental Methods,Experimentation,Scientific Communication},
  file = {/Users/solomonkurz/Zotero/storage/BZJKX54K/1957-05288-001.html}
}

@article{sneeGraphicalDisplayTwoway1974,
  title = {Graphical Display of Two-Way Contingency Tables},
  author = {Snee, Ronald D},
  year = {1974},
  journal = {The American Statistician},
  volume = {28},
  number = {1},
  pages = {9--12},
  publisher = {{Taylor \& Francis}},
  doi = {10.1080/00031305.1974.10479053},
  url = {https://www.researchgate.net/profile/Ron_Snee/publication/243769696_Graphical_Display_of_Two-Way_Contingency_Tables/links/580b7ab908aecba93500ce16/Graphical-Display-of-Two-Way-Contingency-Tables.pdf}
}

@misc{standevelopmentteamAccessingContentsStanfit2020,
  title = {Accessing the Contents of a Stanfit Object},
  author = {{Stan Development Team}},
  year = {2020},
  month = feb,
  url = {https://CRAN.R-project.org/package=rstan/vignettes/stanfit-objects.html},
  urldate = {2020-05-15},
  file = {/Users/solomonkurz/Zotero/storage/RKEPKHUF/stanfit-objects.html}
}

@book{standevelopmentteamStanReferenceManual2021,
  title = {Stan Reference Manual, {{Version}} 2.27},
  author = {{Stan Development Team}},
  year = {2021},
  url = {https://mc-stan.org/docs/2_27/reference-manual/}
}

@book{standevelopmentteamStanUserGuide2021,
  title = {Stan User's Guide, {{Version}} 2.26},
  author = {{Stan Development Team}},
  year = {2021},
  url = {https://mc-stan.org/docs/2_26/stan-users-guide/index.html}
}

@article{steidlStatisticalPowerAnalysis1997,
  title = {Statistical Power Analysis in Wildlife Research},
  author = {Steidl, Robert J. and Hayes, John P. and Schauber, Eric},
  year = {1997},
  month = apr,
  journal = {The Journal of Wildlife Management},
  volume = {61},
  number = {2},
  pages = {270},
  issn = {0022541X},
  doi = {10.2307/3802582},
  url = {https://cals.arizona.edu/~steidl/files/pdfs/Steidl%20et%20al.%201997%20JWM.pdf},
  urldate = {2020-05-16},
  abstract = {Statistical power analysis can be used to increase the efficiency of research efforts and to clarify research results. Power analysis is most valuable in the design or planning phases of research efforts. Such prospective (a priori) power analyses can be used to guide research design and to estimate the number of samples necessary to achieve a high probability of detecting biologically significant effects. Retrospective (a posteriori) power analysis has been advocated as a method to increase information about hypothesis tests that were not rejected. However, estimating power for tests of null hypotheses that were not rejected with the effect size observed in the study is incorrect; these power estimates will always be 50.50 when bias adjusted and have no relation to true power. Therefore, retrospective power estimates based on the observed effect size for hypothesis tests that were not rejected are misleading; retrospective power estimates are only meaningful when based on effect sizes other than the observed effect size, such as those effect sizes hypothesized to be biologcally significant. Retrospective power analysis can be used effectively to estimate the number of samples or effect size that would have been necessary for a completed study to have rejected a specific null hypothesis. Simply presenting confidence intervals can provide addtional information about null hypotheses that were not rejected, including information about the size of the true effect and whether or not there is adequate evidence to "accept" a null hypothesis as true. We suggest that (1)statistical power analyses be routinely incorporated into research planning efforts to increase their efficiency, (2) confidence intervals be used in lieu of retrospective power analyses for null hypotheses that were not rejected to assess the likely size of the true effect, (3) minimum biologically significant effect sizes be used for all power analyses, and (4) if retrospective power estimates are to be reported, then the a-level, effect sizes, and sample sizes used in calculations must also be reported.},
  langid = {english},
  file = {/Users/solomonkurz/Zotero/storage/IHA6SZFZ/Steidl et al. - 1997 - Statistical Power Analysis in Wildlife Research.pdf}
}

@article{sunRethinkingObservedPower2011,
  title = {Rethinking Observed Power: {{Concept}}, Practice, and Implications},
  shorttitle = {Rethinking {{Observed Power}}},
  author = {Sun, Shuyan and Pan, Wei and Wang, Lihshing Leigh},
  year = {2011},
  month = jan,
  journal = {Methodology},
  volume = {7},
  number = {3},
  pages = {81--87},
  issn = {1614-1881, 1614-2241},
  doi = {10.1027/1614-2241/a000025},
  url = {https://www.researchgate.net/profile/Shuyan_Sun2/publication/232499536_Rethinking_Observed_Power_Concept_Practice_and_Implications/links/5623f87708aea35f26868b78/Rethinking-Observed-Power-Concept-Practice-and-Implications.pdf},
  urldate = {2020-05-16},
  abstract = {Observed power analysis is recommended by many scholarly journal editors and reviewers, especially for studies with statistically nonsignificant test results. However, researchers may not fully realize that blind observance of this recommendation could lead to an unfruitful effort, despite the repeated warnings from methodologists. Through both a review of 14 published empirical studies and a Monte Carlo simulation study, the present study demonstrates that observed power is usually not as informative or helpful as we think because (a) observed power for a nonsignificant test is generally low and, therefore, does not provide additional information to the test; and (b) a low observed power does not always indicate that the test is underpowered. Implications and suggestions of statistical power analysis for quantitative researchers are discussed.},
  langid = {english},
  file = {/Users/solomonkurz/Zotero/storage/G35IZV26/Sun et al. - 2011 - Rethinking Observed Power Concept, Practice, and .pdf}
}

@article{thomasRetrospectivePowerAnalysis1997,
  title = {Retrospective Power Analysis},
  author = {Thomas, Len},
  year = {1997},
  month = feb,
  journal = {Conservation Biology},
  volume = {11},
  number = {1},
  pages = {276--280},
  issn = {0888-8892, 1523-1739},
  doi = {10.1046/j.1523-1739.1997.96102.x},
  url = {https://research-repository.st-andrews.ac.uk/bitstream/handle/10023/679/Thomas-Retrospectivepoweranalysis-postprint.pdf?sequence=5},
  urldate = {2020-05-16},
  langid = {english},
  file = {/Users/solomonkurz/Zotero/storage/X4DNELP7/Thomas - 1997 - Retrospective Power Analysis.pdf}
}

@article{vanpaemelPriorSensitivityTheory2010,
  title = {Prior Sensitivity in Theory Testing: {{An}} Apologia for the {{Bayes}} Factor},
  author = {Vanpaemel, Wolf},
  year = {2010},
  journal = {Journal of Mathematical Psychology},
  volume = {54},
  number = {6},
  pages = {491--498},
  publisher = {{Elsevier}},
  doi = {10.1016/j.jmp.2010.07.003},
  url = {https://ppw.kuleuven.be/okp/_pdf/Vanpaemel2010PSITT.pdf}
}

@misc{vehtariBayesianStackingPseudoBMA,
  title = {Bayesian Stacking and Pseudo-{{BMA}} Weights Using the Loo Package},
  author = {Vehtari, Aki and Gabry, Jonah},
  year = {2019},
  month = dec,
  url = {https://CRAN.R-project.org/package=loo/vignettes/loo2-weights.html}
}

@article{vehtariLimitationsLimitationsBayesian2019,
  title = {Limitations of ``{{Limitations}} of {{Bayesian}} Leave-One-out Cross-Validation for Model Selection''},
  author = {Vehtari, Aki and Simpson, Daniel P and Yao, Yuling and Gelman, Andrew},
  year = {2019},
  journal = {Computational Brain \& Behavior},
  volume = {2},
  number = {1},
  pages = {22--27},
  publisher = {{Springer}},
  url = {https://doi.org/10.1007/s42113-018-0020-6}
}

@article{vehtariRanknormalizationFoldingLocalization2019,
  title = {Rank-Normalization, Folding, and Localization: {{An}} Improved $\widehat{R}$ for Assessing Convergence of {{MCMC}}},
  author = {Vehtari, Aki and Gelman, Andrew and Simpson, Daniel and Carpenter, Bob and B{\"u}rkner, Paul-Christian},
  year = {2019},
  journal = {arXiv preprint arXiv:1903.08008},
  eprint = {1903.08008},
  eprinttype = {arxiv},
  url = {https://arxiv.org/abs/1903.08008?},
  archiveprefix = {arXiv}
}

@misc{vehtariUsingLooPackage2020,
  title = {Using the Loo Package (Version {$>$}= 2.0.0)},
  author = {Vehtari, Aki and Gabry, Jonah},
  year = {2020},
  month = jul,
  url = {https://CRAN.R-project.org/package=loo/vignettes/loo2-example.html},
  urldate = {2020-09-15},
  file = {/Users/solomonkurz/Zotero/storage/QQ6SLVSV/loo2-example.html}
}

@article{wagenmakers2007practical,
  title = {A Practical Solution to the Pervasive Problems of {\emph{p}} Values},
  author = {Wagenmakers, Eric-Jan},
  year = {2007},
  journal = {Psychonomic bulletin \& review},
  volume = {14},
  number = {5},
  pages = {779--804},
  publisher = {{Springer}},
  url = {https://doi.org/10.3758/BF03194105}
}

@article{wagenmakersBayesianHypothesisTesting2010,
  title = {Bayesian Hypothesis Testing for Psychologists: {{A}} Tutorial on the {{Savage}}\textendash{{Dickey}} Method},
  shorttitle = {Bayesian Hypothesis Testing for Psychologists},
  author = {Wagenmakers, Eric-Jan and Lodewyckx, Tom and Kuriyal, Himanshu and Grasman, Raoul},
  year = {2010},
  month = may,
  journal = {Cognitive Psychology},
  volume = {60},
  number = {3},
  pages = {158--189},
  issn = {00100285},
  doi = {10.1016/j.cogpsych.2009.12.001},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0010028509000826},
  urldate = {2020-05-16},
  abstract = {In the field of cognitive psychology, the p-value hypothesis test has established a stranglehold on statistical reporting. This is unfortunate, as the p-value provides at best a rough estimate of the evidence that the data provide for the presence of an experimental effect. An alternative and arguably more appropriate measure of evidence is conveyed by a Bayesian hypothesis test, which prefers the model with the highest average likelihood. One of the main problems with this Bayesian hypothesis test, however, is that it often requires relatively sophisticated numerical methods for its computation. Here we draw attention to the Savage\textendash Dickey density ratio method, a method that can be used to compute the result of a Bayesian hypothesis test for nested models and under certain plausible restrictions on the parameter priors. Practical examples demonstrate the method's validity, generality, and flexibility.},
  langid = {english},
  file = {/Users/solomonkurz/Zotero/storage/USW25SKW/Wagenmakers et al. - 2010 - Bayesian hypothesis testing for psychologists A t.pdf}
}

@article{wetzelsDefaultBayesianHypothesis2012,
  title = {A Default {{Bayesian}} Hypothesis Test for {{ANOVA}} Designs},
  author = {Wetzels, Ruud and Grasman, Raoul P. P. P. and Wagenmakers, Eric-Jan},
  year = {2012},
  month = may,
  journal = {The American Statistician},
  volume = {66},
  number = {2},
  pages = {104--111},
  publisher = {{Taylor \& Francis}},
  issn = {0003-1305},
  doi = {10.1080/00031305.2012.695956},
  url = {https://www.ejwagenmakers.com/2012/WetzelsEtAl2012AmStat.pdf},
  urldate = {2020-05-18},
  abstract = {This article presents a Bayesian hypothesis test for analysis of variance (ANOVA) designs. The test is an application of standard Bayesian methods for variable selection in regression models. We illustrate the effect of various g-priors on the ANOVA hypothesis test. The Bayesian test for ANOVA designs is useful for empirical researchers and for students; both groups will get a more acute appreciation of Bayesian inference when they can apply it to practical statistical problems such as ANOVA. We illustrate the use of the test with two examples, and we provide R code that makes the test easy to use.},
  keywords = {Bayes factor,Model selection,Teaching Bayesian statistics},
  annotation = {\_eprint: https://doi.org/10.1080/00031305.2012.695956},
  file = {/Users/solomonkurz/Zotero/storage/K9KJAT77/00031305.2012.html}
}

@article{wetzelsStatisticalEvidenceExperimental2011,
  title = {Statistical Evidence in Experimental Psychology: {{An}} Empirical Comparison Using 855 {\emph{t}} Tests},
  author = {Wetzels, Ruud and Matzke, Dora and Lee, Michael D and Rouder, Jeffrey N and Iverson, Geoffrey J and Wagenmakers, Eric-Jan},
  year = {2011},
  journal = {Perspectives on Psychological Science},
  volume = {6},
  number = {3},
  pages = {291--298},
  publisher = {{Sage Publications Sage CA: Los Angeles, CA}},
  doi = {10.1177/1745691611406923},
  url = {https://pdfs.semanticscholar.org/1874/4e6c84087ccc20bc0f6db28020bc48c81b4a.pdf}
}

@book{wickhamGgplot2ElegantGraphics2016,
  title = {{{ggplot2}}: {{Elegant}} Graphics for Data Analysis},
  author = {Wickham, Hadley},
  year = {2016},
  publisher = {{Springer-Verlag New York}},
  url = {https://ggplot2-book.org/},
  isbn = {978-3-319-24277-4}
}

@article{wickhamReshapingDataReshape2007,
  title = {Reshaping Data with the Reshape Package},
  author = {Wickham, Hadley},
  year = {2007},
  journal = {Journal of Statistical Software},
  volume = {21},
  number = {12},
  pages = {1--20},
  url = {https://doi.org/10.18637/jss.v021.i12}
}

@article{wickhamTidyData2014,
  title = {Tidy Data},
  author = {Wickham, Hadley},
  year = {2014},
  journal = {Journal of Statistical Software},
  volume = {59},
  number = {10},
  issn = {1548-7660},
  doi = {10.18637/jss.v059.i10},
  url = {http://www.jstatsoft.org/v59/i10/},
  urldate = {2020-05-17},
  langid = {english},
  file = {/Users/solomonkurz/Zotero/storage/56ARBADN/Wickham - 2014 - Tidy Data.pdf}
}

@book{wickhamTidyverseStyleGuide2020,
  title = {The Tidyverse Style Guide},
  author = {Wickham, Hadley},
  year = {2020},
  url = {https://style.tidyverse.org/}
}

@article{wickhamWelcomeTidyverse2019,
  title = {Welcome to the Tidyverse},
  author = {Wickham, Hadley and Averick, Mara and Bryan, Jennifer and Chang, Winston and McGowan, Lucy D'Agostino and Fran{\c c}ois, Romain and Grolemund, Garrett and Hayes, Alex and Henry, Lionel and Hester, Jim and Kuhn, Max and Pedersen, Thomas Lin and Miller, Evan and Bache, Stephan Milton and M{\"u}ller, Kirill and Ooms, Jeroen and Robinson, David and Seidel, Dana Paige and Spinu, Vitalie and Takahashi, Kohske and Vaughan, Davis and Wilke, Claus and Woo, Kara and Yutani, Hiroaki},
  year = {2019},
  journal = {Journal of Open Source Software},
  volume = {4},
  number = {43},
  pages = {1686},
  doi = {10.21105/joss.01686}
}

@article{Wilke2019Themes,
  title = {Themes},
  author = {Wilke, Claus O.},
  year = {2019},
  month = jul,
  url = {https://wilkelab.org/cowplot/articles/themes.html}
}

@book{wilkeFundamentalsDataVisualization2019,
  title = {Fundamentals of Data Visualization},
  author = {Wilke, Claus O.},
  year = {2019},
  url = {https://clauswilke.com/dataviz/},
  urldate = {2020-08-24},
  abstract = {A guide to making visualizations that accurately reflect the data, tell a story, and look professional.},
  file = {/Users/solomonkurz/Zotero/storage/URYRTXWA/dataviz.html}
}

@techreport{williamsBayesianMultivariateMixedeffects2019,
  type = {Preprint},
  title = {Bayesian Multivariate Mixed-Effects Location Scale Modeling of Longitudinal Relations among Affective Traits, States, and Physical Activity},
  author = {Williams, Donald R. and Liu, Siwei and Martin, Stephen Ross and Rast, Philippe},
  year = {2019},
  month = mar,
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/4kfjp},
  url = {https://osf.io/4kfjp},
  urldate = {2020-05-17},
  abstract = {Intensive longitudinal studies and experience sampling methods are becoming more common in psychology. While they provide a unique opportunity to ask novel questions about within-person processes relating to personality, there is a lack of methods specifically built to characterize the interplay between traits and states. We thus introduce a Bayesian multivariate mixed-effects location scale model (M-MELSM). The formulation can simultaneously model both personality traits (the location) and states (the scale) for multivariate data common to personality research. Variables can be included to predict either (or both) the traits and states, in addition to estimating random effects therein. This provides correlations between location and scale random effects, both across and within each outcome, which allows for characterizing relations between any number personality traits and the corresponding states. We take a \textbackslash textit\{fully\} Bayesian approach, not only to make estimation possible, but also because  it provides the necessary information for use in psychological applications such as hypothesis testing. To illustrate the model we use data from 194 individuals that provided daily ratings of negative and positive affect, as well as their psychical activity in the form of step counts over 100 consecutive days. We describe the fitted model, where we emphasize, with visualization, the richness of information provided by the M-MELSM. We demonstrate Bayesian hypothesis testing for the correlations between the random effects. We conclude by discussing limitations of the MELSM in general and extensions to the M-MELSM specifically for personality research.}
}

@article{williamsBayesianNonlinearMixedeffects2019,
  title = {A {{Bayesian}} Nonlinear Mixed-Effects Location Scale Model for Learning},
  author = {Williams, Donald R. and Zimprich, Daniel R. and Rast, Philippe},
  year = {2019},
  month = oct,
  journal = {Behavior Research Methods},
  volume = {51},
  number = {5},
  pages = {1968--1986},
  issn = {1554-3528},
  doi = {10.3758/s13428-019-01255-9},
  url = {http://link.springer.com/10.3758/s13428-019-01255-9},
  urldate = {2020-05-17},
  langid = {english}
}

@book{xieBookdownAuthoringBooks2016,
  title = {{{bookdown}}: {{Authoring}} Books and Technical Documents with {{R}} Markdown},
  author = {Xie, Yihui},
  year = {2016},
  publisher = {{Chapman and Hall/CRC}},
  url = {https://bookdown.org/yihui/bookdown/}
}

@book{xieMarkdownDefinitiveGuide2020,
  title = {R Markdown: {{The}} Definitive Guide},
  author = {Xie, Yihui and Allaire, J. J. and Grolemund, Garrett},
  year = {2020},
  publisher = {{Chapman and Hall/CRC}},
  url = {https://bookdown.org/yihui/rmarkdown/}
}

@article{yaoUsingStackingAverage2018,
  title = {Using Stacking to Average {{Bayesian}} Predictive Distributions (with Discussion)},
  author = {Yao, Yuling and Vehtari, Aki and Simpson, Daniel and Gelman, Andrew},
  year = {2018},
  journal = {Bayesian Analysis},
  volume = {13},
  number = {3},
  pages = {917--1007},
  publisher = {{International Society for Bayesian Analysis}},
  doi = {10.1214/17-BA1091},
  url = {https://projecteuclid.org/download/pdfview_1/euclid.ba/1516093227}
}

@article{zhuCounterintuitiveNoninformativePrior2004,
  title = {The Counter-Intuitive Non-Informative Prior for the {{Bernoulli}} Family},
  author = {Zhu, Mu and Lu, Arthur Y.},
  year = {2004},
  month = jan,
  journal = {Journal of Statistics Education},
  volume = {12},
  number = {2},
  pages = {3},
  issn = {1069-1898},
  doi = {10.1080/10691898.2004.11910734},
  url = {https://www.tandfonline.com/doi/full/10.1080/10691898.2004.11910734},
  urldate = {2020-05-16},
  abstract = {In Bayesian statistics, the choice of the prior distribution is often controversial. Different rules for selecting priors have been suggested in the literature, which, sometimes, produce priors that are difficult for the students to understand intuitively. In this article, we use a simple heuristic to illustrate to the students the rather counter-intuitive fact that flat priors are not necessarily non-informative; and non-informative priors are not necessarily flat.},
  langid = {english},
  file = {/Users/solomonkurz/Zotero/storage/TGQZ4HPD/Zhu and Lu - 2004 - The Counter-intuitive Non-informative Prior for th.pdf}
}

@book{ZoteroYourPersonal2020,
  title = {Zotero},
  author = {{Roy Rosenzweig Center for History and New Media}},
  year = {2020},
  url = {https://www.zotero.org/},
  urldate = {2020-05-19},
  file = {/Users/solomonkurz/Zotero/storage/SUAPYKGF/www.zotero.org.html}
}


