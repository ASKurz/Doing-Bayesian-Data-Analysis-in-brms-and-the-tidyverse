
@article{navarroDevilDeepBlue2019,
	title = {Between the devil and the deep blue sea: Tensions between scientific judgement and statistical model selection},
	volume = {2},
	issn = {2522-0861, 2522-087X},
	url = {http://link.springer.com/10.1007/s42113-018-0019-z},
	doi = {10.1007/s42113-018-0019-z},
	shorttitle = {Between the Devil and the Deep Blue Sea},
	abstract = {Discussions of model selection in the psychological literature typically frame the issues as a question of statistical inference, with the goal being to determine which model makes the best predictions about data. Within this setting, advocates of leaveone-out cross-validation and Bayes factors disagree on precisely which prediction problem model selection questions should aim to answer. In this comment, I discuss some of these issues from a scientific perspective. What goal does model selection serve when all models are known to be systematically wrong? How might “toy problems” tell a misleading story? How does the scientific goal of explanation align with (or differ from) traditional statistical concerns? I do not offer answers to these questions, but hope to highlight the reasons why psychological researchers cannot avoid asking them.},
	pages = {28--34},
	number = {1},
	journaltitle = {Computational Brain \& Behavior},
	shortjournal = {Comput Brain Behav},
	author = {Navarro, Danielle J.},
	urldate = {2020-05-15},
	date = {2019-03},
	langid = {english},
	file = {Navarro - 2019 - Between the Devil and the Deep Blue Sea Tensions .pdf:/Users/solomonkurz/Zotero/storage/3D6FMZVD/Navarro - 2019 - Between the Devil and the Deep Blue Sea Tensions .pdf:application/pdf}
}

@online{gabryGraphicalPosteriorPredictive2019,
	title = {Graphical posterior predictive checks using the bayesplot package},
	url = {https://CRAN.R-project.org/package=bayesplot/vignettes/graphical-ppcs.html},
	author = {Gabry, Jonah},
	date = {2019-11-29}
}

@online{kaySlabIntervalStats2020,
	title = {Slab + interval stats and geoms},
	url = {https://mjskay.github.io/ggdist/articles/slabinterval.html},
	abstract = {ggdist},
	author = {Kay, Matthew},
	urldate = {2020-05-15},
	date = {2020-07-14},
	langid = {english},
	note = {Library Catalog: mjskay.github.io},
	file = {Snapshot:/Users/solomonkurz/Zotero/storage/SDV77RJR/slabinterval.html:text/html}
}

@online{standevelopmentteamAccessingContentsStanfit2020,
	title = {Accessing the contents of a stanfit object},
	url = {https://CRAN.R-project.org/package=rstan/vignettes/stanfit-objects.html},
	author = {{Stan Development Team}},
	urldate = {2020-05-15},
	date = {2020-02-10},
	file = {Accessing the contents of a stanfit object:/Users/solomonkurz/Zotero/storage/RKEPKHUF/stanfit-objects.html:text/html}
}

@online{vehtariBayesianStackingPseudoBMA,
	title = {Bayesian stacking and pseudo-{BMA} weights using the loo package},
	url = {https://CRAN.R-project.org/package=loo/vignettes/loo2-weights.html},
	author = {Vehtari, Aki and Gabry, Jonah},
	date = {2022-03-23}
}

@article{bayesLIIEssaySolving1763,
	title = {{LII}. An essay towards solving a problem in the doctrine of chances. By the late Rev. Mr. Bayes, {FRS} communicated by Mr. Price, in a letter to John Canton, {AMFR} S},
	url = {https://royalsocietypublishing.org/doi/pdf/10.1098/rstl.1763.0053},
	pages = {370--418},
	number = {53},
	journaltitle = {Philosophical transactions of the Royal Society of London},
	author = {Bayes, Thomas},
	date = {1763},
	note = {Publisher: The Royal Society London},
	file = {Full Text:/Users/solomonkurz/Zotero/storage/EMMHAP35/Bayes - 1763 - LII. An essay towards solving a problem in the doc.pdf:application/pdf;Snapshot:/Users/solomonkurz/Zotero/storage/JISQSW2F/rstl.1763.html:text/html}
}

@article{burknerBrmsPackageBayesian2017,
	title = {{\textless}span class="nocase"{\textgreater}brms{\textless}/span{\textgreater}: An R package for Bayesian multilevel models using Stan},
	volume = {80},
	doi = {10.18637/jss.v080.i01},
	pages = {1--28},
	number = {1},
	journaltitle = {Journal of Statistical Software},
	author = {Bürkner, Paul-Christian},
	date = {2017}
}

@article{burknerAdvancedBayesianMultilevel2018,
	title = {Advanced Bayesian multilevel modeling with the R package brms},
	volume = {10},
	doi = {10.32614/RJ-2018-017},
	pages = {395--411},
	number = {1},
	journaltitle = {The R Journal},
	author = {Bürkner, Paul-Christian},
	date = {2018}
}

@article{carpenterStanProbabilisticProgramming2017,
	title = {Stan: A probabilistic programming language},
	volume = {76},
	url = {https://www.osti.gov/servlets/purl/1430202},
	doi = {10.18637/jss.v076.i01},
	number = {1},
	journaltitle = {Journal of statistical software},
	author = {Carpenter, Bob and Gelman, Andrew and Hoffman, Matthew D and Lee, Daniel and Goodrich, Ben and Betancourt, Michael and Brubaker, Marcus and Guo, Jiqiang and Li, Peter and Riddell, Allen},
	date = {2017},
	note = {Publisher: Columbia Univ., New York, {NY} (United States); Harvard Univ., Cambridge, {MA} …}
}

@article{chandramouliCommentaryGronauWagenmakers2019,
	title = {Commentary on Gronau and Wagenmakers},
	volume = {2},
	url = {https://doi.org/10.1007/s42113-018-0017-1},
	pages = {12--21},
	number = {1},
	journaltitle = {Computational Brain \& Behavior},
	author = {Chandramouli, Suyog H and Shiffrin, Richard M},
	date = {2019},
	note = {Publisher: Springer}
}

@article{eckhardtStanUlamJohn1987,
	title = {Stan Ulam, John von Neumann and the Monte Carlo method},
	url = {https://library.sciencemadness.org/lanl1_a/lib-www/pubs/00326867.pdf},
	journaltitle = {Argonne, {USA}},
	author = {Eckhardt, Roger},
	date = {1987}
}

@article{gronauLimitationsBayesianLeaveoneout2019,
	title = {Limitations of Bayesian leave-one-out cross-validation for model selection},
	volume = {2},
	url = {https://doi.org/10.1007/s42113-018-0011-7},
	pages = {1--11},
	number = {1},
	journaltitle = {Computational brain \& behavior},
	author = {Gronau, Quentin F and Wagenmakers, Eric-Jan},
	date = {2019},
	note = {Publisher: Springer}
}

@article{gronauRejoinderMoreLimitations2019,
	title = {Rejoinder: More limitations of Bayesian leave-one-out cross-validation},
	volume = {2},
	url = {https://doi.org/10.1007/s42113-018-0022-4},
	pages = {35--47},
	number = {1},
	journaltitle = {Computational brain \& behavior},
	author = {Gronau, Quentin F and Wagenmakers, Eric-Jan},
	date = {2019},
	note = {Publisher: Springer}
}

@article{kassBayesFactors1995,
	title = {Bayes factors},
	volume = {90},
	url = {https://www.stat.washington.edu/raftery/Research/PDF/kass1995.pdf},
	pages = {773--795},
	number = {430},
	journaltitle = {Journal of the American Statistical Association},
	author = {Kass, Robert E and Raftery, Adrian E},
	date = {1995},
	note = {Publisher: Taylor \& Francis}
}

@article{liuBayesFactorsPrior2008,
	title = {Bayes factors: Prior sensitivity and model generalizability},
	volume = {52},
	url = {https://doi.org/10.1016/j.jmp.2008.03.002},
	pages = {362--375},
	number = {6},
	journaltitle = {Journal of Mathematical Psychology},
	author = {Liu, Charles C and Aitkin, Murray},
	date = {2008},
	note = {Publisher: Elsevier}
}

@article{metropolisEquationStateCalculations1953,
	title = {Equation of state calculations by fast computing machines},
	volume = {21},
	url = {https://bayes.wustl.edu/Manual/EquationOfState.pdf},
	doi = {10.1063/1.1699114},
	pages = {1087--1092},
	number = {6},
	journaltitle = {The journal of chemical physics},
	author = {Metropolis, Nicholas and Rosenbluth, Arianna W and Rosenbluth, Marshall N and Teller, Augusta H and Teller, Edward},
	date = {1953},
	note = {Publisher: American Institute of Physics}
}

@article{rosaCloseLookTherapeutic1998,
	title = {A close look at therapeutic touch},
	volume = {279},
	doi = {10.1001/jama.279.13.1005},
	pages = {1005--1010},
	number = {13},
	journaltitle = {{JAMA}},
	author = {Rosa, Linda and Rosa, Emily and Sarner, Larry and Barrett, Stephen},
	date = {1998},
	note = {Publisher: American Medical Association}
}

@article{sneeGraphicalDisplayTwoway1974,
	title = {Graphical display of two-way contingency tables},
	volume = {28},
	url = {https://www.researchgate.net/profile/Ron_Snee/publication/243769696_Graphical_Display_of_Two-Way_Contingency_Tables/links/580b7ab908aecba93500ce16/Graphical-Display-of-Two-Way-Contingency-Tables.pdf},
	doi = {10.1080/00031305.1974.10479053},
	pages = {9--12},
	number = {1},
	journaltitle = {The American Statistician},
	author = {Snee, Ronald D},
	date = {1974},
	note = {Publisher: Taylor \& Francis}
}

@article{vanpaemelPriorSensitivityTheory2010,
	title = {Prior sensitivity in theory testing: An apologia for the Bayes factor},
	volume = {54},
	url = {https://ppw.kuleuven.be/okp/_pdf/Vanpaemel2010PSITT.pdf},
	doi = {10.1016/j.jmp.2010.07.003},
	pages = {491--498},
	number = {6},
	journaltitle = {Journal of Mathematical Psychology},
	author = {Vanpaemel, Wolf},
	date = {2010},
	note = {Publisher: Elsevier}
}

@article{vehtariRanknormalizationFoldingLocalization2019,
	title = {Rank-normalization, folding, and localization: An improved \${\textbackslash}widehat\{R\}\$ for assessing convergence of {MCMC}},
	url = {https://arxiv.org/abs/1903.08008?},
	journaltitle = {{arXiv} preprint {arXiv}:1903.08008},
	author = {Vehtari, Aki and Gelman, Andrew and Simpson, Daniel and Carpenter, Bob and Bürkner, Paul-Christian},
	date = {2019}
}

@article{vehtariLimitationsLimitationsBayesian2019,
	title = {Limitations of “Limitations of Bayesian leave-one-out cross-validation for model selection”},
	volume = {2},
	url = {https://doi.org/10.1007/s42113-018-0020-6},
	pages = {22--27},
	number = {1},
	journaltitle = {Computational Brain \& Behavior},
	author = {Vehtari, Aki and Simpson, Daniel P and Yao, Yuling and Gelman, Andrew},
	date = {2019},
	note = {Publisher: Springer}
}

@article{wetzelsStatisticalEvidenceExperimental2011,
	title = {Statistical evidence in experimental psychology: An empirical comparison using 855 \textit{t} tests},
	volume = {6},
	url = {https://pdfs.semanticscholar.org/1874/4e6c84087ccc20bc0f6db28020bc48c81b4a.pdf},
	doi = {10.1177/1745691611406923},
	pages = {291--298},
	number = {3},
	journaltitle = {Perspectives on Psychological Science},
	author = {Wetzels, Ruud and Matzke, Dora and Lee, Michael D and Rouder, Jeffrey N and Iverson, Geoffrey J and Wagenmakers, Eric-Jan},
	date = {2011},
	note = {Publisher: Sage Publications Sage {CA}: Los Angeles, {CA}}
}

@article{wickhamReshapingDataReshape2007,
	title = {Reshaping data with the reshape package},
	volume = {21},
	url = {https://doi.org/10.18637/jss.v021.i12},
	pages = {1--20},
	number = {12},
	journaltitle = {Journal of Statistical Software},
	author = {Wickham, Hadley},
	date = {2007}
}

@article{yaoUsingStackingAverage2018,
	title = {Using stacking to average Bayesian predictive distributions (with discussion)},
	volume = {13},
	url = {https://projecteuclid.org/download/pdfview_1/euclid.ba/1516093227},
	doi = {10.1214/17-BA1091},
	pages = {917--1007},
	number = {3},
	journaltitle = {Bayesian Analysis},
	author = {Yao, Yuling and Vehtari, Aki and Simpson, Daniel and Gelman, Andrew},
	date = {2018},
	note = {Publisher: International Society for Bayesian Analysis}
}

@book{bryanHappyGitGitHub2020,
	title = {Happy Git and {GitHub} for the {useR}},
	url = {https://happygitwithr.com},
	author = {Bryan, Jenny and {the STAT 545 TAs} and Hester, Jim},
	date = {2020}
}

@book{daleHistoryInverseProbability2012,
	title = {A history of inverse probability: From Thomas Bayes to Karl Pearson},
	url = {https://www.springer.com/gp/book/9780387988078},
	publisher = {Springer Science \& Business Media},
	author = {Dale, Andrew I},
	date = {2012}
}

@book{grolemundDataScience2017,
	title = {R for data science},
	url = {https://r4ds.had.co.nz},
	publisher = {O'Reilly},
	author = {Grolemund, Garrett and Wickham, Hadley},
	date = {2017}
}

@book{jeffreysTheoryProbability1961,
	title = {Theory of probability},
	url = {https://global.oup.com/academic/product/theory-of-probability-9780198503682?cc=us&lang=en&},
	publisher = {Oxford University Press},
	author = {Jeffreys, Harold},
	date = {1961}
}

@book{kruschkeDoingBayesianData2015,
	title = {Doing Bayesian data analysis: A tutorial with R, {JAGS}, and Stan},
	url = {https://sites.google.com/site/doingbayesiandataanalysis/},
	publisher = {Academic Press},
	author = {Kruschke, John K.},
	date = {2015}
}

@book{kolmogorovFoundationsTheoryProbability1956,
	title = {Foundations of the theory of probability: Second English Edition},
	url = {https://www.york.ac.uk/depts/maths/histstat/kolmogorov_foundations.pdf},
	publisher = {Chelsea Publishing Company},
	author = {Kolmogorov, Andre\{{\textbackslash}textbackslash\}uı Nikolaevich and Bharucha-Reid, Albert T},
	date = {1956}
}

@book{leglerBroadeningYourStatistical2019,
	title = {Broadening your statistical horizons: Generalized linear models and multilevel models},
	url = {https://bookdown.org/roback/bookdown-bysh/},
	author = {Legler, Julie and Roback, Paul},
	date = {2019}
}

@book{mcelreathStatisticalRethinkingBayesian2015,
	title = {Statistical rethinking: A Bayesian course with examples in R and Stan},
	url = {https://xcelab.net/rm/statistical-rethinking/},
	publisher = {{CRC} press},
	author = {{McElreath}, Richard},
	date = {2015}
}

@book{mcgrayneTheoryThatWould2011,
	title = {The theory that would not die: how Bayes' rule cracked the enigma code, hunted down Russian submarines, \& emerged triumphant from two centuries of controversy},
	url = {https://yalebooks.yale.edu/book/9780300188226/theory-would-not-die},
	publisher = {Yale University Press},
	author = {{McGrayne}, Sharon Bertsch},
	date = {2011}
}

@book{navarroLearningStatistics2019,
	title = {Learning statistics with R},
	url = {https://learningstatisticswithr.com},
	author = {Navarro, Danielle},
	date = {2019},
	langid = {english}
}

@book{pengProgrammingDataScience2019,
	title = {R programming for data science},
	url = {https://bookdown.org/rdpeng/rprogdatascience/},
	author = {Peng, Roger D.},
	date = {2019}
}

@book{standevelopmentteamStanReferenceManual2021,
	title = {Stan reference manual, Version 2.27},
	url = {https://mc-stan.org/docs/2_27/reference-manual/},
	author = {{Stan Development Team}},
	date = {2021}
}

@book{standevelopmentteamStanUserGuide2021,
	title = {Stan user’s guide, Version 2.26},
	url = {https://mc-stan.org/docs/2_26/stan-users-guide/index.html},
	author = {{Stan Development Team}},
	date = {2021}
}

@book{wickhamTidyverseStyleGuide2020,
	title = {The tidyverse style guide},
	url = {https://style.tidyverse.org/},
	author = {Wickham, Hadley},
	date = {2020}
}

@book{xieMarkdownDefinitiveGuide2020,
	title = {R markdown: The definitive guide},
	url = {https://bookdown.org/yihui/rmarkdown/},
	publisher = {Chapman and Hall/{CRC}},
	author = {Xie, Yihui and Allaire, J. J. and Grolemund, Garrett},
	date = {2020}
}

@book{xieBookdownAuthoringBooks2016,
	title = {{\textless}span class="nocase"{\textgreater}bookdown{\textless}/span{\textgreater}: Authoring books and technical documents with R markdown},
	url = {https://bookdown.org/yihui/bookdown/},
	publisher = {Chapman and Hall/{CRC}},
	author = {Xie, Yihui},
	date = {2016}
}

@book{R-base,
	location = {Vienna, Austria},
	title = {R: A language and environment for statistical computing},
	url = {https://www.R-project.org/},
	publisher = {R Foundation for Statistical Computing},
	author = {{R Core Team}},
	date = {2021}
}

@book{RStudio,
	location = {Boston, {MA}},
	title = {{RStudio}: Integrated development environment for R},
	url = {http://www.rstudio.com/},
	publisher = {{RStudio}, Inc.},
	author = {{RStudio Team}},
	date = {2020}
}

@book{R-bayesplot,
	title = {{\textless}span class="nocase"{\textgreater}bayesplot{\textless}/span{\textgreater}: Plotting for Bayesian models},
	url = {https://CRAN.R-project.org/package=bayesplot},
	author = {Gabry, Jonah and Mahr, Tristan},
	date = {2022}
}

@book{R-brms,
	title = {{\textless}span class="nocase"{\textgreater}brms{\textless}/span{\textgreater}: Bayesian regression models using 'Stan'},
	url = {https://CRAN.R-project.org/package=brms},
	author = {Bürkner, Paul-Christian},
	date = {2022}
}

@book{R-dplyr,
	title = {{\textless}span class="nocase"{\textgreater}dplyr{\textless}/span{\textgreater}: A grammar of data manipulation},
	url = {https://CRAN.R-project.org/package=dplyr},
	author = {Wickham, Hadley and François, Romain and Henry, Lionel and Müller, Kirill},
	date = {2020}
}

@book{R-forcats,
	title = {{\textless}span class="nocase"{\textgreater}forcats{\textless}/span{\textgreater}: Tools for working with categorical variables (factors)},
	url = {https://CRAN.R-project.org/package=forcats},
	author = {Wickham, Hadley},
	date = {2020}
}

@book{R-ggplot2,
	title = {{\textless}span class="nocase"{\textgreater}ggplot2{\textless}/span{\textgreater}: Create elegant data visualisations using the grammar of graphics},
	url = {https://CRAN.R-project.org/package=ggplot2},
	author = {Wickham, Hadley and Chang, Winston and Henry, Lionel and Pedersen, Thomas Lin and Takahashi, Kohske and Wilke, Claus and Woo, Kara and Yutani, Hiroaki and Dunnington, Dewey},
	date = {2021}
}

@book{wickhamGgplot2ElegantGraphics2016,
	title = {{\textless}span class="nocase"{\textgreater}ggplot2{\textless}/span{\textgreater}: Elegant graphics for data analysis},
	isbn = {978-3-319-24277-4},
	url = {https://ggplot2-book.org/},
	publisher = {Springer-Verlag New York},
	author = {Wickham, Hadley},
	date = {2016}
}

@book{R-gridExtra,
	title = {{\textless}span class="nocase"{\textgreater}{gridExtra}{\textless}/span{\textgreater}: Miscellaneous functions for "grid" graphics},
	url = {https://CRAN.R-project.org/package=gridExtra},
	author = {Auguie, Baptiste},
	date = {2017}
}

@book{R-janitor,
	title = {{\textless}span class="nocase"{\textgreater}janitor{\textless}/span{\textgreater}: Simple tools for examining and cleaning dirty data},
	url = {https://CRAN.R-project.org/package=janitor},
	author = {Firke, Sam},
	date = {2020}
}

@book{R-lme4,
	title = {{\textless}span class="nocase"{\textgreater}lme4{\textless}/span{\textgreater}: Linear mixed-effects models using Eigen' and S4},
	url = {https://CRAN.R-project.org/package=lme4},
	author = {Bates, Douglas and Maechler, Martin and Bolker, Ben and {Steven Walker}},
	date = {2021}
}

@article{batesFittingLinearMixedeffects2015,
	title = {Fitting linear mixed-effects models using lme4},
	volume = {67},
	doi = {10.18637/jss.v067.i01},
	pages = {1--48},
	number = {1},
	journaltitle = {Journal of Statistical Software},
	author = {Bates, Douglas and Mächler, Martin and Bolker, Ben and Walker, Steve},
	date = {2015}
}

@book{R-patchwork,
	title = {{\textless}span class="nocase"{\textgreater}patchwork{\textless}/span{\textgreater}: The composer of plots},
	url = {https://CRAN.R-project.org/package=patchwork},
	author = {Pedersen, Thomas Lin},
	date = {2020}
}

@book{R-psych,
	title = {{\textless}span class="nocase"{\textgreater}psych{\textless}/span{\textgreater}: Procedures for psychological, psychometric, and personality research},
	url = {https://CRAN.R-project.org/package=psych},
	author = {Revelle, William},
	date = {2022}
}

@book{R-purrr,
	title = {{\textless}span class="nocase"{\textgreater}purrr{\textless}/span{\textgreater}: Functional programming tools},
	url = {https://CRAN.R-project.org/package=purrr},
	author = {Henry, Lionel and Wickham, Hadley},
	date = {2020}
}

@book{R-readr,
	title = {{\textless}span class="nocase"{\textgreater}readr{\textless}/span{\textgreater}: Read rectangular text data},
	url = {https://CRAN.R-project.org/package=readr},
	author = {Wickham, Hadley and Hester, Jim and Francois, Romain},
	date = {2018}
}

@book{R-reshape2,
	title = {{\textless}span class="nocase"{\textgreater}reshape2{\textless}/span{\textgreater}: Flexibly reshape data: A reboot of the reshape package},
	url = {https://CRAN.R-project.org/package=reshape2},
	author = {Wickham, Hadley},
	date = {2020}
}

@book{R-santoku,
	title = {{\textless}span class="nocase"{\textgreater}santoku{\textless}/span{\textgreater}: A versatile cutting tool},
	url = {https://CRAN.R-project.org/package=santoku},
	author = {Hugh-Jones, David},
	date = {2020}
}

@book{R-stringr,
	title = {{\textless}span class="nocase"{\textgreater}stringr{\textless}/span{\textgreater}: Simple, consistent wrappers for common string operations},
	url = {https://CRAN.R-project.org/package=stringr},
	author = {Wickham, Hadley},
	date = {2019}
}

@book{R-tibble,
	title = {{\textless}span class="nocase"{\textgreater}tibble{\textless}/span{\textgreater}: Simple data frames},
	url = {https://CRAN.R-project.org/package=tibble},
	author = {Müller, Kirill and Wickham, Hadley},
	date = {2020}
}

@book{R-tidybayes,
	title = {{\textless}span class="nocase"{\textgreater}tidybayes{\textless}/span{\textgreater}: Tidy data and 'geoms' for Bayesian models},
	url = {https://mjskay.github.io/tidybayes/},
	author = {Kay, Matthew},
	date = {2020}
}

@book{R-tidyr,
	title = {{\textless}span class="nocase"{\textgreater}tidyr{\textless}/span{\textgreater}: Tidy messy data},
	url = {https://CRAN.R-project.org/package=tidyr},
	author = {Wickham, Hadley and Henry, Lionel},
	date = {2020}
}

@book{R-tidyverse,
	title = {{\textless}span class="nocase"{\textgreater}tidyverse{\textless}/span{\textgreater}: Easily install and load the 'tidyverse'},
	url = {https://CRAN.R-project.org/package=tidyverse},
	author = {Wickham, Hadley},
	date = {2021}
}

@article{wickhamWelcomeTidyverse2019,
	title = {Welcome to the tidyverse},
	volume = {4},
	doi = {10.21105/joss.01686},
	pages = {1686},
	number = {43},
	journaltitle = {Journal of Open Source Software},
	author = {Wickham, Hadley and Averick, Mara and Bryan, Jennifer and Chang, Winston and {McGowan}, Lucy D'Agostino and François, Romain and Grolemund, Garrett and Hayes, Alex and Henry, Lionel and Hester, Jim and Kuhn, Max and Pedersen, Thomas Lin and Miller, Evan and Bache, Stephan Milton and Müller, Kirill and Ooms, Jeroen and Robinson, David and Seidel, Dana Paige and Spinu, Vitalie and Takahashi, Kohske and Vaughan, Davis and Wilke, Claus and Woo, Kara and Yutani, Hiroaki},
	date = {2019}
}

@article{wagenmakers2007practical,
	title = {A practical solution to the pervasive problems of \textit{p} values},
	volume = {14},
	url = {https://doi.org/10.3758/BF03194105},
	pages = {779--804},
	number = {5},
	journaltitle = {Psychonomic bulletin \& review},
	author = {Wagenmakers, Eric-Jan},
	date = {2007},
	note = {tex.publisher: Springer}
}

@article{gelman2012we,
	title = {Why we (usually) don't have to worry about multiple comparisons},
	volume = {5},
	url = {https://arxiv.org/pdf/0907.2478.pdf},
	doi = {10.1080/19345747.2011.618213},
	pages = {189--211},
	number = {2},
	journaltitle = {Journal of Research on Educational Effectiveness},
	author = {Gelman, Andrew and Hill, Jennifer and Yajima, Masanao},
	date = {2012},
	note = {tex.publisher: Taylor \& Francis}
}

@article{lakensEquivalenceTestingPsychological2018,
	title = {Equivalence testing for psychological research: A tutorial},
	volume = {1},
	doi = {10.1177/2515245918770963},
	shorttitle = {Equivalence testing for psychological research},
	pages = {259--269},
	number = {2},
	journaltitle = {Advances in Methods and Practices in Psychological Science},
	author = {Lakens, Daniël and Scheel, Anne M. and Isager, Peder M.},
	date = {2018},
	note = {Publisher: Sage Publications Sage {CA}: Los Angeles, {CA}},
	file = {Full Text:/Users/solomonkurz/Zotero/storage/ARE8PRAA/Lakens et al. - 2018 - Equivalence testing for psychological research A .pdf:application/pdf;Snapshot:/Users/solomonkurz/Zotero/storage/X8WDV6SQ/2515245918770963.html:text/html}
}

@article{lakensImprovingInferencesNull2020,
	title = {Improving inferences about null effects with Bayes factors and equivalence tests},
	volume = {75},
	issn = {1079-5014, 1758-5368},
	url = {https://academic.oup.com/psychsocgerontology/article/75/1/45/5033832},
	doi = {10.1093/geronb/gby065},
	abstract = {Abstract
            Researchers often conclude an effect is absent when a null-hypothesis significance test yields a nonsignificant p value. However, it is neither logically nor statistically correct to conclude an effect is absent when a hypothesis test is not significant. We present two methods to evaluate the presence or absence of effects: Equivalence testing (based on frequentist statistics) and Bayes factors (based on Bayesian statistics). In four examples from the gerontology literature, we illustrate different ways to specify alternative models that can be used to reject the presence of a meaningful or predicted effect in hypothesis tests. We provide detailed explanations of how to calculate, report, and interpret Bayes factors and equivalence tests. We also discuss how to design informative studies that can provide support for a null model or for the absence of a meaningful effect. The conceptual differences between Bayes factors and equivalence tests are discussed, and we also note when and why they might lead to similar or different inferences in practice. It is important that researchers are able to falsify predictions or can quantify the support for predicted null effects. Bayes factors and equivalence tests provide useful statistical tools to improve inferences about null effects.},
	pages = {45--57},
	number = {1},
	journaltitle = {The Journals of Gerontology: Series B},
	author = {Lakens, Daniël and {McLatchie}, Neil and Isager, Peder M and Scheel, Anne M and Dienes, Zoltan},
	editor = {Isaacowitz, Derek},
	urldate = {2020-05-16},
	date = {2020-01-01},
	langid = {english},
	file = {Accepted Version:/Users/solomonkurz/Zotero/storage/RAXAMC8E/Lakens et al. - 2020 - Improving Inferences About Null Effects With Bayes.pdf:application/pdf}
}

@article{lakensEquivalenceTestingSecond2018,
	title = {Equivalence testing and the second generation p-value},
	url = {https://psyarxiv.com/7k6ay/},
	doi = {10.31234/osf.io/7k6ay},
	abstract = {To move beyond the limitations of null-hypothesis tests, statistical approaches have been developed where the observed data is compared against a range of values that are equivalent to the absence of a meaningful effect. Specifying a range of values around zero allows researchers to statistically reject the presence of effects large enough to matter, and prevents practically insignificant effects from being interpreted as a statistically significant difference. We compare the behavior of the recently proposed second generation p-value (Blume, D’Agostino {McGowan}, Dupont, \& Greevy, 2018) with the more established Two One-Sided Tests ({TOST}) equivalence testing procedure (Schuirmann, 1987). We show that the two approaches yield almost identical results under optimal conditions. Under suboptimal conditions (e.g., when the confidence interval is wider than the equivalence range, or when confidence intervals are asymmetric) the second generation p-value becomes difficult to interpret as a descriptive statistic. The second generation p-value is interpretable in a dichotomous manner (i.e., when the {SGPV} equals 0 or 1 because the confidence intervals lies completely within or outside of the equivalence range), but this dichotomous interpretation does not require calculations. We conclude that equivalence tests yield more consistent p-values, distinguish between datasets that yield the same second generation p-value, and allow for easier control of Type I and Type {II} error rates.},
	author = {Lakens, Daniël and Delacre, Marie},
	urldate = {2020-05-16},
	date = {2018-08-28},
	note = {Publisher: {PsyArXiv}},
	file = {Full Text PDF:/Users/solomonkurz/Zotero/storage/8NTJHU7N/Lakens and Delacre - 2018 - Equivalence Testing and the Second Generation P-Va.pdf:application/pdf;Snapshot:/Users/solomonkurz/Zotero/storage/UVGXMXC9/7k6ay.html:text/html}
}

@article{leeModelingIndividualDifferences2005,
	title = {Modeling individual differences in cognition},
	volume = {12},
	issn = {1069-9384, 1531-5320},
	url = {http://link.springer.com/10.3758/BF03196751},
	doi = {10.3758/BF03196751},
	pages = {605--621},
	number = {4},
	journaltitle = {Psychonomic Bulletin \& Review},
	shortjournal = {Psychonomic Bulletin \& Review},
	author = {Lee, Michael D. and Webb, Michael R.},
	urldate = {2020-05-16},
	date = {2005-08},
	langid = {english},
	file = {Lee and Webb - 2005 - Modeling individual differences in cognition.pdf:/Users/solomonkurz/Zotero/storage/7GYW7HR7/Lee and Webb - 2005 - Modeling individual differences in cognition.pdf:application/pdf}
}

@article{zhuCounterintuitiveNoninformativePrior2004,
	title = {The counter-intuitive non-informative prior for the Bernoulli family},
	volume = {12},
	issn = {1069-1898},
	url = {https://www.tandfonline.com/doi/full/10.1080/10691898.2004.11910734},
	doi = {10.1080/10691898.2004.11910734},
	abstract = {In Bayesian statistics, the choice of the prior distribution is often controversial. Diﬀerent rules for selecting priors have been suggested in the literature, which, sometimes, produce priors that are diﬃcult for the students to understand intuitively. In this article, we use a simple heuristic to illustrate to the students the rather counter-intuitive fact that ﬂat priors are not necessarily non-informative; and non-informative priors are not necessarily ﬂat.},
	pages = {3},
	number = {2},
	journaltitle = {Journal of Statistics Education},
	shortjournal = {Journal of Statistics Education},
	author = {Zhu, Mu and Lu, Arthur Y.},
	urldate = {2020-05-16},
	date = {2004-01},
	langid = {english},
	file = {Zhu and Lu - 2004 - The Counter-intuitive Non-informative Prior for th.pdf:/Users/solomonkurz/Zotero/storage/TGQZ4HPD/Zhu and Lu - 2004 - The Counter-intuitive Non-informative Prior for th.pdf:application/pdf}
}

@article{wagenmakersBayesianHypothesisTesting2010,
	title = {Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method},
	volume = {60},
	issn = {00100285},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0010028509000826},
	doi = {10.1016/j.cogpsych.2009.12.001},
	shorttitle = {Bayesian hypothesis testing for psychologists},
	abstract = {In the ﬁeld of cognitive psychology, the p-value hypothesis test has established a stranglehold on statistical reporting. This is unfortunate, as the p-value provides at best a rough estimate of the evidence that the data provide for the presence of an experimental effect. An alternative and arguably more appropriate measure of evidence is conveyed by a Bayesian hypothesis test, which prefers the model with the highest average likelihood. One of the main problems with this Bayesian hypothesis test, however, is that it often requires relatively sophisticated numerical methods for its computation. Here we draw attention to the Savage–Dickey density ratio method, a method that can be used to compute the result of a Bayesian hypothesis test for nested models and under certain plausible restrictions on the parameter priors. Practical examples demonstrate the method’s validity, generality, and ﬂexibility.},
	pages = {158--189},
	number = {3},
	journaltitle = {Cognitive Psychology},
	shortjournal = {Cognitive Psychology},
	author = {Wagenmakers, Eric-Jan and Lodewyckx, Tom and Kuriyal, Himanshu and Grasman, Raoul},
	urldate = {2020-05-16},
	date = {2010-05},
	langid = {english},
	file = {Wagenmakers et al. - 2010 - Bayesian hypothesis testing for psychologists A t.pdf:/Users/solomonkurz/Zotero/storage/USW25SKW/Wagenmakers et al. - 2010 - Bayesian hypothesis testing for psychologists A t.pdf:application/pdf}
}

@article{gerardLimitsRetrospectivePower1998,
	title = {Limits of retrospective power analysis},
	volume = {62},
	url = {https://www.researchgate.net/publication/273104134_Limits_of_Retrospective_Power_Analysis},
	doi = {10.2307/3802357},
	abstract = {Power analysis after study completion has been suggested to interpret study results. We present 3 methods of estimating power and discuss their limitations. We use simulation studies to show that estimated power can be biased, extremely variable, and severely bounded. We endorse the practice of computing power to detect a biologically meaningful difference as a tool for study planning but suggest that calculation of confidence intervals on the parameter of interest is the appropriate way to gauge the strength and biological meaning of study results.},
	pages = {801},
	journaltitle = {The Journal of Wildlife Management},
	shortjournal = {The Journal of Wildlife Management},
	author = {Gerard, Patrick and Smith, David and Weerakkody, Govinda},
	date = {1998-04-01},
	file = {Full Text PDF:/Users/solomonkurz/Zotero/storage/RLMXTUWI/Gerard et al. - 1998 - Limits of Retrospective Power Analysis.pdf:application/pdf}
}

@article{millerWhatProbabilityReplicating2009,
	title = {What is the probability of replicating a statistically significant effect?},
	volume = {16},
	issn = {1069-9384, 1531-5320},
	url = {http://link.springer.com/10.3758/PBR.16.4.617},
	doi = {10.3758/PBR.16.4.617},
	pages = {617--640},
	number = {4},
	journaltitle = {Psychonomic Bulletin \& Review},
	shortjournal = {Psychonomic Bulletin \& Review},
	author = {Miller, Jeff},
	urldate = {2020-05-16},
	date = {2009-08},
	langid = {english},
	file = {Miller - 2009 - What is the probability of replicating a statistic.pdf:/Users/solomonkurz/Zotero/storage/6JP49JDB/Miller - 2009 - What is the probability of replicating a statistic.pdf:application/pdf}
}

@article{nakagawaCaseRetrospectiveStatistical2004,
	title = {The case against retrospective statistical power analyses with an introduction to power analysis},
	volume = {7},
	issn = {1437-9546(Electronic),0873-9749(Print)},
	url = {https://www.researchgate.net/publication/226772798_The_case_against_retrospective_statistical_power_analyses_with_an_introduction_to_power_analysis},
	doi = {10.1007/s10211-004-0095-z},
	abstract = {Statistical power analysis is an important tool for planning an experiment because this type of analysis allows researchers to identify an appropriate sample size for a particular experimental design. In recent years, it seems many biology journals have been encouraging researchers to calculate statistical power after their experiments when they have obtained non-significant results (hereafter, termed "retrospective power calculation or analysis" as opposed to "prospective power analysis", which is conducted pre-experimentally). The logic for retrospective power analysis for data interpretation is as follows. When a non-significant result is obtained (especially with small samples), we should examine the statistical power of the significance test. If the test had low statistical power (or a high Type-{II} error rate), we should reserve "acceptance" (or more properly "nonrejection") of H₀. The argument is that we may refer to the result as inconclusive because an increase in power (e.g. through an increase in sample size) might have produced a statistically significant result. On the other hand, if a nonsignificant result is obtained, despite high power (i.e. a low Type-{II} error rate), we can be fairly confident about the non-rejection of H₀ (note that with results from null hypothesis significance testing, we can only reject or not reject H₀, but we cannot "accept" H₀-although the previously quoted sentence from Animal Behavior's instructions for authors seems to confuse this fact). Many researchers have both not recognized the serious logical flaw in retrospective power analysis when it is used for interpreting nonsignificant results and that an accurate understanding of power analysis has yet to be established among some researchers, especially among students in the study of animal behavior. The purpose of this article is-using the independent f-test as an example-to: (1) outline statistical power analysis and its components; (2) describe three common ways used to make retrospective power calculations and their logical flaws and shortcomings; (3) discuss solutions to the current situation and make recommendations. ({PsycINFO} Database Record (c) 2016 {APA}, all rights reserved)},
	pages = {103--108},
	number = {2},
	journaltitle = {Acta Ethologica},
	author = {Nakagawa, Shinichi and Foster, T. Mary},
	date = {2004},
	note = {Place: Germany
Publisher: Springer},
	keywords = {Experimental Design, Null Hypothesis Testing, Statistical Analysis, Statistical Power, Type {II} Errors},
	file = {Snapshot:/Users/solomonkurz/Zotero/storage/SG5KXE2E/2005-06529-008.html:text/html}
}

@article{okeefeBriefReportPost2007,
	title = {Brief report: Post hoc power, observed power, a priori power, retrospective power, prospective power, achieved power: Sorting out appropriate uses of statistical power analyses},
	volume = {1},
	issn = {1931-2458, 1931-2466},
	url = {http://www.dokeefe.net/pub/OKeefe07CMM-posthoc.pdf},
	doi = {10.1080/19312450701641375},
	shorttitle = {Brief Report},
	pages = {291--299},
	number = {4},
	journaltitle = {Communication Methods and Measures},
	shortjournal = {Communication Methods and Measures},
	author = {O'Keefe, Daniel J.},
	urldate = {2020-05-16},
	date = {2007-12},
	langid = {english},
	file = {O'Keefe - 2007 - Brief Report Post Hoc Power, Observed Power, A Pr.pdf:/Users/solomonkurz/Zotero/storage/5M3I5XMH/O'Keefe - 2007 - Brief Report Post Hoc Power, Observed Power, A Pr.pdf:application/pdf}
}

@article{steidlStatisticalPowerAnalysis1997,
	title = {Statistical power analysis in wildlife research},
	volume = {61},
	issn = {0022541X},
	url = {https://cals.arizona.edu/~steidl/files/pdfs/Steidl%20et%20al.%201997%20JWM.pdf},
	doi = {10.2307/3802582},
	abstract = {Statistical power analysis can be used to increase the efficiency of research efforts and to clarify research results. Power analysis is most valuable in the design or planning phases of research efforts. Such prospective (a priori) power analyses can be used to guide research design and to estimate the number of samples necessary to achieve a high probability of detecting biologically significant effects. Retrospective (a posteriori) power analysis has been advocated as a method to increase information about hypothesis tests that were not rejected. However, estimating power for tests of null hypotheses that were not rejected with the effect size observed in the study is incorrect; these power estimates will always be 50.50 when bias adjusted and have no relation to true power. Therefore, retrospective power estimates based on the observed effect size for hypothesis tests that were not rejected are misleading; retrospective power estimates are only meaningful when based on effect sizes other than the observed effect size, such as those effect sizes hypothesized to be biologcally significant. Retrospective power analysis can be used effectively to estimate the number of samples or effect size that would have been necessary for a completed study to have rejected a specific null hypothesis. Simply presenting confidence intervals can provide addtional information about null hypotheses that were not rejected, including information about the size of the true effect and whether or not there is adequate evidence to "accept" a null hypothesis as true. We suggest that (1)statistical power analyses be routinely incorporated into research planning efforts to increase their efficiency, (2) confidence intervals be used in lieu of retrospective power analyses for null hypotheses that were not rejected to assess the likely size of the true effect, (3) minimum biologically significant effect sizes be used for all power analyses, and (4) if retrospective power estimates are to be reported, then the a-level, effect sizes, and sample sizes used in calculations must also be reported.},
	pages = {270},
	number = {2},
	journaltitle = {The Journal of Wildlife Management},
	shortjournal = {The Journal of Wildlife Management},
	author = {Steidl, Robert J. and Hayes, John P. and Schauber, Eric},
	urldate = {2020-05-16},
	date = {1997-04},
	langid = {english},
	file = {Steidl et al. - 1997 - Statistical Power Analysis in Wildlife Research.pdf:/Users/solomonkurz/Zotero/storage/IHA6SZFZ/Steidl et al. - 1997 - Statistical Power Analysis in Wildlife Research.pdf:application/pdf}
}

@article{sunRethinkingObservedPower2011,
	title = {Rethinking observed power: Concept, practice, and implications},
	volume = {7},
	issn = {1614-1881, 1614-2241},
	url = {https://www.researchgate.net/profile/Shuyan_Sun2/publication/232499536_Rethinking_Observed_Power_Concept_Practice_and_Implications/links/5623f87708aea35f26868b78/Rethinking-Observed-Power-Concept-Practice-and-Implications.pdf},
	doi = {10.1027/1614-2241/a000025},
	shorttitle = {Rethinking Observed Power},
	abstract = {Observed power analysis is recommended by many scholarly journal editors and reviewers, especially for studies with statistically nonsigniﬁcant test results. However, researchers may not fully realize that blind observance of this recommendation could lead to an unfruitful effort, despite the repeated warnings from methodologists. Through both a review of 14 published empirical studies and a Monte Carlo simulation study, the present study demonstrates that observed power is usually not as informative or helpful as we think because (a) observed power for a nonsigniﬁcant test is generally low and, therefore, does not provide additional information to the test; and (b) a low observed power does not always indicate that the test is underpowered. Implications and suggestions of statistical power analysis for quantitative researchers are discussed.},
	pages = {81--87},
	number = {3},
	journaltitle = {Methodology},
	shortjournal = {Methodology},
	author = {Sun, Shuyan and Pan, Wei and Wang, Lihshing Leigh},
	urldate = {2020-05-16},
	date = {2011-01},
	langid = {english},
	file = {Sun et al. - 2011 - Rethinking Observed Power Concept, Practice, and .pdf:/Users/solomonkurz/Zotero/storage/G35IZV26/Sun et al. - 2011 - Rethinking Observed Power Concept, Practice, and .pdf:application/pdf}
}

@article{thomasRetrospectivePowerAnalysis1997,
	title = {Retrospective power analysis},
	volume = {11},
	issn = {0888-8892, 1523-1739},
	url = {https://research-repository.st-andrews.ac.uk/bitstream/handle/10023/679/Thomas-Retrospectivepoweranalysis-postprint.pdf?sequence=5},
	doi = {10.1046/j.1523-1739.1997.96102.x},
	pages = {276--280},
	number = {1},
	journaltitle = {Conservation Biology},
	shortjournal = {Conservation Biology},
	author = {Thomas, Len},
	urldate = {2020-05-16},
	date = {1997-02},
	langid = {english},
	file = {Thomas - 1997 - Retrospective Power Analysis.pdf:/Users/solomonkurz/Zotero/storage/X4DNELP7/Thomas - 1997 - Retrospective Power Analysis.pdf:application/pdf}
}

@article{duaneHybridMonteCarlo1987,
	title = {Hybrid Monte Carlo},
	volume = {195},
	issn = {0370-2693},
	url = {http://www.sciencedirect.com/science/article/pii/037026938791197X},
	doi = {10.1016/0370-2693(87)91197-X},
	abstract = {We present a new method for the numerical simulation of lattice field theory. A hybrid (molecular dynamics/Langevin) algorithm is used to guide a Monte Carlo simulation. There are no discretization errors even for large step sizes. The method is especially efficient for systems such as quantum chromodynamics which contain fermionic degrees of freedom. Detailed results are presented for four-dimensional compact quantum electrodynamics including the dynamical effects of electrons.},
	pages = {216--222},
	number = {2},
	journaltitle = {Physics Letters B},
	shortjournal = {Physics Letters B},
	author = {Duane, Simon and Kennedy, A. D. and Pendleton, Brian J. and Roweth, Duncan},
	urldate = {2020-05-16},
	date = {1987-09-03},
	langid = {english},
	file = {ScienceDirect Snapshot:/Users/solomonkurz/Zotero/storage/SUYZYUWV/037026938791197X.html:text/html}
}

@article{nealImprovedAcceptanceProcedure1994,
	title = {An improved acceptance procedure for the hybrid Monte Carlo algorithm},
	volume = {111},
	issn = {0021-9991},
	url = {http://www.sciencedirect.com/science/article/pii/S0021999184710540},
	doi = {10.1006/jcph.1994.1054},
	abstract = {The probability of accepting a candidate move in the hybrid Monte Carlo algorithm can be increased by considering a transition to be between windows of several states at the beginning and end of the trajectory, with a particular state within the selected window then being chosen according to the Boltzmann probabilities. The detailed balance condition used to justify the algorithm still holds with this procedure, provided the start state is randomly positioned within its window. The new procedure is shown empirically to significantly improve the acceptance rate for a test system of uncoupled oscillators. It also allows expectations to be estimated using data from all states in the windows, rather than just states that are accepted.},
	pages = {194--203},
	number = {1},
	journaltitle = {Journal of Computational Physics},
	shortjournal = {Journal of Computational Physics},
	author = {Neal, Radford M.},
	urldate = {2020-05-16},
	date = {1994-03-01},
	langid = {english},
	file = {ScienceDirect Snapshot:/Users/solomonkurz/Zotero/storage/2RCV64ZH/S0021999184710540.html:text/html;Submitted Version:/Users/solomonkurz/Zotero/storage/4G66CMT3/Neal - 1994 - An Improved Acceptance Procedure for the Hybrid Mo.pdf:application/pdf}
}

@book{gelman2013bayesian,
	edition = {Third Edition},
	title = {Bayesian data analysis},
	url = {https://stat.columbia.edu/~gelman/book/},
	publisher = {{CRC} press},
	author = {Gelman, Andrew and Carlin, John B and Stern, Hal S and Dunson, David B and Vehtari, Aki and Rubin, Donald B},
	date = {2013}
}

@book{mackay2003information,
	title = {Information theory, inference and learning algorithms},
	url = {https://www.inference.org.uk/itprnn/book.pdf},
	publisher = {Cambridge University Press},
	author = {{MacKay}, David {JC}},
	date = {2003}
}

@incollection{neal2011mcmc,
	title = {{MCMC} using Hamiltonian dynamics},
	url = {https://arxiv.org/pdf/1206.1901.pdf},
	pages = {116--162},
	booktitle = {Handbook of Markov chain Monte Carlo},
	author = {Neal, R},
	editor = {Brooks, Steve and Gelman, Andrew and Jones, Galin and Meng, Xiao-Li},
	date = {2011},
	note = {tex.publisher: London, United Kingdom: Chapman \& Hall/{CRC} Press}
}

@article{nelder1972generalized,
	title = {Generalized linear models},
	volume = {135},
	url = {https://repository.rothamsted.ac.uk/download/25425465aa52d05e1a9e553b2daddeeffe15d0ba40f5f9b8937aaab5c3d29e1d/4410096/Nelder%201972.pdf},
	doi = {10.2307/2344614},
	pages = {370--384},
	number = {3},
	journaltitle = {Journal of the Royal Statistical Society: Series A (General)},
	author = {Nelder, John Ashworth and Wedderburn, Robert {WM}},
	date = {1972},
	note = {tex.publisher: Wiley Online Library}
}

@article{bliss1934method,
	title = {The method of probits.},
	url = {https://science.sciencemag.org/content/79/2037/38},
	doi = {10.1126/science.79.2037.38},
	journaltitle = {Science},
	author = {Bliss, Chester I},
	date = {1934},
	note = {tex.publisher: American Assn for the Advancement of Science}
}

@book{cohenStatisticalPowerAnalysis1988,
	edition = {2nd Edition},
	title = {Statistical power analysis for the behavioral sciences},
	isbn = {978-0-203-77158-7},
	url = {https://www.taylorfrancis.com/books/9780203771587},
	publisher = {Routledge},
	author = {Cohen, Jacob},
	urldate = {2020-05-16},
	date = {1988},
	langid = {english},
	doi = {10.4324/9780203771587},
	file = {Full Text PDF:/Users/solomonkurz/Zotero/storage/P6QDI9KH/Cohen - 2013 - Statistical Power Analysis for the Behavioral Scie.pdf:application/pdf;Snapshot:/Users/solomonkurz/Zotero/storage/CCGXJI5G/9780203771587.html:text/html}
}

@article{kelley2012effect,
	title = {On effect size},
	volume = {17},
	url = {https://www3.nd.edu/~kkelley/publications/articles/Kelley_and_Preacher_Psychological_Methods_2012.pdf},
	doi = {10.1037/a0028086},
	pages = {137},
	number = {2},
	journaltitle = {Psychological methods},
	author = {Kelley, Ken and Preacher, Kristopher J},
	date = {2012},
	note = {tex.publisher: American Psychological Association}
}

@book{R-metRology,
	title = {{\textless}span class="nocase"{\textgreater}{metRology}{\textless}/span{\textgreater}: Support for metrological applications},
	url = {https://CRAN.R-project.org/package=metRology},
	author = {Ellison., Stephen L R},
	date = {2018}
}

@incollection{endersCenteringPredictorsContextual2013,
	location = {1 Oliver's Yard, 55 City Road, London {EC}1Y 1SP United Kingdom},
	title = {Centering predictors and contextual effects},
	isbn = {978-0-85702-564-7 978-1-4462-4760-0},
	url = {http://methods.sagepub.com/book/the-sage-handbook-of-multilevel-modeling/n6.xml},
	pages = {89--108},
	booktitle = {The {SAGE} Handbook of Multilevel Modeling},
	publisher = {{SAGE} Publications Ltd},
	author = {Enders, Craig},
	editor = {Scott, Marc and Simonoff, Jeffrey and Marx, Brian},
	urldate = {2020-05-16},
	date = {2013},
	doi = {10.4135/9781446247600.n6}
}

@article{enders2007centering,
	title = {Centering predictor variables in cross-sectional multilevel models: A new look at an old issue.},
	volume = {12},
	url = {https://www.researchgate.net/publication/6274186_Centering_Predictor_Variables_in_Cross-Sectional_Multilevel_Models_A_New_Look_at_An_Old_Issue},
	doi = {10.1037/1082-989X.12.2.121},
	pages = {121},
	number = {2},
	journaltitle = {Psychological methods},
	author = {Enders, Craig K and Tofighi, Davood},
	date = {2007},
	note = {tex.publisher: American Psychological Association}
}

@book{kurzStatisticalRethinkingBrms2020,
	edition = {version 1.2.0},
	title = {Statistical rethinking with brms, {\textless}span class="nocase"{\textgreater}ggplot2{\textless}/span{\textgreater}, and the tidyverse},
	url = {https://bookdown.org/content/3890/},
	abstract = {This project is an attempt to re-express the code in {McElreath}’s textbook. His models are re-fit in brms, plots are redone with ggplot2, and the general data wrangling code predominantly follows the tidyverse style.},
	author = {Kurz, A. Solomon},
	urldate = {2020-05-16},
	date = {2020-10},
	doi = {10.5281/zenodo.3693202},
	file = {Snapshot:/Users/solomonkurz/Zotero/storage/MTCXZRHZ/3890.html:text/html}
}

@article{gabry2019visualization,
	title = {Visualization in Bayesian workflow},
	volume = {182},
	url = {https://arxiv.org/abs/1709.01449},
	doi = {10.1111/rssa.12378},
	pages = {389--402},
	number = {2},
	journaltitle = {Journal of the Royal Statistical Society: Series A (Statistics in Society)},
	author = {Gabry, Jonah and Simpson, Daniel and Vehtari, Aki and Betancourt, Michael and Gelman, Andrew},
	date = {2019},
	note = {tex.publisher: Wiley Online Library}
}

@book{R-MASS,
	title = {{MASS}: Support functions and datasets for venables and ripley's {MASS}},
	url = {https://CRAN.R-project.org/package=MASS},
	author = {Ripley, Brian},
	date = {2021}
}

@book{MASS2002,
	location = {New York},
	edition = {Fourth Edition},
	title = {Modern applied statistics with S},
	url = {http://www.stats.ox.ac.uk/pub/MASS4},
	publisher = {Springer},
	author = {Venables, W. N. and Ripley, B. D.},
	date = {2002}
}

@article{guber1999getting,
	title = {Getting what you pay for: The debate over equity in public school expenditures},
	volume = {7},
	url = {https://www.semanticscholar.org/paper/Getting-What-You-Pay-For-The-Debate-Over-Equity-in-Guber/29c30e9dc77b56340faa5e6ad35e0741a5a83d49},
	number = {2},
	journaltitle = {Journal of Statistics Education},
	author = {Guber, Deborah, L},
	date = {1999}
}

@article{Pedersen2020AddingAnnotation,
	title = {Adding annotation and style},
	url = {https://patchwork.data-imaginist.com/articles/guides/annotation.html},
	author = {Pedersen, Thomas L},
	date = {2020}
}

@article{gelmanRsquaredBayesianRegression2019,
	title = {R-squared for Bayesian regression models},
	volume = {73},
	issn = {0003-1305, 1537-2731},
	url = {https://www.tandfonline.com/doi/full/10.1080/00031305.2018.1549100},
	doi = {10.1080/00031305.2018.1549100},
	pages = {307--309},
	number = {3},
	journaltitle = {The American Statistician},
	shortjournal = {The American Statistician},
	author = {Gelman, Andrew and Goodrich, Ben and Gabry, Jonah and Vehtari, Aki},
	urldate = {2020-05-16},
	date = {2019-07-03},
	langid = {english}
}

@article{Merkle2018blavaan,
	title = {{\textless}span class="nocase"{\textgreater}blavaan{\textless}/span{\textgreater}: Bayesian structural equation models via parameter expansion},
	volume = {85},
	doi = {10.18637/jss.v085.i04},
	pages = {1--30},
	number = {4},
	journaltitle = {Journal of Statistical Software},
	author = {Merkle, Edgar C. and Rosseel, Yves},
	date = {2018}
}

@book{R-blavaan,
	title = {{\textless}span class="nocase"{\textgreater}blavaan{\textless}/span{\textgreater}: Bayesian latent variable analysis},
	url = {https://CRAN.R-project.org/package=blavaan},
	author = {Merkle, Edgar C. and Rosseel, Yves and Goodrich, Ben},
	date = {2021}
}

@article{braumoellerHypothesisTestingMultiplicative2004,
	title = {Hypothesis testing and multiplicative interaction terms},
	volume = {58},
	issn = {1531-5088, 0020-8183},
	url = {https://www.cambridge.org/core/journals/international-organization/article/hypothesis-testing-and-multiplicative-interaction-terms/5AE39EABAA8F26582C65F0D3FAD153D8},
	doi = {10.1017/S0020818304040251},
	abstract = {When a statistical equation incorporates a multiplicative term in an
attempt to model interaction effects, the statistical significance of
the lower-order coefficients is largely useless for the typical
purposes of hypothesis testing. This fact remains largely unappreciated
in political science, however. This brief article explains this point,
provides examples, and offers some suggestions for more meaningful
interpretation.I am grateful to Tim
{McDaniel}, Anne Sartori, and Beth Simmons for comments on a previous
draft.},
	pages = {807--820},
	number = {4},
	journaltitle = {International Organization},
	author = {Braumoeller, Bear F.},
	urldate = {2020-05-16},
	date = {2004-10},
	langid = {english},
	note = {Publisher: Cambridge University Press},
	file = {Snapshot:/Users/solomonkurz/Zotero/storage/FZWUA73C/5AE39EABAA8F26582C65F0D3FAD153D8.html:text/html;Submitted Version:/Users/solomonkurz/Zotero/storage/BPTHF27L/Braumoeller - 2004 - Hypothesis Testing and Multiplicative Interaction .pdf:application/pdf}
}

@book{R-ggridges,
	title = {{\textless}span class="nocase"{\textgreater}ggridges{\textless}/span{\textgreater}: Ridgeline Plots in '{\textless}span class="nocase"{\textgreater}ggplot2{\textless}/span{\textgreater}'},
	url = {https://CRAN.R-project.org/package=ggridges},
	author = {Wilke, Claus O.},
	date = {2021}
}

@inproceedings{carvalho2009handling,
	title = {Handling sparsity via the horseshoe},
	url = {http://proceedings.mlr.press/v5/carvalho09a/carvalho09a.pdf},
	pages = {73--80},
	booktitle = {Artificial intelligence and statistics},
	author = {Carvalho, Carlos M and Polson, Nicholas G and Scott, James G},
	date = {2009}
}

@article{piironenSparsityInformationRegularization2017,
	title = {Sparsity information and regularization in the horseshoe and other shrinkage priors},
	volume = {11},
	issn = {1935-7524},
	url = {https://projecteuclid.org/euclid.ejs/1513306866},
	doi = {10.1214/17-EJS1337SI},
	abstract = {The horseshoe prior has proven to be a noteworthy alternative for sparse Bayesian estimation, but has previously suffered from two problems. First, there has been no systematic way of specifying a prior for the global shrinkage hyperparameter based on the prior information about the degree of sparsity in the parameter vector. Second, the horseshoe prior has the undesired property that there is no possibility of specifying separately information about sparsity and the amount of regularization for the largest coefficients, which can be problematic with weakly identified parameters, such as the logistic regression coefficients in the case of data separation. This paper proposes solutions to both of these problems. We introduce a concept of effective number of nonzero parameters, show an intuitive way of formulating the prior for the global hyperparameter based on the sparsity assumptions, and argue that the previous default choices are dubious based on their tendency to favor solutions with more unshrunk parameters than we typically expect a priori. Moreover, we introduce a generalization to the horseshoe prior, called the regularized horseshoe, that allows us to specify a minimum level of regularization to the largest values. We show that the new prior can be considered as the continuous counterpart of the spike-and-slab prior with a finite slab width, whereas the original horseshoe resembles the spike-and-slab with an infinitely wide slab. Numerical experiments on synthetic and real world data illustrate the benefit of both of these theoretical advances.},
	pages = {5018--5051},
	number = {2},
	journaltitle = {Electronic Journal of Statistics},
	shortjournal = {Electron. J. Statist.},
	author = {Piironen, Juho and Vehtari, Aki},
	urldate = {2020-05-16},
	date = {2017},
	mrnumber = {MR3738204},
	zmnumber = {06825039},
	note = {Publisher: The Institute of Mathematical Statistics and the Bernoulli Society},
	keywords = {Bayesian inference, horseshoe prior, shrinkage priors, sparse estimation},
	file = {Full Text PDF:/Users/solomonkurz/Zotero/storage/3JJ5T858/Piironen and Vehtari - 2017 - Sparsity information and regularization in the hor.pdf:application/pdf;Snapshot:/Users/solomonkurz/Zotero/storage/SX6KLCX7/1513306866.html:text/html}
}

@article{Pedersen2020PlotAssembly,
	title = {Plot assembly},
	url = {https://patchwork.data-imaginist.com/articles/guides/assembly.html},
	author = {Pedersen, Thomas L},
	date = {2020}
}

@book{fisherStatisticalMethodsResearch1925,
	location = {Oliver and Boyd},
	title = {Statistical methods for research workers, 11th ed. rev},
	url = {https://psycnet.apa.org/record/1925-15003-000},
	series = {Statistical methods for research workers, 11th ed. rev},
	abstract = {Contains revisions of probability formulas and treatment of correlations.  Harvard Book List (edited) 1955 \#94 ({PsycINFO} Database Record (c) 2016 {APA}, all rights reserved)},
	publisher = {Edinburgh},
	author = {Fisher, R.A.},
	date = {1925},
	file = {Snapshot:/Users/solomonkurz/Zotero/storage/L7DDMNLC/1925-15003-000.html:text/html}
}

@article{gelmanPriorDistributionsVariance2006,
	title = {Prior distributions for variance parameters in hierarchical models (comment on article by Browne and Draper)},
	volume = {1},
	issn = {1936-0975, 1931-6690},
	url = {https://projecteuclid.org/euclid.ba/1340371048},
	doi = {10.1214/06-BA117A},
	abstract = {Various noninformative prior distributions have been suggested for scale parameters in hierarchical models. We construct a new folded-noncentral-ttt family of conditionally conjugate priors for hierarchical standard deviation parameters, and then consider noninformative and weakly informative priors in this family. We use an example to illustrate serious problems with the inverse-gamma family of "noninformative" prior distributions. We suggest instead to use a uniform prior on the hierarchical standard deviation, using the half-ttt family when the number of groups is small and in other settings where a weakly informative prior is desired. We also illustrate the use of the half-ttt family for hierarchical modeling of multiple variance parameters such as arise in the analysis of variance.},
	pages = {515--534},
	number = {3},
	journaltitle = {Bayesian Analysis},
	shortjournal = {Bayesian Anal.},
	author = {Gelman, Andrew},
	urldate = {2020-05-17},
	date = {2006-09},
	mrnumber = {MR2221284},
	zmnumber = {1331.62139},
	note = {Publisher: International Society for Bayesian Analysis},
	keywords = {Bayesian inference, conditional conjugacy, folded-noncentral-\$t\$ distribution, half-\$t\$ distribution, hierarchical model, multilevel model, noninformative prior distribution, weakly informative prior distribution},
	file = {Full Text PDF:/Users/solomonkurz/Zotero/storage/LNB63KFA/Gelman - 2006 - Prior distributions for variance parameters in hie.pdf:application/pdf;Snapshot:/Users/solomonkurz/Zotero/storage/AJT3SYSS/1340371048.html:text/html}
}

@article{efronSteinParadoxStatistics1977,
	title = {Stein's paradox in statistics},
	volume = {236},
	issn = {0036-8733},
	url = {https://www.jstor.org/stable/24954030},
	doi = {10.1038/scientificamerican0577-119},
	pages = {119--127},
	number = {5},
	journaltitle = {Scientific American},
	author = {Efron, Bradley and Morris, Carl},
	urldate = {2020-05-17},
	date = {1977},
	note = {Publisher: Scientific American, a division of Nature America, Inc.}
}

@article{chungNondegeneratePenalizedLikelihood2013,
	title = {A nondegenerate penalized likelihood estimator for variance parameters in multilevel models},
	volume = {78},
	issn = {0033-3123, 1860-0980},
	url = {http://link.springer.com/10.1007/s11336-013-9328-2},
	doi = {10.1007/s11336-013-9328-2},
	pages = {685--709},
	number = {4},
	journaltitle = {Psychometrika},
	shortjournal = {Psychometrika},
	author = {Chung, Yeojin and Rabe-Hesketh, Sophia and Dorie, Vincent and Gelman, Andrew and Liu, Jingchen},
	urldate = {2020-05-17},
	date = {2013-10},
	langid = {english}
}

@article{shapiroSexualActivityLifespan1994,
	title = {Sexual activity and the lifespan of male fruitflies: A dataset that gets attention},
	volume = {2},
	issn = {null},
	url = {https://doi.org/10.1080/10691898.1994.11910467},
	doi = {10.1080/10691898.1994.11910467},
	shorttitle = {Sexual Activity and the Lifespan of Male Fruitflies},
	abstract = {This dataset contains observations on five groups of male fruitflies –– 25 fruitflies in each group –– from an experiment designed to test if increased reproduction reduces longevity for male fruitflies. (Such a cost has already been established for females.) The five groups are: males forced to live alone, males assigned to live with one or eight interested females, and males assigned to live with one or eight non-receptive females. The observations on each fly were longevity, thorax length, and the percentage of each day spent sleeping. The structure of the experiment provokes lively discussion on experimental design and on contrasts, and gives students opportunities to understand and verbalize what we mean by the term “statistical interaction.” Because the variable thorax length has a strong effect on survival, it is important to take it into account to increase the precision of between-group contrasts, even though it is distributed similarly across groups. The dataset can also be used to illustrate techniques of survival analysis.},
	pages = {null},
	number = {1},
	journaltitle = {Journal of Statistics Education},
	author = {Shapiro, H, Stanley},
	urldate = {2020-05-17},
	date = {1994-07-01},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/10691898.1994.11910467},
	keywords = {Analysis of covariance, Experiment, Longevity, Precision, Regression, Survival analysis},
	file = {Full Text PDF:/Users/solomonkurz/Zotero/storage/9J3933SB/A and H - 1994 - Sexual Activity and the Lifespan of Male Fruitflie.pdf:application/pdf;Snapshot:/Users/solomonkurz/Zotero/storage/HIZI77AL/10691898.1994.html:text/html}
}

@article{wickhamTidyData2014,
	title = {Tidy data},
	volume = {59},
	issn = {1548-7660},
	url = {http://www.jstatsoft.org/v59/i10/},
	doi = {10.18637/jss.v059.i10},
	number = {10},
	journaltitle = {Journal of Statistical Software},
	shortjournal = {J. Stat. Soft.},
	author = {Wickham, Hadley},
	urldate = {2020-05-17},
	date = {2014},
	langid = {english},
	file = {Full Text:/Users/solomonkurz/Zotero/storage/56ARBADN/Wickham - 2014 - Tidy Data.pdf:application/pdf}
}

@online{kayExtractingVisualizingTidy2020,
	title = {Extracting and visualizing tidy draws from brms models},
	url = {https://mjskay.github.io/tidybayes/articles/tidy-brms.html},
	abstract = {tidybayes},
	author = {Kay, Matthew},
	urldate = {2020-05-17},
	date = {2020-06-17},
	langid = {english},
	note = {Library Catalog: mjskay.github.io},
	file = {Snapshot:/Users/solomonkurz/Zotero/storage/NT83AM3T/tidy-brms.html:text/html}
}

@report{williamsBayesianMultivariateMixedeffects2019,
	title = {Bayesian multivariate mixed-effects location scale modeling of longitudinal relations among affective traits, states, and physical activity},
	url = {https://osf.io/4kfjp},
	abstract = {Intensive longitudinal studies and experience sampling methods are becoming more common in psychology. While they provide a unique opportunity to ask novel questions about within-person processes relating to personality, there is a lack of methods specifically built to characterize the interplay between traits and states. We thus introduce a Bayesian multivariate mixed-effects location scale model (M-{MELSM}). The formulation can simultaneously model both personality traits (the location) and states (the scale) for multivariate data common to personality research. Variables can be included to predict either (or both) the traits and states, in addition to estimating random effects therein. This provides correlations between location and scale random effects, both across and within each outcome, which allows for characterizing relations between any number personality traits and the corresponding states. We take a {\textbackslash}textit\{fully\} Bayesian approach, not only to make estimation possible, but also because  it provides the necessary information for use in psychological applications such as hypothesis testing. To illustrate the model we use data from 194 individuals that provided daily ratings of negative and positive affect, as well as their psychical activity in the form of step counts over 100 consecutive days. We describe the fitted model, where we emphasize, with visualization, the richness of information provided by the M-{MELSM}. We demonstrate Bayesian hypothesis testing for the correlations between the random effects. We conclude by discussing limitations of the {MELSM} in general and extensions to the M-{MELSM} specifically for personality research.},
	institution = {{PsyArXiv}},
	type = {preprint},
	author = {Williams, Donald R. and Liu, Siwei and Martin, Stephen Ross and Rast, Philippe},
	urldate = {2020-05-17},
	date = {2019-03-27},
	doi = {10.31234/osf.io/4kfjp}
}

@article{williamsBayesianNonlinearMixedeffects2019,
	title = {A Bayesian nonlinear mixed-effects location scale model for learning},
	volume = {51},
	issn = {1554-3528},
	url = {http://link.springer.com/10.3758/s13428-019-01255-9},
	doi = {10.3758/s13428-019-01255-9},
	pages = {1968--1986},
	number = {5},
	journaltitle = {Behavior Research Methods},
	shortjournal = {Behav Res},
	author = {Williams, Donald R. and Zimprich, Daniel R. and Rast, Philippe},
	urldate = {2020-05-17},
	date = {2019-10},
	langid = {english}
}

@article{skinnerCaseHistoryScientific1956,
	title = {A case history in scientific method},
	volume = {11},
	issn = {1935-990X(Electronic),0003-066X(Print)},
	url = {https://pdfs.semanticscholar.org/a113/55f49947e4c77659ec9fa5c6b69bd7798194.pdf},
	doi = {10.1037/h0047662},
	abstract = {The case history in scientific method cited is autobiographical; Skinner relates certain relevant experiences in the development of some of his scientific contributions. ({PsycINFO} Database Record (c) 2016 {APA}, all rights reserved)},
	pages = {221--233},
	number = {5},
	journaltitle = {American Psychologist},
	author = {Skinner, B. F.},
	date = {1956},
	note = {Place: {US}
Publisher: American Psychological Association},
	keywords = {Experimental Methods, Experimentation, Scientific Communication},
	file = {Snapshot:/Users/solomonkurz/Zotero/storage/BZJKX54K/1957-05288-001.html:text/html}
}

@incollection{hamakerWhyResearchersShould2012,
	location = {New York, {NY}, {US}},
	title = {Why researchers should think "within-person": A paradigmatic rationale},
	isbn = {978-1-60918-747-7 978-1-60918-749-1},
	url = {https://www.guilford.com/books/Handbook-of-Research-Methods-for-Studying-Daily-Life/Mehl-Conner/9781462513055},
	shorttitle = {Why researchers should think "within-person"},
	abstract = {This chapter presents reasoning for taking an alternative research approach to the study of processes that unfold within individuals over time as part of their daily lives. To this end I focus on three issues. First, I present a brief historical account that shows the large-sample approach is not necessarily the only appropriate research approach in psychology. Second, I discuss the limitations of this approach, specifically, if our interest is in studying psychological processes that take place within individuals. Finally, I discuss several alternatives to the standard large-sample approach that allow us to take a closer and more detailed look at the processes as they are occurring in daily life. ({PsycINFO} Database Record (c) 2019 {APA}, all rights reserved)},
	pages = {43--61},
	booktitle = {Handbook of research methods for studying daily life},
	publisher = {The Guilford Press},
	author = {Hamaker, Ellen L.},
	date = {2012},
	keywords = {Experimentation, Cognitive Processes, Experiences (Events), Experimental Psychologists, History, Methodology, Personality Processes},
	file = {Snapshot:/Users/solomonkurz/Zotero/storage/7IAKF3TS/2012-05165-003.html:text/html}
}

@article{bolgerCausalProcessesPsychology2019,
	title = {Causal processes in psychology are heterogeneous},
	volume = {148},
	issn = {1939-2222(Electronic),0096-3445(Print)},
	url = {https://www.researchgate.net/profile/Niall_Bolger/publication/332358948_Causal_processes_in_psychology_are_heterogeneous/links/5cd9b471a6fdccc9ddaa7879/Causal-processes-in-psychology-are-heterogeneous.pdf},
	doi = {10.1037/xge0000558},
	abstract = {All experimenters know that human and animal subjects do not respond uniformly to experimental treatments. Yet theories and findings in experimental psychology either ignore this causal effect heterogeneity or treat it as uninteresting error. This is the case even when data are available to examine effect heterogeneity directly, in within-subjects designs where experimental effects can be examined subject by subject. Using data from four repeated-measures experiments, we show that effect heterogeneity can be modeled readily, that its discovery presents exciting opportunities for theory and methods, and that allowing for it in study designs is good research practice. This evidence suggests that experimenters should work from the assumption that causal effects are heterogeneous. Such a working assumption will be of particular benefit, given the increasing diversity of subject populations in psychology. ({PsycINFO} Database Record (c) 2019 {APA}, all rights reserved)},
	pages = {601--618},
	number = {4},
	journaltitle = {Journal of Experimental Psychology: General},
	author = {Bolger, Niall and Zee, Katherine S. and Rossignac-Milon, Maya and Hassin, Ran R.},
	date = {2019},
	note = {Place: {US}
Publisher: American Psychological Association},
	keywords = {Experimental Methods, Experimental Psychology, Experimenters, Homogeneity of Variance, Models, Repeated Measures, Theory Formulation},
	file = {Snapshot:/Users/solomonkurz/Zotero/storage/CAWSDRIT/2019-19962-002.html:text/html}
}

@article{rouderDefaultBayesFactors2012,
	title = {Default Bayes factors for {ANOVA} designs},
	volume = {56},
	issn = {0022-2496},
	url = {http://pcl.missouri.edu/sites/default/files/Rouder.JMP_.2012.pdf},
	doi = {10.1016/j.jmp.2012.08.001},
	abstract = {Bayes factors have been advocated as superior to p-values for assessing statistical evidence in data. Despite the advantages of Bayes factors and the drawbacks of p-values, inference by p-values is still nearly ubiquitous. One impediment to the adoption of Bayes factors is a lack of practical development, particularly a lack of ready-to-use formulas and algorithms. In this paper, we discuss and expand a set of default Bayes factor tests for {ANOVA} designs. These tests are based on multivariate generalizations of Cauchy priors on standardized effects, and have the desirable properties of being invariant with respect to linear transformations of measurement units. Moreover, these Bayes factors are computationally convenient, and straightforward sampling algorithms are provided. We cover models with fixed, random, and mixed effects, including random interactions, and do so for within-subject, between-subject, and mixed designs. We extend the discussion to regression models with continuous covariates. We also discuss how these Bayes factors may be applied in nonlinear settings, and show how they are useful in differentiating between the power law and the exponential law of skill acquisition. In sum, the current development makes the computation of Bayes factors straightforward for the vast majority of designs in experimental psychology.},
	pages = {356--374},
	number = {5},
	journaltitle = {Journal of Mathematical Psychology},
	shortjournal = {Journal of Mathematical Psychology},
	author = {Rouder, Jeffrey N. and Morey, Richard D. and Speckman, Paul L. and Province, Jordan M.},
	urldate = {2020-05-18},
	date = {2012-10-01},
	langid = {english},
	keywords = {Bayes factor, Bayesian statistics, Linear models, Model selection},
	file = {ScienceDirect Snapshot:/Users/solomonkurz/Zotero/storage/2MM7ERU8/S0022249612000806.html:text/html}
}

@article{wetzelsDefaultBayesianHypothesis2012,
	title = {A default Bayesian hypothesis test for {ANOVA} designs},
	volume = {66},
	issn = {0003-1305},
	url = {https://www.ejwagenmakers.com/2012/WetzelsEtAl2012AmStat.pdf},
	doi = {10.1080/00031305.2012.695956},
	abstract = {This article presents a Bayesian hypothesis test for analysis of variance ({ANOVA}) designs. The test is an application of standard Bayesian methods for variable selection in regression models. We illustrate the effect of various g-priors on the {ANOVA} hypothesis test. The Bayesian test for {ANOVA} designs is useful for empirical researchers and for students; both groups will get a more acute appreciation of Bayesian inference when they can apply it to practical statistical problems such as {ANOVA}. We illustrate the use of the test with two examples, and we provide R code that makes the test easy to use.},
	pages = {104--111},
	number = {2},
	journaltitle = {The American Statistician},
	author = {Wetzels, Ruud and Grasman, Raoul P. P. P. and Wagenmakers, Eric-Jan},
	urldate = {2020-05-18},
	date = {2012-05-01},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/00031305.2012.695956},
	keywords = {Bayes factor, Model selection, Teaching Bayesian statistics},
	file = {Snapshot:/Users/solomonkurz/Zotero/storage/K9KJAT77/00031305.2012.html:text/html}
}

@book{R-ggExtra,
	title = {{\textless}span class="nocase"{\textgreater} {ggExtra}{\textless}/span{\textgreater}: Add marginal histograms to '{\textless}span class="nocase"{\textgreater}ggplot2{\textless}/span{\textgreater}', and more '{\textless}span class="nocase"{\textgreater}ggplot2{\textless}/span{\textgreater}' enhancements},
	url = {https://CRAN.R-project.org/package=ggExtra},
	author = {Attali, Dean and Baker, Christopher},
	date = {2022}
}

@book{luceIndividualChoiceBehavior2012,
	title = {Individual choice behavior: A theoretical analysis},
	isbn = {978-0-486-15339-1},
	shorttitle = {Individual Choice Behavior},
	abstract = {This influential treatise presents upper-level undergraduates and graduate students with a mathematical analysis of choice behavior. It begins with the statement of a general axiom upon which the rest of the book rests; the following three chapters, which may be read independently of each other, are devoted to applications of the theory to substantive problems: psychophysics, utility, and learning.Applications to psychophysics include considerations of time- and space-order effects, the Fechnerian assumption, the power law and its relation to discrimination data, interaction of continua, discriminal processes, signal detectability theory, and ranking of stimuli. The next major theme, utility theory, features unusual results that suggest an experiment to test the theory. The final chapters explore learning-related topics, analyzing the stochastic theories of learning as the basic approach—with the exception that distributions of response strengths are assumed to be transformed rather than response probabilities. The author arrives at three classes of learning operators, both linear and nonlinear, and the text concludes with a useful series of appendixes.},
	pagetotal = {172},
	publisher = {Courier Corporation},
	author = {Luce, R. Duncan},
	date = {2012-06-22},
	langid = {english},
	note = {Google-Books-{ID}: {ERQsKkPiKkkC}},
	keywords = {Mathematics / Probability \& Statistics / General}
}

@article{luceLuceChoiceAxiom2008,
	title = {Luce's choice axiom},
	volume = {3},
	issn = {1941-6016},
	url = {http://www.scholarpedia.org/article/Luce%27s_choice_axiom},
	doi = {10.4249/scholarpedia.8077},
	pages = {8077},
	number = {12},
	journaltitle = {Scholarpedia},
	author = {Luce, R. Duncan},
	urldate = {2020-05-18},
	date = {2008-12-02},
	langid = {english},
	file = {Snapshot:/Users/solomonkurz/Zotero/storage/PMGIVY8Z/Luce's_choice_axiom.html:text/html}
}

@article{likertTechniqueMeasurementAttitudes1932,
	title = {A technique for the measurement of attitudes},
	volume = {22  140},
	url = {https://legacy.voteview.com/pdf/Likert_1932.pdf},
	abstract = {The project conceived in 1929 by Gardner Murphy and the writer aimed first to present a wide array of problems having to do with five major "attitude areas"—international relations, race relations, economic conflict, political conflict, and religion. The kind of questionnaire material falls into four classes: yes-no, multiple choice, propositions to be responded to by degrees of approval, and a series of brief newspaper narratives to be approved or disapproved in various degrees. The monograph aims to describe a technique rather than to give results. The appendix, covering ten pages, shows the method of constructing an attitude scale. A bibliography is also given. ({PsycINFO} Database Record (c) 2016 {APA}, all rights reserved)},
	pages = {55--55},
	journaltitle = {Archives of Psychology},
	author = {Likert, R.},
	date = {1932},
	file = {Snapshot:/Users/solomonkurz/Zotero/storage/3VW2VGT5/1933-01885-001.html:text/html}
}

@article{carifio2007ten,
	title = {Ten common misunderstandings, misconceptions, persistent myths and urban legends about Likert scales and Likert response formats and their antidotes},
	volume = {3},
	url = {https://thescipub.com/pdf/10.3844/jssp.2007.106.116.pdf},
	pages = {106--116},
	number = {3},
	journaltitle = {Journal of Social Sciences},
	author = {Carifio, James and Perla, Rocco J},
	date = {2007}
}

@article{carifioResolving50yearDebate2008,
	title = {Resolving the 50-year debate around using and misusing Likert scales},
	volume = {42},
	rights = {© Blackwell Publishing Ltd 2008},
	issn = {1365-2923},
	url = {Resolving the 50-year debate around using and misusing Likert scales},
	doi = {10.1111/j.1365-2923.2008.03172.x},
	pages = {1150--1152},
	number = {12},
	journaltitle = {Medical Education},
	author = {Carifio, James and Perla, Rocco},
	urldate = {2020-05-18},
	date = {2008},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1365-2923.2008.03172.x},
	file = {Snapshot:/Users/solomonkurz/Zotero/storage/L3VGQJRR/j.1365-2923.2008.03172.html:text/html}
}

@article{normanLikertScalesLevels2010,
	title = {Likert scales, levels of measurement and the “laws” of statistics},
	volume = {15},
	issn = {1573-1677},
	url = {https://www.researchgate.net/publication/41420484_LIkert_scales_levels_of_measurement_adn_the_laws_of_statistics},
	doi = {10.1007/s10459-010-9222-y},
	abstract = {Reviewers of research reports frequently criticize the choice of statistical methods. While some of these criticisms are well-founded, frequently the use of various parametric methods such as analysis of variance, regression, correlation are faulted because: (a) the sample size is too small, (b) the data may not be normally distributed, or (c) The data are from Likert scales, which are ordinal, so parametric statistics cannot be used. In this paper, I dissect these arguments, and show that many studies, dating back to the 1930s consistently show that parametric statistics are robust with respect to violations of these assumptions. Hence, challenges like those above are unfounded, and parametric methods can be utilized without concern for “getting the wrong answer”.},
	pages = {625--632},
	number = {5},
	journaltitle = {Advances in Health Sciences Education},
	shortjournal = {Adv in Health Sci Educ},
	author = {Norman, Geoff},
	urldate = {2020-05-18},
	date = {2010-12-01},
	langid = {english}
}

@article{burknerBayesianItemResponse2020,
	title = {Bayesian item response modeling in R with brms and Stan},
	url = {http://arxiv.org/abs/1905.09501},
	abstract = {Item Response Theory ({IRT}) is widely applied in the human sciences to model persons' responses on a set of items measuring one or more latent constructs. While several R packages have been developed that implement {IRT} models, they tend to be restricted to respective prespecified classes of models. Further, most implementations are frequentist while the availability of Bayesian methods remains comparably limited. We demonstrate how to use the R package brms together with the probabilistic programming language Stan to specify and fit a wide range of Bayesian {IRT} models using flexible and intuitive multilevel formula syntax. Further, item and person parameters can be related in both a linear or non-linear manner. Various distributions for categorical, ordinal, and continuous responses are supported. Users may even define their own custom response distribution for use in the presented framework. Common {IRT} model classes that can be specified natively in the presented framework include 1PL and 2PL logistic models optionally also containing guessing parameters, graded response and partial credit ordinal models, as well as drift diffusion models of response times coupled with binary decisions. Posterior distributions of item and person parameters can be conveniently extracted and post-processed. Model fit can be evaluated and compared using Bayes factors and efficient cross-validation procedures.},
	journaltitle = {{arXiv}:1905.09501 [stat]},
	author = {Bürkner, Paul-Christian},
	urldate = {2020-05-18},
	date = {2020-02-01},
	eprinttype = {arxiv},
	eprint = {1905.09501},
	keywords = {Statistics - Computation},
	file = {arXiv Fulltext PDF:/Users/solomonkurz/Zotero/storage/T5WVXMPA/Bürkner - 2020 - Bayesian Item Response Modeling in R with brms and.pdf:application/pdf;arXiv.org Snapshot:/Users/solomonkurz/Zotero/storage/KYB42QN2/1905.html:text/html}
}

@article{burknerOrdinalRegressionModels2019,
	title = {Ordinal regression models in psychology: A tutorial},
	volume = {2},
	issn = {2515-2459},
	url = {https://doi.org/10.1177/2515245918823199},
	doi = {10.1177/2515245918823199},
	shorttitle = {Ordinal Regression Models in Psychology},
	abstract = {Ordinal variables, although extremely common in psychology, are almost exclusively analyzed with statistical models that falsely assume them to be metric. This practice can lead to distorted effect-size estimates, inflated error rates, and other problems. We argue for the application of ordinal models that make appropriate assumptions about the variables under study. In this Tutorial, we first explain the three major classes of ordinal models: the cumulative, sequential, and adjacent-category models. We then show how to fit ordinal models in a fully Bayesian framework with the R package brms, using data sets on opinions about stem-cell research and time courses of marriage. The appendices provide detailed mathematical derivations of the models and a discussion of censored ordinal models. Compared with metric models, ordinal models provide better theoretical interpretation and numerical inference from ordinal data, and we recommend their widespread adoption in psychology.},
	pages = {77--101},
	number = {1},
	journaltitle = {Advances in Methods and Practices in Psychological Science},
	shortjournal = {Advances in Methods and Practices in Psychological Science},
	author = {Bürkner, Paul-Christian and Vuorre, Matti},
	urldate = {2020-05-18},
	date = {2019-03-01},
	langid = {english},
	note = {Publisher: {SAGE} Publications Inc}
}

@article{gelmanAnalysisVarianceWhy2005,
	title = {Analysis of variance--Why it is more important than ever},
	volume = {33},
	issn = {0090-5364, 2168-8966},
	url = {https://projecteuclid.org/download/pdfview_1/euclid.aos/1112967698},
	doi = {10.1214/009053604000001048},
	abstract = {Analysis of variance ({ANOVA}) is an extremely important method in exploratory and confirmatory data analysis. Unfortunately, in complex problems (e.g., split-plot designs), it is not always easy to set up an appropriate {ANOVA}. We propose a hierarchical analysis that automatically gives the correct {ANOVA} comparisons even in complex scenarios. The inferences for all means and variances are performed under a model with a separate batch of effects for each row of the {ANOVA} table. We connect to classical {ANOVA} by working with finite-sample variance components: fixed and random effects models are characterized by inferences about existing levels of a factor and new levels, respectively. We also introduce a new graphical display showing inferences about the standard deviations of each batch of effects. We illustrate with two examples from our applied data analysis, first illustrating the usefulness of our hierarchical computations and displays, and second showing how the ideas of {ANOVA} are helpful in understanding a previously fit hierarchical model.},
	pages = {1--53},
	number = {1},
	journaltitle = {Annals of Statistics},
	shortjournal = {Ann. Statist.},
	author = {Gelman, Andrew},
	urldate = {2020-05-18},
	date = {2005-02},
	mrnumber = {MR2157795},
	zmnumber = {1064.62082},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {Bayesian inference, hierarchical model, multilevel model, {ANOVA}, fixed effects, linear regression, random effects, variance components},
	file = {Full Text PDF:/Users/solomonkurz/Zotero/storage/2U3XQY5J/Gelman - 2005 - Analysis of variance—why it is more important than.pdf:application/pdf;Snapshot:/Users/solomonkurz/Zotero/storage/SQ6DDNZI/1112967698.html:text/html}
}

@article{aczelDiscussionPointsBayesian2020,
	title = {Discussion points for Bayesian inference},
	rights = {2020 Springer Nature Limited},
	issn = {2397-3374},
	url = {https://www.researchgate.net/publication/338849264_Discussion_points_for_Bayesian_inference},
	doi = {10.1038/s41562-019-0807-z},
	abstract = {Why is there no consensual way of conducting Bayesian analyses? We present a summary of agreements and disagreements of the authors on several discussion points regarding Bayesian inference. We also provide a thinking guideline to assist researchers in conducting Bayesian inference in the social and behavioural sciences.},
	pages = {1--3},
	journaltitle = {Nature Human Behaviour},
	author = {Aczel, Balazs and Hoekstra, Rink and Gelman, Andrew and Wagenmakers, Eric-Jan and Klugkist, Irene G. and Rouder, Jeffrey N. and Vandekerckhove, Joachim and Lee, Michael D. and Morey, Richard D. and Vanpaemel, Wolf and Dienes, Zoltan and van Ravenzwaaij, Don},
	urldate = {2020-05-18},
	date = {2020-01-27},
	langid = {english},
	note = {Publisher: Nature Publishing Group},
	file = {Snapshot:/Users/solomonkurz/Zotero/storage/LPH5KWXL/s41562-019-0807-z.html:text/html}
}

@article{kruschkeBayesianNewStatistics2018,
	title = {{\textless}span class="nocase"{\textgreater}The Bayesian New Statistics{\textless}/span{\textgreater}: Hypothesis testing, estimation, meta-analysis, and power analysis from a {\textless}span class="nocase"{\textgreater}Bayesian{\textless}/span{\textgreater} perspective},
	volume = {25},
	issn = {1531-5320},
	url = {https://link.springer.com/content/pdf/10.3758/s13423-016-1221-4.pdf},
	doi = {10.3758/s13423-016-1221-4},
	shorttitle = {The Bayesian New Statistics},
	abstract = {In the practice of data analysis, there is a conceptual distinction between hypothesis testing, on the one hand, and estimation with quantified uncertainty on the other. Among frequentists in psychology, a shift of emphasis from hypothesis testing to estimation has been dubbed “the New Statistics” (Cumming 2014). A second conceptual distinction is between frequentist methods and Bayesian methods. Our main goal in this article is to explain how Bayesian methods achieve the goals of the New Statistics better than frequentist methods. The article reviews frequentist and Bayesian approaches to hypothesis testing and to estimation with confidence or credible intervals. The article also describes Bayesian approaches to meta-analysis, randomized controlled trials, and power analysis.},
	pages = {178--206},
	number = {1},
	journaltitle = {Psychonomic Bulletin \& Review},
	shortjournal = {Psychon Bull Rev},
	author = {Kruschke, John K. and Liddell, Torrin M.},
	urldate = {2020-05-18},
	date = {2018-02-01},
	langid = {english},
	file = {Springer Full Text PDF:/Users/solomonkurz/Zotero/storage/SRKQT967/Kruschke and Liddell - 2018 - The Bayesian New Statistics Hypothesis testing, e.pdf:application/pdf}
}

@article{kruschkePosteriorPredictiveChecks2013,
	title = {Posterior predictive checks can and should be Bayesian: Comment on Gelman and Shalizi, ‘Philosophy and the practice of Bayesian statistics’},
	volume = {66},
	rights = {© 2012 The British Psychological Society},
	issn = {2044-8317},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.2044-8317.2012.02063.x},
	doi = {10.1111/j.2044-8317.2012.02063.x},
	shorttitle = {Posterior predictive checks can and should be Bayesian},
	abstract = {Bayesian inference is conditional on the space of models assumed by the analyst. The posterior distribution indicates only which of the available parameter values are less bad than the others, without indicating whether the best available parameter values really fit the data well. A posterior predictive check is important to assess whether the posterior predictions of the least bad parameters are discrepant from the actual data in systematic ways. Gelman and Shalizi (2012a) assert that the posterior predictive check, whether done qualitatively or quantitatively, is non-Bayesian. I suggest that the qualitative posterior predictive check might be Bayesian, and the quantitative posterior predictive check should be Bayesian. In particular, I show that the ‘Bayesian p-value’, from which an analyst attempts to reject a model without recourse to an alternative model, is ambiguous and inconclusive. Instead, the posterior predictive check, whether qualitative or quantitative, should be consummated with Bayesian estimation of an expanded model. The conclusion agrees with Gelman and Shalizi regarding the importance of the posterior predictive check for breaking out of an initially assumed space of models. Philosophically, the conclusion allows the liberation to be completely Bayesian instead of relying on a non-Bayesian deus ex machina. Practically, the conclusion cautions against use of the Bayesian p-value in favour of direct model expansion and Bayesian evaluation.},
	pages = {45--56},
	number = {1},
	journaltitle = {British Journal of Mathematical and Statistical Psychology},
	author = {Kruschke, John K.},
	urldate = {2020-05-18},
	date = {2013},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.2044-8317.2012.02063.x},
	file = {Snapshot:/Users/solomonkurz/Zotero/storage/T32AK4DC/j.2044-8317.2012.02063.html:text/html}
}

@article{rouderWhatWhyHow2016,
	title = {The what, why, and how of born-open data},
	volume = {48},
	issn = {1554-3528},
	url = {https://link.springer.com/content/pdf/10.3758/s13428-015-0630-z.pdf},
	doi = {10.3758/s13428-015-0630-z},
	abstract = {Although many researchers agree that scientific data should be open to scrutiny to ferret out poor analyses and outright fraud, most raw data sets are not available on demand. There are many reasons researchers do not open their data, and one is technical. It is often time consuming to prepare and archive data. In response, my laboratory has automated the process such that our data are archived the night they are created without any human approval or action. All data are versioned, logged, time stamped, and uploaded including aborted runs and data from pilot subjects. The archive is {GitHub}, github.com, the world’s largest collection of open-source materials. Data archived in this manner are called born open. In this paper, I discuss the benefits of born-open data and provide a brief technical overview of the process. I also address some of the common concerns about opening data before publication.},
	pages = {1062--1069},
	number = {3},
	journaltitle = {Behavior Research Methods},
	shortjournal = {Behav Res},
	author = {Rouder, Jeffrey N.},
	urldate = {2020-05-18},
	date = {2016-09-01},
	langid = {english},
	file = {Springer Full Text PDF:/Users/solomonkurz/Zotero/storage/T89ALUJW/Rouder - 2016 - The what, why, and how of born-open data.pdf:application/pdf}
}

@article{kleinPracticalGuideTransparency2018,
	title = {A practical guide for transparency in psychological science.},
	volume = {4},
	issn = {2474-7394},
	url = {https://lirias.kuleuven.be/1999530},
	doi = {10.1525/collabra.158},
	abstract = {© 2018 The Author(s). The credibility of scientific claims depends upon the transparency of the research products upon which they are based (e.g., study protocols, data, materials, and analysis scripts). As psychology navigates a period of unprecedented introspection, user-friendly tools and services that support open science have flourished. However, the plethora of decisions and choices involved can be bewildering. Here we provide a practical guide to help researchers navigate the process of preparing and sharing the products of their research (e.g., choosing a repository, preparing their research products for sharing, structuring folders, etc.). Being an open scientist means adopting a few straightforward research management practices, which lead to less error prone, reproducible research workflows. Further, this adoption can be piecemeal – each incremental step towards complete transparency adds positive value. Transparent research practices not only improve the efficiency of individual researchers, they enhance the credibility of the knowledge generated by the scientific community.},
	pages = {1--15},
	number = {1},
	journaltitle = {Collabra: Psychology},
	author = {Klein, O. and Hardwicke, T. E. and Aust, F. and Breuer, J. and Danielsson, H. and Hofelich Mohr, A. and {IJzerman}, H. and Nilsonne, G. and Vanpaemel, W. and Frank, M. C.},
	urldate = {2020-05-18},
	date = {2018-06},
	note = {Publisher: The Regents of the University of California},
	file = {Full Text PDF:/Users/solomonkurz/Zotero/storage/439IHJWF/Klein et al. - 2018 - A practical guide for transparency in psychologica.pdf:application/pdf;Snapshot:/Users/solomonkurz/Zotero/storage/AKE5WGPW/1999530.html:text/html}
}

@article{martoneDataSharingPsychology2018,
	title = {Data sharing in psychology},
	volume = {73},
	issn = {0003-066X},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5920518/pdf/nihms935471.pdf},
	doi = {10.1037/amp0000242},
	abstract = {Routine data sharing, defined here as the publication of the primary data and any supporting materials required to interpret the data acquired as part of a research study, is still in its infancy in psychology, as in many domains. Nevertheless, with increased scrutiny on reproducibility and more funder mandates requiring sharing of data, the issues surrounding data sharing are moving beyond whether data sharing is a benefit or a bane to science, to what data should be shared and how. Here, we present an overview of these issues, specifically focusing on the sharing of so-called “long tail” data, that is, data generated by individual laboratories as part of largely hypothesis-driven research. We draw on experiences in other domains to discuss attitudes towards data sharing, cost-benefits, best practices and infrastructure. We argue that the publishing of data sets is an integral component of 21st century scholarship. Moreover, although not all issues around how and what to share have been resolved, a consensus on principles and best practices for effective data sharing and the infrastructure for sharing many types of data are largely in place.},
	pages = {111--125},
	number = {2},
	journaltitle = {The American psychologist},
	shortjournal = {Am Psychol},
	author = {Martone, Maryann E. and Garcia-Castro, Alexander and {VandenBos}, Gary R.},
	urldate = {2020-05-18},
	date = {2018},
	pmid = {29481105},
	pmcid = {PMC5920518},
	file = {PubMed Central Full Text PDF:/Users/solomonkurz/Zotero/storage/JXPYAVVI/Martone et al. - 2018 - Data Sharing in Psychology.pdf:application/pdf}
}

@article{hyndmanComputingGraphingHighest1996,
	title = {Computing and graphing highest density regions},
	volume = {50},
	issn = {0003-1305},
	url = {https://amstat.tandfonline.com/doi/abs/10.1080/00031305.1996.10474359},
	doi = {10.1080/00031305.1996.10474359},
	abstract = {Many statistical methods involve summarizing a probability distribution by a region of the sample space covering a specified probability. One method of selecting such a region is to require it to contain points of relatively high density. Highest density regions are particularly useful for displaying multimodal distributions and, in such cases, may consist of several disjoint subsets—one for each local mode. In this paper, I propose a simple method for computing a highest density region from any given (possibly multivariate) density f(x) that is bounded and continuous in x. Several examples of the use of highest density regions in statistical graphics are also given. A new form of boxplot is proposed based on highest density regions; versions in one and two dimensions are given. Highest density regions in higher dimensions are also discussed and plotted.},
	pages = {120--126},
	number = {2},
	journaltitle = {The American Statistician},
	shortjournal = {The American Statistician},
	author = {Hyndman, Rob J.},
	urldate = {2020-05-18},
	date = {1996-05-01},
	note = {Publisher: Taylor \& Francis},
	file = {Snapshot:/Users/solomonkurz/Zotero/storage/RTPEUENN/00031305.1996.html:text/html}
}

@article{chenMonteCarloEstimation1999,
	title = {Monte Carlo estimation of Bayesian credible and {HPD} intervals},
	volume = {8},
	issn = {1061-8600},
	url = {https://www.researchgate.net/publication/2442323_Monte_Carlo_Estimation_of_Bayesian_Credible_and_HPD_Intervals},
	doi = {10.1080/10618600.1999.10474802},
	abstract = {This article considers how to estimate Bayesian credible and highest probability density ({HPD}) intervals for parameters of interest and provides a simple Monte Carlo approach to approximate these Bayesian intervals when a sample of the relevant parameters can be generated from their respective marginal posterior distribution using a Markov chain Monte Carlo ({MCMC}) sampling algorithm. We also develop a Monte Carlo method to compute {HPD} intervals for the parameters of interest from the desired posterior distribution using a sample from an importance sampling distribution. We apply our methodology to a Bayesian hierarchical model that has a posterior density containing analytically intractable integrals that depend on the (hyper) parameters. We further show that our methods are useful not only for calculating the {HPD} intervals for the parameters of interest but also for computing the {HPD} intervals for functions of the parameters. Necessary theory is developed and illustrative examples—including a simulation study—are given.},
	pages = {69--92},
	number = {1},
	journaltitle = {Journal of Computational and Graphical Statistics},
	shortjournal = {Journal of Computational and Graphical Statistics},
	author = {Chen, Ming-Hui and Shao, Qi-Man},
	urldate = {2020-05-18},
	date = {1999-03-01},
	note = {Publisher: Taylor \& Francis},
	file = {Snapshot:/Users/solomonkurz/Zotero/storage/A37BJW48/10618600.1999.html:text/html}
}

@incollection{chenMonteCarloGap2003,
	title = {A Monte Carlo gap test in computing {HPD} regions},
	volume = {Volume 1},
	isbn = {978-981-238-395-2},
	url = {https://www.researchgate.net/publication/264969946_A_Monte_Carlo_gap_test_in_computing_HPD_regions},
	series = {Series in Biostatistics},
	volumes = {0},
	pages = {38--52},
	number = {Volume 1},
	booktitle = {Development of Modern Statistics and Related Topics},
	publisher = {World Scientific},
	author = {Chen, Ming-Hui and He, Xuming and Shao, Qi-Man and Xu, Hai},
	urldate = {2020-05-18},
	date = {2003-06-01},
	doi = {10.1142/9789812796707_0004},
	file = {Snapshot:/Users/solomonkurz/Zotero/storage/ZSZ4HUD3/9789812796707_0004.html:text/html}
}

@online{BibTeX2020,
	title = {{BibTeX}},
	url = {http://www.bibtex.org/},
	urldate = {2020-05-19},
	date = {2020},
	file = {BibTeX:/Users/solomonkurz/Zotero/storage/PMDJYC3M/www.bibtex.org.html:text/html}
}

@online{heynsBetterBibTeXZotero2020,
	title = {Better {BibTeX} for zotero},
	url = {https://retorque.re/zotero-better-bibtex/},
	author = {Heyns, Emiliano},
	urldate = {2020-05-19},
	date = {2020}
}

@book{R-bookdown,
	title = {{\textless}span class="nocase"{\textgreater}bookdown{\textless}/span{\textgreater}: Authoring books and technical documents with R Markdown},
	url = {https://CRAN.R-project.org/package=bookdown},
	author = {Xie, Yihui},
	date = {2020}
}

@article{hanleySexualActivityLifespan1994,
	title = {Sexual activity and the lifespan of male fruitflies: A dataset that gets attention},
	volume = {2},
	issn = {null},
	url = {https://doi.org/10.1080/10691898.1994.11910467},
	doi = {10.1080/10691898.1994.11910467},
	shorttitle = {Sexual Activity and the Lifespan of Male Fruitflies},
	abstract = {This dataset contains observations on five groups of male fruitflies –– 25 fruitflies in each group –– from an experiment designed to test if increased reproduction reduces longevity for male fruitflies. (Such a cost has already been established for females.) The five groups are: males forced to live alone, males assigned to live with one or eight interested females, and males assigned to live with one or eight non-receptive females. The observations on each fly were longevity, thorax length, and the percentage of each day spent sleeping. The structure of the experiment provokes lively discussion on experimental design and on contrasts, and gives students opportunities to understand and verbalize what we mean by the term “statistical interaction.” Because the variable thorax length has a strong effect on survival, it is important to take it into account to increase the precision of between-group contrasts, even though it is distributed similarly across groups. The dataset can also be used to illustrate techniques of survival analysis.},
	pages = {null},
	number = {1},
	journaltitle = {Journal of Statistics Education},
	author = {Hanley, A, James and Shapiro, H, Stanley},
	urldate = {2020-05-19},
	date = {1994-07-01},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/10691898.1994.11910467},
	keywords = {Analysis of covariance, Experiment, Longevity, Precision, Regression, Survival analysis},
	file = {Full Text PDF:/Users/solomonkurz/Zotero/storage/3XL9TZQK/A and H - 1994 - Sexual Activity and the Lifespan of Male Fruitflie.pdf:application/pdf;Snapshot:/Users/solomonkurz/Zotero/storage/5G6CU48Y/10691898.1994.html:text/html}
}

@book{mcelreathStatisticalRethinkingBayesian2020,
	edition = {Second Edition},
	title = {Statistical rethinking: A Bayesian course with examples in R and Stan},
	isbn = {978-0-429-63914-2},
	url = {https://xcelab.net/rm/statistical-rethinking/},
	shorttitle = {Statistical Rethinking},
	abstract = {Statistical Rethinking: A Bayesian Course with Examples in R and Stan builds your knowledge of and confidence in making inferences from data. Reflecting the need for scripting in today's model-based statistics, the book pushes you to perform step-by-step calculations that are usually automated. This unique computational approach ensures that you understand enough of the details to make reasonable choices and interpretations in your own modeling work.  The text presents causal inference and generalized linear multilevel models from a simple Bayesian perspective that builds on information theory and maximum entropy. The core material ranges from the basics of regression to advanced multilevel models. It also presents measurement error, missing data, and Gaussian process models for spatial and phylogenetic confounding.  The second edition emphasizes the directed acyclic graph ({DAG}) approach to causal inference, integrating {DAGs} into many examples. The new edition also contains new material on the design of prior distributions, splines, ordered categorical predictors, social relations models, cross-validation, importance sampling, instrumental variables, and Hamiltonian Monte Carlo. It ends with an entirely new chapter that goes beyond generalized linear modeling, showing how domain-specific scientific models can be built into statistical analyses.  Features   Integrates working code into the main text   Illustrates concepts through worked data analysis examples   Emphasizes understanding assumptions and how assumptions are reflected in code   Offers more detailed explanations of the mathematics in optional sections   Presents examples of using the dagitty R package to analyze causal graphs   Provides the rethinking R package on the author's website and on {GitHub}},
	pagetotal = {575},
	publisher = {{CRC} Press},
	author = {{McElreath}, Richard},
	date = {2020-03-13},
	langid = {english},
	keywords = {Mathematics / Probability \& Statistics / General}
}

@book{agrestiFoundationsLinearGeneralized2015,
	title = {Foundations of linear and generalized linear models},
	isbn = {978-1-118-73005-8},
	url = {https://www.wiley.com/en-us/Foundations+of+Linear+and+Generalized+Linear+Models-p-9781118730034},
	abstract = {A valuable overview of the most important ideas and results in statistical modeling Written by a highly-experienced author, Foundations of Linear and Generalized Linear Models is a clear and comprehensive guide to the key concepts and results of linearstatistical models. The book presents a broad, in-depth overview of the most commonly usedstatistical models by discussing the theory underlying the models, R software applications,and examples with crafted models to elucidate key ideas and promote practical modelbuilding. The book begins by illustrating the fundamentals of linear models, such as how the model-fitting projects the data onto a model vector subspace and how orthogonal decompositions of the data yield information about the effects of explanatory variables. Subsequently, the book covers the most popular generalized linear models, which include binomial and multinomial logistic regression for categorical data, and Poisson and negative binomial loglinear models for count data. Focusing on the theoretical underpinnings of these models, Foundations {ofLinear} and Generalized Linear Models also features:  An introduction to quasi-likelihood methods that require weaker distributional assumptions, such as generalized estimating equation methods An overview of linear mixed models and generalized linear mixed models with random effects for clustered correlated data, Bayesian modeling, and extensions to handle problematic cases such as high dimensional problems Numerous examples that use R software for all text data analyses More than 400 exercises for readers to practice and extend the theory, methods, and data analysis A supplementary website with datasets for the examples and exercises  An invaluable textbook for upper-undergraduate and graduate-level students in statistics and biostatistics courses, Foundations of Linear and Generalized Linear Models is also an excellent reference for practicing statisticians and biostatisticians, as well as anyone who is interested in learning about the most important statistical models for analyzing data.},
	pagetotal = {469},
	publisher = {John Wiley \& Sons},
	author = {Agresti, Alan},
	date = {2015-01-15},
	langid = {english},
	note = {Google-Books-{ID}: {dgIzBgAAQBAJ}},
	keywords = {Mathematics / Probability \& Statistics / General, Mathematics / Probability \& Statistics / Stochastic Processes}
}

@book{R-GGally,
	title = {{\textless}span class="nocase"{\textgreater}{GGally}{\textless}/span{\textgreater}: Extension to {\textless}span class="nocase"{\textgreater}'ggplot2'{\textless}/span{\textgreater}},
	url = {https://CRAN.R-project.org/package=GGally},
	author = {Schloerke, Barret and Crowley, Jason and {Di Cook} and Briatte, Francois and Marbach, Moritz and Thoen, Edwin and Elberg, Amos and Larmarange, Joseph},
	date = {2021}
}

@article{gabryPlottingMCMCDraws2019,
	title = {Plotting {MCMC} draws using the bayesplot package},
	url = {https://CRAN.R-project.org/package=bayesplot/vignettes/plotting-mcmc-draws.html},
	author = {Gabry, Jonah},
	urldate = {2020-05-26},
	date = {2020-05-27}
}

@article{vehtariPracticalBayesianModel2017,
	title = {Practical Bayesian model evaluation using leave-one-out cross-validation and {WAIC}},
	volume = {27},
	issn = {1573-1375},
	url = {https://arxiv.org/pdf/1507.04544.pdf},
	doi = {10.1007/s11222-016-9696-4},
	abstract = {Leave-one-out cross-validation ({LOO}) and the widely applicable information criterion ({WAIC}) are methods for estimating pointwise out-of-sample prediction accuracy from a fitted Bayesian model using the log-likelihood evaluated at the posterior simulations of the parameter values. {LOO} and {WAIC} have various advantages over simpler estimates of predictive error such as {AIC} and {DIC} but are less used in practice because they involve additional computational steps. Here we lay out fast and stable computations for {LOO} and {WAIC} that can be performed using existing simulation draws. We introduce an efficient computation of {LOO} using Pareto-smoothed importance sampling ({PSIS}), a new procedure for regularizing importance weights. Although {WAIC} is asymptotically equal to {LOO}, we demonstrate that {PSIS}-{LOO} is more robust in the finite case with weak priors or influential observations. As a byproduct of our calculations, we also obtain approximate standard errors for estimated predictive errors and for comparison of predictive errors between two models. We implement the computations in an R package called loo and demonstrate using models fit with the Bayesian inference package Stan.},
	pages = {1413--1432},
	number = {5},
	journaltitle = {Statistics and Computing},
	shortjournal = {Stat Comput},
	author = {Vehtari, Aki and Gelman, Andrew and Gabry, Jonah},
	urldate = {2020-06-03},
	date = {2017-09-01},
	langid = {english},
	file = {Submitted Version:/Users/solomonkurz/Zotero/storage/I7HY567V/Vehtari et al. - 2017 - Practical Bayesian model evaluation using leave-on.pdf:application/pdf}
}

@book{R-loo,
	title = {{\textless}span class="nocase"{\textgreater}loo{\textless}/span{\textgreater}: Efficient leave-one-out cross-validation and {WAIC} for bayesian models},
	url = {https://CRAN.R-project.org/package=loo/},
	author = {Vehtari, Aki and Gabry, Jonah and Magnusson, Mans and Yao, Yuling and Gelman, Andrew},
	date = {2022}
}

@book{R-ggthemes,
	title = {{\textless}span class="nocase"{\textgreater}ggthemes{\textless}/span{\textgreater}: Extra themes, scales and geoms for {\textless}span class="nocase"{\textgreater}'ggplot2'{\textless}/span{\textgreater}},
	url = {https://CRAN.R-project.org/package=ggthemes},
	author = {Arnold, Jeffrey B.},
	date = {2021}
}

@article{casellaExplainingGibbsSampler1992,
	title = {Explaining the Gibbs sampler},
	volume = {46},
	issn = {0003-1305},
	url = {https://ecommons.cornell.edu/bitstream/handle/1813/31670/BU-1098-MA.Revised.pdf?sequence=1},
	doi = {10.1080/00031305.1992.10475878},
	abstract = {Computer-intensive algorithms, such as the Gibbs sampler, have become increasingly popular statistical tools, both in applied and theoretical work. The properties of such algorithms, however, may sometimes not be obvious. Here we give a simple explanation of how and why the Gibbs sampler works. We analytically establish its properties in a simple case and provide insight for more complicated cases. There are also a number of examples.},
	pages = {167--174},
	number = {3},
	journaltitle = {The American Statistician},
	author = {Casella, George and George, Edward I.},
	urldate = {2020-06-11},
	date = {1992-08-01},
	note = {Publisher: Taylor \& Francis
\_eprint: https://www.tandfonline.com/doi/pdf/10.1080/00031305.1992.10475878},
	keywords = {Data augmentation, Markov chains, Monte Carlo methods, Resampling techniques},
	file = {Snapshot:/Users/solomonkurz/Zotero/storage/SFZUD4XZ/00031305.1992.html:text/html;Submitted Version:/Users/solomonkurz/Zotero/storage/7G3SEDKK/Casella and George - 1992 - Explaining the Gibbs Sampler.pdf:application/pdf}
}

@article{atkinsTutorialOnCount2013,
	title = {A tutorial on count regression and zero-altered count models for longitudinal substance use data.},
	volume = {27},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3513584/pdf/nihms396181.pdf},
	doi = {10.1037/a0029508},
	pages = {166},
	number = {1},
	journaltitle = {Psychology of Addictive Behaviors},
	author = {Atkins, David C and Baldwin, Scott A and Zheng, Cheng and Gallop, Robert J and Neighbors, Clayton},
	date = {2013},
	note = {Publisher: American Psychological Association}
}

@report{R-cowplot,
	title = {{\textless}span class="nocase"{\textgreater}cowplot{\textless}/span{\textgreater}: Streamlined plot theme and plot annotations for 'ggplot2'},
	url = {https://wilkelab.org/cowplot},
	type = {manual},
	author = {Wilke, Claus O.},
	date = {2020}
}

@book{wilkeFundamentalsDataVisualization2019,
	title = {Fundamentals of data visualization},
	url = {https://clauswilke.com/dataviz/},
	abstract = {A guide to making visualizations that accurately reflect the data, tell a story, and look professional.},
	author = {Wilke, Claus O.},
	urldate = {2020-08-24},
	date = {2019},
	file = {Snapshot:/Users/solomonkurz/Zotero/storage/URYRTXWA/dataviz.html:text/html}
}

@article{Wilke2019Themes,
	title = {Themes},
	url = {https://wilkelab.org/cowplot/articles/themes.html},
	author = {Wilke, Claus O.},
	date = {2019-07-11}
}

@report{R-colorblindr,
	title = {{\textless}span class="nocase"{\textgreater}colorblindr{\textless}/span{\textgreater}: Simulate colorblindness in R figures},
	url = {https://github.com/clauswilke/colorblindr},
	type = {manual},
	author = {{McWhite}, Claire D. and Wilke, Claus O.},
	date = {2021}
}

@artwork{HokusaiGreatWaveOffKanagawa1820,
	title = {The great wave off Kanagawa},
	author = {Hokusai, Katsushika},
	date = {1820},
	note = {Medium: woodblock print
tex.referencetype: artwork}
}

@report{R-lisa,
	title = {{\textless}span class="nocase"{\textgreater}lisa{\textless}/span{\textgreater}: Color palettes from color lisa},
	url = {https://CRAN.R-project.org/package=lisa},
	type = {manual},
	author = {Littlefield, Tyler},
	date = {2020}
}

@artwork{jeanRiftScull2009,
	title = {{RIFT} {SCULL}},
	author = {Jean, James},
	date = {2009},
	note = {tex.referencetype: artwork}
}

@report{R-fishualize,
	title = {{\textless}span class="nocase"{\textgreater}fishualize{\textless}/span{\textgreater}: Color palettes based on fish species},
	url = {https://CRAN.R-project.org/package=fishualize},
	type = {manual},
	author = {Schiettekatte, Nina M. D. and Brandl, Simon J. and Casey, Jordan M.},
	date = {2022}
}

@book{R-beyonce,
	title = {{\textless}span class="nocase"{\textgreater}beyonce{\textless}/span{\textgreater}: Beyoncé colour palettes for R},
	url = {https://github.com/dill/beyonce},
	author = {Miller, David Lawrence},
	date = {2021}
}

@report{R-palettetown,
	title = {{\textless}span class="nocase"{\textgreater}palettetown{\textless}/span{\textgreater}: Use Pokemon inspired colour palettes},
	url = {https://CRAN.R-project.org/package=palettetown},
	type = {manual},
	author = {Lucas, Tim},
	date = {2016}
}

@inproceedings{kayWhenIshMy2016,
	location = {New York, {NY}, {USA}},
	title = {When (ish) is my bus? User-centered visualizations of uncertainty in everyday, mobile predictive systems},
	isbn = {978-1-4503-3362-7},
	url = {https://doi.org/10.1145/2858036.2858558},
	doi = {10.1145/2858036.2858558},
	series = {{CHI} '16},
	shorttitle = {When (ish) is My Bus?},
	abstract = {Users often rely on realtime predictions in everyday contexts like riding the bus, but may not grasp that such predictions are subject to uncertainty. Existing uncertainty visualizations may not align with user needs or how they naturally reason about probability. We present a novel mobile interface design and visualization of uncertainty for transit predictions on mobile phones based on discrete outcomes. To develop it, we identified domain specific design requirements for visualizing uncertainty in transit prediction through: 1) a literature review, 2) a large survey of users of a popular realtime transit application, and 3) an iterative design process. We present several candidate visualizations of uncertainty for realtime transit predictions in a mobile context, and we propose a novel discrete representation of continuous outcomes designed for small screens, quantile dotplots. In a controlled experiment we find that quantile dotplots reduce the variance of probabilistic estimates by {\textasciitilde}1.15 times compared to density plots and facilitate more confident estimation by end-users in the context of realtime transit prediction scenarios.},
	pages = {5092--5103},
	booktitle = {Proceedings of the 2016 {CHI} Conference on Human Factors in Computing Systems},
	publisher = {Association for Computing Machinery},
	author = {Kay, Matthew and Kola, Tara and Hullman, Jessica R. and Munson, Sean A.},
	urldate = {2020-09-05},
	date = {2016-05-07},
	keywords = {dotplots, end-user visualization, mobile interfac-es, transit predictions, uncertainty visualization}
}

@incollection{fernandesUncertaintyDisplaysUsing2018,
	location = {New York, {NY}, {USA}},
	title = {Uncertainty displays using quantile dotplots or {CDFs} improve transit decision-making},
	isbn = {978-1-4503-5620-6},
	url = {https://doi.org/10.1145/3173574.3173718},
	abstract = {Everyday predictive systems typically present point predictions, making it hard for people to account for uncertainty when making decisions. Evaluations of uncertainty displays for transit prediction have assessed people's ability to extract probabilities, but not the quality of their decisions. In a controlled, incentivized experiment, we had subjects decide when to catch a bus using displays with textual uncertainty, uncertainty visualizations, or no-uncertainty (control). Frequency-based visualizations previously shown to allow people to better extract probabilities (quantile dotplots) yielded better decisions. Decisions with quantile dotplots with 50 outcomes were(1) better on average, having expected payoffs 97\% of optimal(95\% {CI}: [95\%,98\%]), 5 percentage points more than control (95\% {CI}: [2,8]); and (2) more consistent, having within-subject standard deviation of 3 percentage points (95\% {CI}:[2,4]), 4 percentage points less than control (95\% {CI}: [2,6]).Cumulative distribution function plots performed nearly as well, and both outperformed textual uncertainty, which was sensitive to the probability interval communicated. We discuss implications for real time transit predictions and possible generalization to other domains.},
	pages = {1--12},
	booktitle = {Proceedings of the 2018 {CHI} Conference on Human Factors in Computing Systems},
	publisher = {Association for Computing Machinery},
	author = {Fernandes, Michael and Walls, Logan and Munson, Sean and Hullman, Jessica and Kay, Matthew},
	urldate = {2020-09-05},
	date = {2018-04-19},
	keywords = {dotplots, transit predictions, uncertainty visualization, cumulative distribution plots, mobileinterfaces}
}

@report{R-PNWColors,
	title = {{PNWColors}: Color palettes inspired by nature in the {US} Pacific Northwest},
	url = {https://CRAN.R-project.org/package=PNWColors},
	type = {manual},
	author = {Lawlor, Jake},
	date = {2020}
}

@report{R-directlabels,
	title = {directlabels: Direct labels for multicolor plots},
	url = {https://CRAN.R-project.org/package=directlabels},
	type = {manual},
	author = {Hocking, Toby Dylan},
	date = {2021}
}

@report{R-ochRe,
	title = {{ochRe}: Australia-themed colour palettes},
	url = {https://github.com/ropenscilabs/ochRe},
	type = {manual},
	author = {Allan, Alicia and Cook, Di and Gayler, Ross and Kirk, Holly and Peng, Roger and Saber, Elle},
	date = {2021}
}

@report{R-scico,
	title = {{\textless}span class="nocase"{\textgreater}scico{\textless}/span{\textgreater}: Colour palettes based on the scientific colour-maps},
	url = {https://CRAN.R-project.org/package=scico},
	type = {manual},
	author = {Pedersen, Thomas Lin and Crameri, Fabio},
	date = {2021}
}

@report{R-ggforce,
	title = {{\textless}span class="nocase"{\textgreater}ggforce{\textless}/span{\textgreater}: Accelerating '{\textless}span class="nocase"{\textgreater}ggplot2{\textless}/span{\textgreater}'},
	url = {https://CRAN.R-project.org/package=ggforce},
	type = {manual},
	author = {Pedersen, Thomas Lin},
	date = {2021}
}

@online{pedersenDrawPolygonsExpansion,
	title = {Draw polygons with expansion/contraction and/or rounded corners — geom\_shape},
	url = {https://ggforce.data-imaginist.com/reference/geom_shape.html},
	abstract = {This geom is a cousin of ggplot2::geom\_polygon() with the added
possibility of expanding or contracting the polygon by an absolute amount
(e.g. 1 cm). Furthermore, it is possible to round the corners of the polygon,
again by an absolute amount. The resulting geom reacts to resizing of the
plot, so the expansion/contraction and corner radius will not get distorted.
If no expansion/contraction or corner radius is specified, the geom falls
back to geom\_polygon so there is no performance penality in using this
instead of geom\_polygon.},
	author = {Pedersen, Thomas Lin},
	urldate = {2020-09-11},
	langid = {english},
	file = {Snapshot:/Users/solomonkurz/Zotero/storage/MMJ6P7YD/geom_shape.html:text/html}
}

@online{vehtariUsingLooPackage2020,
	title = {Using the loo package (version {\textgreater}= 2.0.0)},
	url = {https://CRAN.R-project.org/package=loo/vignettes/loo2-example.html},
	author = {Vehtari, Aki and Gabry, Jonah},
	urldate = {2020-09-15},
	date = {2020-07-14},
	file = {Using the loo package (version >= 2.0.0):/Users/solomonkurz/Zotero/storage/QQ6SLVSV/loo2-example.html:text/html}
}

@book{R-cubelyr,
	title = {{\textless}span class="nocase"{\textgreater}cubelyr{\textless}/span{\textgreater}: A data cube 'dplyr' backend},
	url = {https://CRAN.R-project.org/package=cubelyr},
	author = {Wickham, Hadley},
	date = {2020}
}

@report{R-ggmcmc,
	title = {{\textless}span class="nocase"{\textgreater}ggmcmc{\textless}/span{\textgreater}: Tools for analyzing {MCMC} simulations from {\textless}span class="nocase"{\textgreater}Bayesian{\textless}/span{\textgreater} inference},
	url = {https://CRAN.R-project.org/package=ggmcmc},
	type = {manual},
	author = {Fernández i Marín, Xavier},
	date = {2021}
}

@article{fernandezGGMCMCAnalysisofMCMC2016,
	title = {{\textless}span class="nocase"{\textgreater}ggmcmc{\textless}/span{\textgreater}: Analysis of {MCMC} samples and Bayesian inference},
	volume = {70},
	doi = {10.18637/jss.v070.i09},
	pages = {1--20},
	number = {9},
	journaltitle = {Journal of Statistical Software},
	author = {Fernández i Marín, Xavier},
	date = {2016}
}

@report{R-viridis,
	title = {{\textless}span class="nocase"{\textgreater}viridis{\textless}/span{\textgreater}: Default color maps from 'matplotlib'},
	url = {https://CRAN.R-project.org/package=viridis},
	type = {manual},
	author = {Garnier, Simon},
	date = {2021}
}

@book{cummingUnderstandingTheNewStatistics2012,
	title = {Understanding the new statistics: Effect sizes, confidence intervals, and meta-analysis},
	isbn = {978-0-415-87967-5},
	url = {https://www.routledge.com/Understanding-The-New-Statistics-Effect-Sizes-Confidence-Intervals-and/Cumming/p/book/9780415879682},
	publisher = {Routledge},
	author = {Cumming, Geoff},
	date = {2012}
}

@article{pekReportingEffectSizes2018,
	title = {Reporting effect sizes in original psychological research: A discussion and tutorial},
	volume = {23},
	doi = {https://doi.apa.org/fulltext/2017-10871-001.html},
	pages = {208},
	number = {2},
	journaltitle = {Psychological Methods},
	author = {Pek, Jolynn and Flora, David B},
	date = {2018},
	note = {Publisher: American Psychological Association}
}

@article{Bürkner2021Define,
	title = {Define custom response distributions with brms},
	url = {https://CRAN.R-project.org/package=brms/vignettes/brms_customfamilies.html},
	author = {Bürkner, Paul-Christian},
	date = {2021-03}
}

@article{Bürkner2021Distributional,
	title = {Estimating distributional models with brms},
	url = {https://CRAN.R-project.org/package=brms/vignettes/brms_distreg.html},
	author = {Bürkner, Paul-Christian},
	date = {2021-03}
}

@article{Bürkner2021Multivariate,
	title = {Estimating multivariate models with brms},
	url = {https://CRAN.R-project.org/package=brms/vignettes/brms_multivariate.html},
	author = {Bürkner, Paul-Christian},
	date = {2021-03}
}

@article{Bürkner2021Non_linear,
	title = {Estimating non-linear models with brms},
	url = {https://CRAN.R-project.org/package=brms/vignettes/brms_nonlinear.html},
	author = {Bürkner, Paul-Christian},
	date = {2021-03}
}

@article{Bürkner2021Parameterization,
	title = {Parameterization of response distributions in brms},
	url = {https://CRAN.R-project.org/package=brms/vignettes/brms_families.html},
	author = {Bürkner, Paul-Christian},
	date = {2021-03}
}

@book{brms2021RM,
	title = {{\textless}span class="nocase"{\textgreater}brms{\textless}/span{\textgreater} reference manual, Version 2.15.0},
	url = {https://CRAN.R-project.org/package=brms/brms.pdf},
	author = {Bürkner, Paul-Christian},
	date = {2021}
}

@report{R-coda,
	title = {{\textless}span class="nocase"{\textgreater}coda{\textless}/span{\textgreater}: Output analysis and diagnostics for {MCMC}},
	url = {https://CRAN.R-project.org/package=coda},
	type = {manual},
	author = {Plummer, Martyn and Best, Nicky and Cowles, Kate and Vines, Karen and Sarkar, Deepayan and Bates, Douglas and Almond, Russell and Magnusson, Arni},
	date = {2020}
}

@article{plummerCODA2006,
	title = {{CODA}: Convergence diagnosis and output analysis for {MCMC}},
	volume = {6},
	url = {https://journal.r-project.org/archive/},
	pages = {7--11},
	number = {1},
	journaltitle = {R News},
	author = {Plummer, Martyn and Best, Nicky and Cowles, Kate and Vines, Karen},
	date = {2006},
	note = {tex.pdf: https://www.r-project.org/doc/Rnews/Rnews₂006-1.pdf}
}

@book{kurzStatisticalRethinkingSecondEd2021,
	edition = {version 0.2.0},
	title = {Statistical rethinking with brms, {\textless}span class="nocase"{\textgreater}ggplot2{\textless}/span{\textgreater}, and the tidyverse: Second Edition},
	url = {https://bookdown.org/content/4857/},
	abstract = {This book is an attempt to re-express the code in the second edition of {McElreath}'s textbook, 'Statistical rethinking.' His models are re-fit in brms, plots are redone with ggplot2, and the general data wrangling code predominantly follows the tidyverse style.},
	author = {Kurz, A. Solomon},
	urldate = {2021-04-14},
	date = {2021-03}
}

@report{R-cowplot,
	title = {{\textless}span class="nocase"{\textgreater}cowplot{\textless}/span{\textgreater}: Streamlined plot theme and plot annotations for {\textless}span class="nocase"{\textgreater}ggplot2{\textless}/span{\textgreater}},
	url = {https://wilkelab.org/cowplot/},
	type = {manual},
	author = {Wilke, Claus O.},
	date = {2020}
}

@book{ZoteroYourPersonal2020,
	title = {Zotero},
	url = {https://www.zotero.org/},
	author = {{Roy Rosenzweig Center for History and New Media}},
	urldate = {2020-05-19},
	date = {2020},
	file = {www.zotero.org:/Users/solomonkurz/Zotero/storage/SUAPYKGF/www.zotero.org.html:text/html}
}

@report{R-posterior,
	title = {{\textless}span class="nocase"{\textgreater}posterior{\textless}/span{\textgreater}: Tools for working with posterior distributions},
	type = {manual},
	author = {Bürkner, Paul-Christian and Gabry, Jonah and Kay, Matthew and Vehtari, Aki},
	date = {2021}
}

@article{linde2021DecisionsAboutequivalence,
	title = {Decisions about equivalence: A comparison of {\textless}span class="nocase"{\textgreater}{TOST}, {HDI}-{ROPE}{\textless}/span{\textgreater}, and the Bayes factor.},
	doi = {https://doi.org/10.1037/met0000402},
	journaltitle = {Psychological Methods},
	author = {Linde, Maximilian and Tendeiro, Jorge N and Selker, Ravi and Wagenmakers, Eric-Jan and van Ravenzwaaij, Don},
	date = {2021},
	note = {Publisher: American Psychological Association}
}

@article{campbell2021re,
	title = {re: Linde et al.(2021)–The Bayes factor, {HDI}-{ROPE} and frequentist equivalence testing are actually all equivalent},
	url = {https://arxiv.org/abs/2104.07834},
	journaltitle = {{arXiv} preprint {arXiv}:2104.07834},
	author = {Campbell, Harlan and Gustafson, Paul},
	date = {2021}
}

@book{nicenboim2021introduction,
	title = {An introduction to {\textless}span class="nocase"{\textgreater}Bayesian{\textless}/span{\textgreater} data analysis for cognitive science},
	url = {https://vasishth.github.io/bayescogsci/book/},
	author = {Nicenboim, Bruno and Schad, Daniel and Vasishth, Shravan},
	date = {2021}
}

@article{weberRunningBrmsModels2022,
	title = {Running Brms Models with Within-Chain Parallelization},
	url = {https://CRAN.R-project.org/package=brms/vignettes/brms_threading.html},
	author = {Weber, Sebastian and Bürkner, Paul-Christian},
	date = {2022-04}
}

@book{xieBookdownAuthoringBooks2022,
	title = {bookdown: Authoring books and technical documents with R Markdown},
	url = {https://bookdown.org/yihui/bookdown/},
	publisher = {Chapman and Hall/{CRC}},
	author = {Xie, Yihui},
	date = {2022}
}

@book{xieMarkdownDefinitiveGuide2022,
	title = {R Markdown: The definitive guide},
	url = {https://bookdown.org/yihui/rmarkdown/},
	publisher = {Chapman and Hall/{CRC}},
	author = {Xie, Yihui and Allaire, J. J. and Grolemund, Garrett},
	date = {2022}
}

@book{pengProgrammingDataScience2020,
	title = {R programming for data science},
	url = {https://bookdown.org/rdpeng/rprogdatascience/},
	author = {Peng, Roger D.},
	date = {2020}
}

@misc{kayExtractingVisualizingTidy2021,
	title = {Extracting and visualizing tidy draws from brms models},
	url = {https://mjskay.github.io/tidybayes/articles/tidy-brms.html},
	abstract = {tidybayes},
	author = {Kay, Matthew},
	urldate = {2022-04-15},
	date = {2021-12}
}

@book{StanReferenceManual2022,
	title = {Stan Reference Manual, Version 2.29},
	url = {https://mc-stan.org/docs/2_29/reference-manual/},
	date = {2022}
}

@article{vehtariRanknormalizationFoldingLocalization2021,
	title = {Rank-normalization, folding, and localization: An improved \${\textbackslash}{widehatR}\$ for assessing convergence of {MCMC} (with Discussion)},
	volume = {16},
	doi = {10.1214/20-BA1221},
	pages = {667--718},
	number = {2},
	journaltitle = {Bayesian analysis},
	author = {Vehtari, Aki and Gelman, Andrew and Simpson, Daniel and Carpenter, Bob and Bürkner, Paul-Christian},
	date = {2021},
	note = {Publisher: International Society for Bayesian Analysis}
}

@misc{standevelopmentteamAccessingContentsStanfit2022,
	title = {Accessing the contents of a stanfit object},
	url = {https://CRAN.R-project.org/package=rstan/vignettes/stanfit-objects.html},
	author = {{Stan Development Team}},
	urldate = {2022-04-15},
	date = {2022-04}
}

@article{Wilke2020Themes,
	title = {Themes},
	url = {https://wilkelab.org/cowplot/articles/themes.html},
	author = {Wilke, Claus O.},
	date = {2020-12}
}

@article{Bürkner2022Define,
	title = {Define custom response distributions with brms},
	url = {https://CRAN.R-project.org/package=brms/vignettes/brms_customfamilies.html},
	author = {Bürkner, Paul-Christian},
	date = {2022-04}
}

@article{Bürkner2022Distributional,
	title = {Estimating distributional models with brms},
	url = {https://CRAN.R-project.org/package=brms/vignettes/brms_distreg.html},
	author = {Bürkner, Paul-Christian},
	date = {2022-04}
}

@article{Bürkner2022Multivariate,
	title = {Estimating multivariate models with brms},
	url = {https://CRAN.R-project.org/package=brms/vignettes/brms_multivariate.html},
	author = {Bürkner, Paul-Christian},
	date = {2022-04}
}

@article{Bürkner2022Non_linear,
	title = {Estimating non-linear models with brms},
	url = {https://CRAN.R-project.org/package=brms/vignettes/brms_nonlinear.html},
	author = {Bürkner, Paul-Christian},
	date = {2022-04}
}

@article{Bürkner2022Parameterization,
	title = {Parameterization of response distributions in brms},
	url = {https://CRAN.R-project.org/package=brms/vignettes/brms_families.html},
	author = {Bürkner, Paul-Christian},
	date = {2022-04}
}

@book{brms2022RM,
	title = {brms Reference Manual, Version 2.17.0},
	url = {https://CRAN.R-project.org/package=brms/brms.pdf},
	author = {Bürkner, Paul-Christian},
	date = {2022}
}

@book{standevelopmentteamStanUserGuide2022,
	title = {Stan User's Guide, Version 2.29},
	url = {https://mc-stan.org/docs/2_29/stan-users-guide/index.html},
	author = {{Stan Development Team}},
	date = {2022}
}

@misc{kaySlabIntervalStats2022,
	title = {Slab + interval stats and geoms},
	url = {https://mjskay.github.io/ggdist/articles/slabinterval.html},
	abstract = {ggdist},
	author = {Kay, Matthew},
	urldate = {2022-04-15},
	date = {2022-02}
}

@misc{vehtariUsingLooPackage2022,
	title = {Using the Loo Package (Version \${\textgreater}\$= 2.0.0)},
	url = {https://CRAN.R-project.org/package=loo/vignettes/loo2-example.html},
	author = {Vehtari, Aki and Gabry, Jonah},
	urldate = {2022-04-15},
	date = {2022-03}
}

@misc{gabryGraphicalPosteriorPredictive2022,
	title = {Graphical posterior predictive checks using the bayesplot package},
	url = {https://CRAN.R-project.org/package=bayesplot/vignettes/graphical-ppcs.html},
	author = {Gabry, Jonah},
	date = {2022-03}
}

@article{williamsBayesianMultivariateMixedeffects2021,
	title = {Bayesian multivariate mixed-effects location scale modeling of longitudinal relations among affective traits, states, and physical activity},
	doi = {https://doi.org/10.1027/1015-5759/a000624},
	journaltitle = {European Journal of Psychological Assessment},
	author = {Williams, Donald R and Martin, Stephen R and Liu, Siwei and Rast, Philippe},
	date = {2021},
	note = {Publisher: Hogrefe Publishing}
}

@book{standevelopmentteamStanReferenceManual2022,
	title = {Stan reference manual, Version 2.29},
	url = {https://mc-stan.org/docs/2_29/reference-manual/},
	author = {{Stan Development Team}},
	date = {2022}
}