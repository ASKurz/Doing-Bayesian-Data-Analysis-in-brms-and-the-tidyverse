<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>25 Tools in the Trunk | Doing Bayesian Data Analysis in brms and the tidyverse</title>
  <meta name="description" content="This project is an attempt to re-express the code in Kruschke’s (2015) textbook. His models are re-fit in brms, plots are redone with ggplot2, and the general data wrangling code predominantly follows the tidyverse style." />
  <meta name="generator" content="bookdown 0.18 and GitBook 2.6.7" />

  <meta property="og:title" content="25 Tools in the Trunk | Doing Bayesian Data Analysis in brms and the tidyverse" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This project is an attempt to re-express the code in Kruschke’s (2015) textbook. His models are re-fit in brms, plots are redone with ggplot2, and the general data wrangling code predominantly follows the tidyverse style." />
  <meta name="github-repo" content="ASKurz/Doing-Bayesian-Data-Analysis-in-brms-and-the-tidyverse" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="25 Tools in the Trunk | Doing Bayesian Data Analysis in brms and the tidyverse" />
  <meta name="twitter:site" content="@SolomonKurz" />
  <meta name="twitter:description" content="This project is an attempt to re-express the code in Kruschke’s (2015) textbook. His models are re-fit in brms, plots are redone with ggplot2, and the general data wrangling code predominantly follows the tidyverse style." />
  

<meta name="author" content="A Solomon Kurz" />


<meta name="date" content="2020-05-19" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="count-predicted-variable.html"/>
<link rel="next" href="references.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>What and why</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#we-have-updates"><i class="fa fa-check"></i>We have updates</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#version-0.1.0."><i class="fa fa-check"></i>Version 0.1.0.</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#version-0.2.0."><i class="fa fa-check"></i>Version 0.2.0.</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#were-not-done-yet-and-i-could-use-your-help."><i class="fa fa-check"></i>We’re not done yet and I could use your help.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#thank-yous-are-in-order"><i class="fa fa-check"></i>Thank-you’s are in order</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="whats-in-this-book-read-this-first.html"><a href="whats-in-this-book-read-this-first.html"><i class="fa fa-check"></i><b>1</b> What’s in This Book (Read This First!)</a><ul>
<li class="chapter" data-level="1.1" data-path="whats-in-this-book-read-this-first.html"><a href="whats-in-this-book-read-this-first.html#real-people-can-read-this-book"><i class="fa fa-check"></i><b>1.1</b> Real people can read this book</a></li>
<li class="chapter" data-level="1.2" data-path="whats-in-this-book-read-this-first.html"><a href="whats-in-this-book-read-this-first.html#whats-in-this-book"><i class="fa fa-check"></i><b>1.2</b> What’s in this book</a></li>
<li class="chapter" data-level="1.3" data-path="whats-in-this-book-read-this-first.html"><a href="whats-in-this-book-read-this-first.html#whats-new-in-the-second-edition"><i class="fa fa-check"></i><b>1.3</b> What’s new in the second edition</a></li>
<li class="chapter" data-level="1.4" data-path="whats-in-this-book-read-this-first.html"><a href="whats-in-this-book-read-this-first.html#gimme-feedback-be-polite"><i class="fa fa-check"></i><b>1.4</b> Gimme feedback (be polite)</a></li>
<li class="chapter" data-level="1.5" data-path="whats-in-this-book-read-this-first.html"><a href="whats-in-this-book-read-this-first.html#thank-you"><i class="fa fa-check"></i><b>1.5</b> Thank you!</a></li>
<li class="chapter" data-level="" data-path="whats-in-this-book-read-this-first.html"><a href="whats-in-this-book-read-this-first.html#session-info"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introduction-credibility-models-and-parameters.html"><a href="introduction-credibility-models-and-parameters.html"><i class="fa fa-check"></i><b>2</b> Introduction: Credibility, Models, and Parameters</a><ul>
<li class="chapter" data-level="2.1" data-path="introduction-credibility-models-and-parameters.html"><a href="introduction-credibility-models-and-parameters.html#bayesian-inference-is-reallocation-of-credibility-across-possibilities"><i class="fa fa-check"></i><b>2.1</b> Bayesian inference is reallocation of credibility across possibilities</a><ul>
<li class="chapter" data-level="2.1.1" data-path="introduction-credibility-models-and-parameters.html"><a href="introduction-credibility-models-and-parameters.html#data-are-noisy-and-inferences-are-probabilistic."><i class="fa fa-check"></i><b>2.1.1</b> Data are noisy and inferences are probabilistic.</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="introduction-credibility-models-and-parameters.html"><a href="introduction-credibility-models-and-parameters.html#possibilities-are-parameter-values-in-descriptive-models"><i class="fa fa-check"></i><b>2.2</b> Possibilities are parameter values in descriptive models</a></li>
<li class="chapter" data-level="2.3" data-path="introduction-credibility-models-and-parameters.html"><a href="introduction-credibility-models-and-parameters.html#the-steps-of-bayesian-data-analysis"><i class="fa fa-check"></i><b>2.3</b> The steps of Bayesian data analysis</a></li>
<li class="chapter" data-level="" data-path="introduction-credibility-models-and-parameters.html"><a href="introduction-credibility-models-and-parameters.html#session-info-1"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html"><i class="fa fa-check"></i><b>3</b> The R Programming Language</a><ul>
<li class="chapter" data-level="3.1" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#get-the-software"><i class="fa fa-check"></i><b>3.1</b> Get the software</a><ul>
<li class="chapter" data-level="3.1.1" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#a-look-at-rstudio."><i class="fa fa-check"></i><b>3.1.1</b> A look at RStudio.</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#a-simple-example-of-r-in-action"><i class="fa fa-check"></i><b>3.2</b> A simple example of R in action</a><ul>
<li class="chapter" data-level="3.2.1" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#get-the-programs-used-with-this-book."><i class="fa fa-check"></i><b>3.2.1</b> Get the programs used with this book.</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#basic-commands-and-operators-in-r"><i class="fa fa-check"></i><b>3.3</b> Basic commands and operators in R</a><ul>
<li class="chapter" data-level="3.3.1" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#getting-help-in-r."><i class="fa fa-check"></i><b>3.3.1</b> Getting help in R.</a></li>
<li class="chapter" data-level="3.3.2" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#arithmetic-and-logical-operators."><i class="fa fa-check"></i><b>3.3.2</b> Arithmetic and logical operators.</a></li>
<li class="chapter" data-level="3.3.3" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#assignment-relational-operators-and-tests-of-equality."><i class="fa fa-check"></i><b>3.3.3</b> Assignment, relational operators, and tests of equality.</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#variable-types"><i class="fa fa-check"></i><b>3.4</b> Variable types</a><ul>
<li class="chapter" data-level="3.4.1" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#vector."><i class="fa fa-check"></i><b>3.4.1</b> Vector.</a></li>
<li class="chapter" data-level="3.4.2" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#factor."><i class="fa fa-check"></i><b>3.4.2</b> Factor.</a></li>
<li class="chapter" data-level="3.4.3" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#matrix-and-array."><i class="fa fa-check"></i><b>3.4.3</b> Matrix and array.</a></li>
<li class="chapter" data-level="3.4.4" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#list-and-data-frame."><i class="fa fa-check"></i><b>3.4.4</b> List and data frame.</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#loading-and-saving-data"><i class="fa fa-check"></i><b>3.5</b> Loading and saving data</a><ul>
<li class="chapter" data-level="3.5.1" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#the-read.csv-read_csv-and-read.table-read_table-functions."><i class="fa fa-check"></i><b>3.5.1</b> The <del>read.csv</del> <code>read_csv()</code> and <del>read.table</del> <code>read_table()</code> functions.</a></li>
<li class="chapter" data-level="3.5.2" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#saving-data-from-r."><i class="fa fa-check"></i><b>3.5.2</b> Saving data from R.</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#some-utility-functions"><i class="fa fa-check"></i><b>3.6</b> Some utility functions</a></li>
<li class="chapter" data-level="3.7" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#programming-in-r"><i class="fa fa-check"></i><b>3.7</b> Programming in R</a><ul>
<li class="chapter" data-level="3.7.1" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#variable-names-in-r."><i class="fa fa-check"></i><b>3.7.1</b> Variable names in R.</a></li>
<li class="chapter" data-level="3.7.2" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#running-a-program."><i class="fa fa-check"></i><b>3.7.2</b> Running a program.</a></li>
<li class="chapter" data-level="3.7.3" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#programming-a-function."><i class="fa fa-check"></i><b>3.7.3</b> Programming a function.</a></li>
<li class="chapter" data-level="3.7.4" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#conditions-and-loops."><i class="fa fa-check"></i><b>3.7.4</b> Conditions and loops.</a></li>
<li class="chapter" data-level="3.7.5" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#measuring-processing-time."><i class="fa fa-check"></i><b>3.7.5</b> Measuring processing time.</a></li>
<li class="chapter" data-level="3.7.6" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#debugging."><i class="fa fa-check"></i><b>3.7.6</b> Debugging.</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#graphical-plots-opening-and-saving"><i class="fa fa-check"></i><b>3.8</b> Graphical plots: Opening and saving</a></li>
<li class="chapter" data-level="" data-path="the-r-programming-language.html"><a href="the-r-programming-language.html#session-info-2"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="what-is-this-stuff-called-probability.html"><a href="what-is-this-stuff-called-probability.html"><i class="fa fa-check"></i><b>4</b> What is This Stuff Called Probability?</a><ul>
<li class="chapter" data-level="4.1" data-path="what-is-this-stuff-called-probability.html"><a href="what-is-this-stuff-called-probability.html#the-set-of-all-possible-events"><i class="fa fa-check"></i><b>4.1</b> The set of all possible events</a></li>
<li class="chapter" data-level="4.2" data-path="what-is-this-stuff-called-probability.html"><a href="what-is-this-stuff-called-probability.html#probability-outside-or-inside-the-head"><i class="fa fa-check"></i><b>4.2</b> Probability: Outside or inside the head</a><ul>
<li class="chapter" data-level="4.2.1" data-path="what-is-this-stuff-called-probability.html"><a href="what-is-this-stuff-called-probability.html#outside-the-head-long-run-relative-frequency."><i class="fa fa-check"></i><b>4.2.1</b> Outside the head: Long-run relative frequency.</a></li>
<li class="chapter" data-level="4.2.2" data-path="what-is-this-stuff-called-probability.html"><a href="what-is-this-stuff-called-probability.html#inside-the-head-subjective-belief."><i class="fa fa-check"></i><b>4.2.2</b> Inside the head: Subjective belief.</a></li>
<li class="chapter" data-level="4.2.3" data-path="what-is-this-stuff-called-probability.html"><a href="what-is-this-stuff-called-probability.html#probabilities-assign-numbers-to-possibilities."><i class="fa fa-check"></i><b>4.2.3</b> Probabilities assign numbers to possibilities.</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="what-is-this-stuff-called-probability.html"><a href="what-is-this-stuff-called-probability.html#probability-distributions"><i class="fa fa-check"></i><b>4.3</b> Probability distributions</a><ul>
<li class="chapter" data-level="4.3.1" data-path="what-is-this-stuff-called-probability.html"><a href="what-is-this-stuff-called-probability.html#discrete-distributions-probability-mass."><i class="fa fa-check"></i><b>4.3.1</b> Discrete distributions: Probability mass.</a></li>
<li class="chapter" data-level="4.3.2" data-path="what-is-this-stuff-called-probability.html"><a href="what-is-this-stuff-called-probability.html#continuous-distributions-rendezvous-with-density."><i class="fa fa-check"></i><b>4.3.2</b> Continuous distributions: Rendezvous with density.</a></li>
<li class="chapter" data-level="4.3.3" data-path="what-is-this-stuff-called-probability.html"><a href="what-is-this-stuff-called-probability.html#mean-and-variance-of-a-distribution."><i class="fa fa-check"></i><b>4.3.3</b> Mean and variance of a distribution.</a></li>
<li class="chapter" data-level="4.3.4" data-path="what-is-this-stuff-called-probability.html"><a href="what-is-this-stuff-called-probability.html#highest-density-interval-hdi."><i class="fa fa-check"></i><b>4.3.4</b> Highest density interval (HDI).</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="what-is-this-stuff-called-probability.html"><a href="what-is-this-stuff-called-probability.html#two-way-distributions"><i class="fa fa-check"></i><b>4.4</b> Two-way distributions</a><ul>
<li class="chapter" data-level="4.4.1" data-path="what-is-this-stuff-called-probability.html"><a href="what-is-this-stuff-called-probability.html#conditional-probability."><i class="fa fa-check"></i><b>4.4.1</b> Conditional probability.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="what-is-this-stuff-called-probability.html"><a href="what-is-this-stuff-called-probability.html#session-info-3"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="bayes-rule.html"><a href="bayes-rule.html"><i class="fa fa-check"></i><b>5</b> Bayes’ Rule</a><ul>
<li class="chapter" data-level="5.1" data-path="bayes-rule.html"><a href="bayes-rule.html#bayes-rule-1"><i class="fa fa-check"></i><b>5.1</b> Bayes’ rule</a><ul>
<li class="chapter" data-level="5.1.1" data-path="bayes-rule.html"><a href="bayes-rule.html#derived-from-definitions-of-conditional-probability."><i class="fa fa-check"></i><b>5.1.1</b> Derived from definitions of conditional probability.</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="bayes-rule.html"><a href="bayes-rule.html#applied-to-parameters-and-data"><i class="fa fa-check"></i><b>5.2</b> Applied to parameters and data</a></li>
<li class="chapter" data-level="5.3" data-path="bayes-rule.html"><a href="bayes-rule.html#complete-examples-estimating-bias-in-a-coin"><i class="fa fa-check"></i><b>5.3</b> Complete examples: Estimating bias in a coin</a><ul>
<li class="chapter" data-level="5.3.1" data-path="bayes-rule.html"><a href="bayes-rule.html#influence-of-sample-size-on-the-posterior."><i class="fa fa-check"></i><b>5.3.1</b> Influence of sample size on the posterior.</a></li>
<li class="chapter" data-level="5.3.2" data-path="bayes-rule.html"><a href="bayes-rule.html#influence-of-prior-on-the-posterior."><i class="fa fa-check"></i><b>5.3.2</b> Influence of prior on the posterior.</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="bayes-rule.html"><a href="bayes-rule.html#why-bayesian-inference-can-be-difficult"><i class="fa fa-check"></i><b>5.4</b> Why Bayesian inference can be difficult</a></li>
<li class="chapter" data-level="" data-path="bayes-rule.html"><a href="bayes-rule.html#session-info-4"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><i class="fa fa-check"></i><b>6</b> Inferring a Binomial Probability via Exact Mathematical Analysis</a><ul>
<li class="chapter" data-level="6.1" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#the-likelihood-function-the-bernoulli-distribution"><i class="fa fa-check"></i><b>6.1</b> The likelihood function: The Bernoulli distribution</a></li>
<li class="chapter" data-level="6.2" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#a-description-of-credibilities-the-beta-distribution"><i class="fa fa-check"></i><b>6.2</b> A description of credibilities: The beta distribution</a><ul>
<li class="chapter" data-level="6.2.1" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#specifying-a-beta-prior."><i class="fa fa-check"></i><b>6.2.1</b> Specifying a beta prior.</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#the-posterior-beta"><i class="fa fa-check"></i><b>6.3</b> The posterior beta</a><ul>
<li class="chapter" data-level="6.3.1" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#posterior-is-compromise-of-prior-and-likelihood."><i class="fa fa-check"></i><b>6.3.1</b> Posterior is compromise of prior and likelihood.</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#examples"><i class="fa fa-check"></i><b>6.4</b> Examples</a><ul>
<li class="chapter" data-level="6.4.1" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#prior-knowledge-expressed-as-a-beta-distribution."><i class="fa fa-check"></i><b>6.4.1</b> Prior knowledge expressed as a beta distribution.</a></li>
<li class="chapter" data-level="6.4.2" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#prior-knowledge-that-cannot-be-expressed-as-a-beta-distribution."><i class="fa fa-check"></i><b>6.4.2</b> Prior knowledge that cannot be expressed as a beta distribution.</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#summary"><i class="fa fa-check"></i><b>6.5</b> Summary</a></li>
<li class="chapter" data-level="" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#session-info-5"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html"><i class="fa fa-check"></i><b>7</b> Markov Chain Monte Carlo</a><ul>
<li class="chapter" data-level="7.1" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#approximating-a-distribution-with-a-large-sample"><i class="fa fa-check"></i><b>7.1</b> Approximating a distribution with a large sample</a></li>
<li class="chapter" data-level="7.2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#a-simple-case-of-the-metropolis-algorithm"><i class="fa fa-check"></i><b>7.2</b> A simple case of the Metropolis algorithm</a><ul>
<li class="chapter" data-level="7.2.1" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#a-politician-stumbles-upon-the-metropolis-algorithm."><i class="fa fa-check"></i><b>7.2.1</b> A politician stumbles upon the Metropolis algorithm.</a></li>
<li class="chapter" data-level="7.2.2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#a-random-walk."><i class="fa fa-check"></i><b>7.2.2</b> A random walk.</a></li>
<li class="chapter" data-level="7.2.3" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#general-properties-of-a-random-walk."><i class="fa fa-check"></i><b>7.2.3</b> General properties of a random walk.</a></li>
<li class="chapter" data-level="7.2.4" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#why-we-care."><i class="fa fa-check"></i><b>7.2.4</b> Why we care.</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#the-metropolis-algorithm-more-generally"><i class="fa fa-check"></i><b>7.3</b> The Metropolis algorithm more generally</a><ul>
<li class="chapter" data-level="7.3.1" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#metropolis-algorithm-applied-to-bernoulli-likelihood-and-beta-prior."><i class="fa fa-check"></i><b>7.3.1</b> Metropolis algorithm applied to Bernoulli likelihood and beta prior.</a></li>
<li class="chapter" data-level="7.3.2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#summary-of-metropolis-algorithm."><i class="fa fa-check"></i><b>7.3.2</b> Summary of Metropolis algorithm.</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#toward-gibbs-sampling-estimating-two-coin-biases"><i class="fa fa-check"></i><b>7.4</b> Toward Gibbs sampling: Estimating two coin biases</a><ul>
<li class="chapter" data-level="7.4.1" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#prior-likelihood-and-posterior-for-two-biases."><i class="fa fa-check"></i><b>7.4.1</b> Prior, likelihood and posterior for two biases.</a></li>
<li class="chapter" data-level="7.4.2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#the-posterior-via-exact-formal-analysis."><i class="fa fa-check"></i><b>7.4.2</b> The posterior via exact formal analysis.</a></li>
<li class="chapter" data-level="7.4.3" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#the-posterior-via-the-metropolis-algorithm."><i class="fa fa-check"></i><b>7.4.3</b> The posterior via the Metropolis algorithm.</a></li>
<li class="chapter" data-level="7.4.4" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#gibbs-hamiltonian-monte-carlo-sampling."><i class="fa fa-check"></i><b>7.4.4</b> <del>Gibbs</del> Hamiltonian Monte Carlo sampling.</a></li>
<li class="chapter" data-level="7.4.5" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#is-there-a-difference-between-biases"><i class="fa fa-check"></i><b>7.4.5</b> Is there a difference between biases?</a></li>
<li class="chapter" data-level="7.4.6" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#terminology-mcmc."><i class="fa fa-check"></i><b>7.4.6</b> Terminology: MCMC.</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#mcmc-representativeness-accuracy-and-efficiency"><i class="fa fa-check"></i><b>7.5</b> MCMC representativeness, accuracy, and efficiency</a><ul>
<li class="chapter" data-level="7.5.1" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#mcmc-representativeness."><i class="fa fa-check"></i><b>7.5.1</b> MCMC representativeness.</a></li>
<li class="chapter" data-level="7.5.2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#mcmc-accuracy."><i class="fa fa-check"></i><b>7.5.2</b> MCMC accuracy.</a></li>
<li class="chapter" data-level="7.5.3" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#mcmc-efficiency."><i class="fa fa-check"></i><b>7.5.3</b> MCMC efficiency.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#session-info-6"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="jags-brms.html"><a href="jags-brms.html"><i class="fa fa-check"></i><b>8</b> <del>JAGS</del> brms</a><ul>
<li class="chapter" data-level="8.1" data-path="jags-brms.html"><a href="jags-brms.html#jags-brms-and-its-relation-to-r"><i class="fa fa-check"></i><b>8.1</b> <del>JAGS</del> brms and its relation to R</a></li>
<li class="chapter" data-level="8.2" data-path="jags-brms.html"><a href="jags-brms.html#a-complete-example"><i class="fa fa-check"></i><b>8.2</b> A complete example</a><ul>
<li class="chapter" data-level="8.2.1" data-path="jags-brms.html"><a href="jags-brms.html#load-data."><i class="fa fa-check"></i><b>8.2.1</b> Load data.</a></li>
<li class="chapter" data-level="8.2.2" data-path="jags-brms.html"><a href="jags-brms.html#specify-model."><i class="fa fa-check"></i><b>8.2.2</b> Specify model.</a></li>
<li class="chapter" data-level="8.2.3" data-path="jags-brms.html"><a href="jags-brms.html#initialize-chains."><i class="fa fa-check"></i><b>8.2.3</b> Initialize chains.</a></li>
<li class="chapter" data-level="8.2.4" data-path="jags-brms.html"><a href="jags-brms.html#generate-chains."><i class="fa fa-check"></i><b>8.2.4</b> Generate chains.</a></li>
<li class="chapter" data-level="8.2.5" data-path="jags-brms.html"><a href="jags-brms.html#examine-chains."><i class="fa fa-check"></i><b>8.2.5</b> Examine chains.</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="jags-brms.html"><a href="jags-brms.html#simplified-scripts-for-frequently-used-analyses"><i class="fa fa-check"></i><b>8.3</b> Simplified scripts for frequently used analyses</a></li>
<li class="chapter" data-level="8.4" data-path="jags-brms.html"><a href="jags-brms.html#example-difference-of-biases"><i class="fa fa-check"></i><b>8.4</b> Example: Difference of biases</a></li>
<li class="chapter" data-level="8.5" data-path="jags-brms.html"><a href="jags-brms.html#sampling-from-the-prior-distribution-in-jags-brms"><i class="fa fa-check"></i><b>8.5</b> Sampling from the prior distribution in <del>JAGS</del> brms</a></li>
<li class="chapter" data-level="8.6" data-path="jags-brms.html"><a href="jags-brms.html#probability-distributions-available-in-jags-brms"><i class="fa fa-check"></i><b>8.6</b> Probability distributions available in <del>JAGS</del> brms</a><ul>
<li class="chapter" data-level="8.6.1" data-path="jags-brms.html"><a href="jags-brms.html#defining-new-likelihood-functions."><i class="fa fa-check"></i><b>8.6.1</b> Defining new likelihood functions.</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="jags-brms.html"><a href="jags-brms.html#faster-sampling-with-parallel-processing-in-runjags-brmsbrm"><i class="fa fa-check"></i><b>8.7</b> Faster sampling with parallel processing in <del>runjags</del> <code>brms::brm()</code></a></li>
<li class="chapter" data-level="8.8" data-path="jags-brms.html"><a href="jags-brms.html#tips-for-expanding-jags-brms-models"><i class="fa fa-check"></i><b>8.8</b> Tips for expanding <del>JAGS</del> brms models</a></li>
<li class="chapter" data-level="" data-path="jags-brms.html"><a href="jags-brms.html#session-info-7"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="hierarchical-models.html"><a href="hierarchical-models.html"><i class="fa fa-check"></i><b>9</b> Hierarchical Models</a><ul>
<li class="chapter" data-level="9.1" data-path="hierarchical-models.html"><a href="hierarchical-models.html#a-single-coin-from-a-single-mint"><i class="fa fa-check"></i><b>9.1</b> A single coin from a single mint</a><ul>
<li class="chapter" data-level="9.1.1" data-path="hierarchical-models.html"><a href="hierarchical-models.html#posterior-via-grid-approximation."><i class="fa fa-check"></i><b>9.1.1</b> Posterior via grid approximation.</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="hierarchical-models.html"><a href="hierarchical-models.html#multiple-coins-from-a-single-mint"><i class="fa fa-check"></i><b>9.2</b> Multiple coins from a single mint</a><ul>
<li class="chapter" data-level="9.2.1" data-path="hierarchical-models.html"><a href="hierarchical-models.html#posterior-via-grid-approximation.-1"><i class="fa fa-check"></i><b>9.2.1</b> Posterior via grid approximation.</a></li>
<li class="chapter" data-level="9.2.2" data-path="hierarchical-models.html"><a href="hierarchical-models.html#a-realistic-model-with-mcmc."><i class="fa fa-check"></i><b>9.2.2</b> A realistic model with MCMC.</a></li>
<li class="chapter" data-level="9.2.3" data-path="hierarchical-models.html"><a href="hierarchical-models.html#doing-it-with-jags-brms."><i class="fa fa-check"></i><b>9.2.3</b> Doing it with <del>JAGS</del> brms.</a></li>
<li class="chapter" data-level="9.2.4" data-path="hierarchical-models.html"><a href="hierarchical-models.html#example-therapeutic-touch."><i class="fa fa-check"></i><b>9.2.4</b> Example: Therapeutic touch.</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="hierarchical-models.html"><a href="hierarchical-models.html#shrinkage-in-hierarchical-models"><i class="fa fa-check"></i><b>9.3</b> Shrinkage in hierarchical models</a></li>
<li class="chapter" data-level="9.4" data-path="hierarchical-models.html"><a href="hierarchical-models.html#speeding-up-jags-brms"><i class="fa fa-check"></i><b>9.4</b> Speeding up <del>JAGS</del> brms</a></li>
<li class="chapter" data-level="9.5" data-path="hierarchical-models.html"><a href="hierarchical-models.html#extending-the-hierarchy-subjects-within-categories"><i class="fa fa-check"></i><b>9.5</b> Extending the hierarchy: Subjects within categories</a><ul>
<li class="chapter" data-level="9.5.1" data-path="hierarchical-models.html"><a href="hierarchical-models.html#example-baseball-batting-abilities-by-position."><i class="fa fa-check"></i><b>9.5.1</b> Example: Baseball batting abilities by position.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="hierarchical-models.html"><a href="hierarchical-models.html#session-info-8"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="model-comparison-and-hierarchical-modeling.html"><a href="model-comparison-and-hierarchical-modeling.html"><i class="fa fa-check"></i><b>10</b> Model Comparison and Hierarchical Modeling</a><ul>
<li class="chapter" data-level="10.1" data-path="model-comparison-and-hierarchical-modeling.html"><a href="model-comparison-and-hierarchical-modeling.html#general-formula-and-the-bayes-factor"><i class="fa fa-check"></i><b>10.1</b> General formula and the Bayes factor</a></li>
<li class="chapter" data-level="10.2" data-path="model-comparison-and-hierarchical-modeling.html"><a href="model-comparison-and-hierarchical-modeling.html#example-two-factories-of-coins"><i class="fa fa-check"></i><b>10.2</b> Example: Two factories of coins</a><ul>
<li class="chapter" data-level="10.2.1" data-path="model-comparison-and-hierarchical-modeling.html"><a href="model-comparison-and-hierarchical-modeling.html#solution-by-formal-analysis."><i class="fa fa-check"></i><b>10.2.1</b> Solution by formal analysis.</a></li>
<li class="chapter" data-level="10.2.2" data-path="model-comparison-and-hierarchical-modeling.html"><a href="model-comparison-and-hierarchical-modeling.html#solution-by-grid-approximation."><i class="fa fa-check"></i><b>10.2.2</b> Solution by grid approximation.</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="model-comparison-and-hierarchical-modeling.html"><a href="model-comparison-and-hierarchical-modeling.html#solution-by-mcmc"><i class="fa fa-check"></i><b>10.3</b> Solution by MCMC</a><ul>
<li class="chapter" data-level="10.3.1" data-path="model-comparison-and-hierarchical-modeling.html"><a href="model-comparison-and-hierarchical-modeling.html#nonhierarchical-mcmc-computation-of-each-models-marginal-likelihood."><i class="fa fa-check"></i><b>10.3.1</b> Nonhierarchical MCMC computation of each model’s marginal likelihood.</a></li>
<li class="chapter" data-level="10.3.2" data-path="model-comparison-and-hierarchical-modeling.html"><a href="model-comparison-and-hierarchical-modeling.html#hierarchical-mcmc-computation-of-relative-model-probability-is-not-available-in-brms-well-cover-information-criteria-instead."><i class="fa fa-check"></i><b>10.3.2</b> Hierarchical MCMC computation <del>of relative model probability</del> is not available in brms: We’ll cover information criteria instead.</a></li>
<li class="chapter" data-level="10.3.3" data-path="model-comparison-and-hierarchical-modeling.html"><a href="model-comparison-and-hierarchical-modeling.html#models-with-different-noise-distributions-in-jags-brms."><i class="fa fa-check"></i><b>10.3.3</b> Models with different “noise” distributions in <del>JAGS</del> brms.</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="model-comparison-and-hierarchical-modeling.html"><a href="model-comparison-and-hierarchical-modeling.html#prediction-model-averaging"><i class="fa fa-check"></i><b>10.4</b> Prediction: Model averaging</a></li>
<li class="chapter" data-level="10.5" data-path="model-comparison-and-hierarchical-modeling.html"><a href="model-comparison-and-hierarchical-modeling.html#model-complexity-naturally-accounted-for"><i class="fa fa-check"></i><b>10.5</b> Model complexity naturally accounted for</a><ul>
<li class="chapter" data-level="10.5.1" data-path="model-comparison-and-hierarchical-modeling.html"><a href="model-comparison-and-hierarchical-modeling.html#caveats-regarding-nested-model-comparison."><i class="fa fa-check"></i><b>10.5.1</b> Caveats regarding nested model comparison.</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="model-comparison-and-hierarchical-modeling.html"><a href="model-comparison-and-hierarchical-modeling.html#extreme-sensitivity-to-the-prior-distribution"><i class="fa fa-check"></i><b>10.6</b> Extreme sensitivity to the prior distribution</a><ul>
<li class="chapter" data-level="10.6.1" data-path="model-comparison-and-hierarchical-modeling.html"><a href="model-comparison-and-hierarchical-modeling.html#priors-of-different-models-should-be-equally-informed."><i class="fa fa-check"></i><b>10.6.1</b> Priors of different models should be equally informed.</a></li>
</ul></li>
<li class="chapter" data-level="10.7" data-path="model-comparison-and-hierarchical-modeling.html"><a href="model-comparison-and-hierarchical-modeling.html#bonus-theres-danger-ahead"><i class="fa fa-check"></i><b>10.7</b> Bonus: There’s danger ahead</a></li>
<li class="chapter" data-level="" data-path="model-comparison-and-hierarchical-modeling.html"><a href="model-comparison-and-hierarchical-modeling.html#session-info-9"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html"><i class="fa fa-check"></i><b>11</b> Null Hypothesis Significance Testing</a><ul>
<li class="chapter" data-level="11.1" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#paved-with-good-intentions"><i class="fa fa-check"></i><b>11.1</b> Paved with good intentions</a><ul>
<li class="chapter" data-level="11.1.1" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#definition-of-p-value."><i class="fa fa-check"></i><b>11.1.1</b> Definition of <span class="math inline">\(p\)</span> value.</a></li>
<li class="chapter" data-level="11.1.2" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#with-intention-to-fix-n."><i class="fa fa-check"></i><b>11.1.2</b> With intention to fix <span class="math inline">\(N\)</span>.</a></li>
<li class="chapter" data-level="11.1.3" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#with-intention-to-fix-z."><i class="fa fa-check"></i><b>11.1.3</b> With intention to fix <span class="math inline">\(z\)</span>.</a></li>
<li class="chapter" data-level="11.1.4" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#with-intention-to-fix-duration."><i class="fa fa-check"></i><b>11.1.4</b> With intention to fix duration.</a></li>
<li class="chapter" data-level="11.1.5" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#with-intention-to-make-multiple-tests."><i class="fa fa-check"></i><b>11.1.5</b> With intention to make multiple tests.</a></li>
<li class="chapter" data-level="11.1.6" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#soul-searching."><i class="fa fa-check"></i><b>11.1.6</b> Soul searching.</a></li>
<li class="chapter" data-level="11.1.7" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#bayesian-analysis."><i class="fa fa-check"></i><b>11.1.7</b> Bayesian analysis.</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#prior-knowledge"><i class="fa fa-check"></i><b>11.2</b> Prior knowledge</a><ul>
<li class="chapter" data-level="11.2.1" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#nhst-analysis."><i class="fa fa-check"></i><b>11.2.1</b> NHST analysis.</a></li>
<li class="chapter" data-level="11.2.2" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#bayesian-analysis.-1"><i class="fa fa-check"></i><b>11.2.2</b> Bayesian analysis.</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#confidence-interval-and-highest-density-interval"><i class="fa fa-check"></i><b>11.3</b> Confidence interval and highest density interval</a><ul>
<li class="chapter" data-level="11.3.1" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#ci-depends-on-intention."><i class="fa fa-check"></i><b>11.3.1</b> CI depends on intention.</a></li>
<li class="chapter" data-level="11.3.2" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#bayesian-hdi."><i class="fa fa-check"></i><b>11.3.2</b> Bayesian HDI.</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#multiple-comparisons"><i class="fa fa-check"></i><b>11.4</b> Multiple comparisons</a><ul>
<li class="chapter" data-level="11.4.1" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#nhst-correction-for-experiment-wise-error."><i class="fa fa-check"></i><b>11.4.1</b> NHST correction for experiment wise error.</a></li>
<li class="chapter" data-level="11.4.2" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#just-one-bayesian-posterior-no-matter-how-you-look-at-it."><i class="fa fa-check"></i><b>11.4.2</b> Just one Bayesian posterior no matter how you look at it.</a></li>
<li class="chapter" data-level="11.4.3" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#how-bayesian-analysis-mitigates-false-alarms."><i class="fa fa-check"></i><b>11.4.3</b> How Bayesian analysis mitigates false alarms.</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#what-a-sampling-distribution-is-good-for"><i class="fa fa-check"></i><b>11.5</b> What a sampling distribution is good for</a><ul>
<li class="chapter" data-level="11.5.1" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#planning-an-experiment."><i class="fa fa-check"></i><b>11.5.1</b> Planning an experiment.</a></li>
<li class="chapter" data-level="11.5.2" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#exploring-model-predictions-posterior-predictive-check."><i class="fa fa-check"></i><b>11.5.2</b> Exploring model predictions (posterior predictive check).</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="null-hypothesis-significance-testing.html"><a href="null-hypothesis-significance-testing.html#session-info-10"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="bayesian-approaches-to-testing-a-point-null-hypothesis.html"><a href="bayesian-approaches-to-testing-a-point-null-hypothesis.html"><i class="fa fa-check"></i><b>12</b> Bayesian Approaches to Testing a Point (“Null”) Hypothesis</a><ul>
<li class="chapter" data-level="12.1" data-path="bayesian-approaches-to-testing-a-point-null-hypothesis.html"><a href="bayesian-approaches-to-testing-a-point-null-hypothesis.html#the-estimation-approach"><i class="fa fa-check"></i><b>12.1</b> The estimation approach</a><ul>
<li class="chapter" data-level="12.1.1" data-path="bayesian-approaches-to-testing-a-point-null-hypothesis.html"><a href="bayesian-approaches-to-testing-a-point-null-hypothesis.html#region-of-practical-equivalence."><i class="fa fa-check"></i><b>12.1.1</b> Region of practical equivalence.</a></li>
<li class="chapter" data-level="12.1.2" data-path="bayesian-approaches-to-testing-a-point-null-hypothesis.html"><a href="bayesian-approaches-to-testing-a-point-null-hypothesis.html#some-examples."><i class="fa fa-check"></i><b>12.1.2</b> Some examples.</a></li>
<li class="chapter" data-level="12.1.3" data-path="bayesian-approaches-to-testing-a-point-null-hypothesis.html"><a href="bayesian-approaches-to-testing-a-point-null-hypothesis.html#differences-of-correlated-parameters."><i class="fa fa-check"></i><b>12.1.3</b> Differences of correlated parameters.</a></li>
<li class="chapter" data-level="12.1.4" data-path="bayesian-approaches-to-testing-a-point-null-hypothesis.html"><a href="bayesian-approaches-to-testing-a-point-null-hypothesis.html#why-hdi-and-not-equal-tailed-interval"><i class="fa fa-check"></i><b>12.1.4</b> Why HDI and not equal-tailed interval?</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="bayesian-approaches-to-testing-a-point-null-hypothesis.html"><a href="bayesian-approaches-to-testing-a-point-null-hypothesis.html#the-model-comparison-approach"><i class="fa fa-check"></i><b>12.2</b> The model-comparison approach</a><ul>
<li class="chapter" data-level="12.2.1" data-path="bayesian-approaches-to-testing-a-point-null-hypothesis.html"><a href="bayesian-approaches-to-testing-a-point-null-hypothesis.html#is-a-coin-fair-or-not"><i class="fa fa-check"></i><b>12.2.1</b> Is a coin fair or not?</a></li>
<li class="chapter" data-level="12.2.2" data-path="bayesian-approaches-to-testing-a-point-null-hypothesis.html"><a href="bayesian-approaches-to-testing-a-point-null-hypothesis.html#bayes-factor-can-accept-null-with-poor-precision."><i class="fa fa-check"></i><b>12.2.2</b> Bayes’ factor can accept null with poor precision.</a></li>
<li class="chapter" data-level="12.2.3" data-path="bayesian-approaches-to-testing-a-point-null-hypothesis.html"><a href="bayesian-approaches-to-testing-a-point-null-hypothesis.html#are-different-groups-equal-or-not"><i class="fa fa-check"></i><b>12.2.3</b> Are different groups equal or not?</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="bayesian-approaches-to-testing-a-point-null-hypothesis.html"><a href="bayesian-approaches-to-testing-a-point-null-hypothesis.html#relations-of-parameter-estimation-and-model-comparison"><i class="fa fa-check"></i><b>12.3</b> Relations of parameter estimation and model comparison</a></li>
<li class="chapter" data-level="12.4" data-path="bayesian-approaches-to-testing-a-point-null-hypothesis.html"><a href="bayesian-approaches-to-testing-a-point-null-hypothesis.html#estimation-and-model-comparison"><i class="fa fa-check"></i><b>12.4</b> Estimation and model comparison?</a></li>
<li class="chapter" data-level="" data-path="bayesian-approaches-to-testing-a-point-null-hypothesis.html"><a href="bayesian-approaches-to-testing-a-point-null-hypothesis.html#session-info-11"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html"><i class="fa fa-check"></i><b>13</b> Goals, Power, and Sample Size</a><ul>
<li class="chapter" data-level="13.1" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#the-will-to-power"><i class="fa fa-check"></i><b>13.1</b> The will to power</a><ul>
<li class="chapter" data-level="13.1.1" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#goals-and-obstacles."><i class="fa fa-check"></i><b>13.1.1</b> Goals and obstacles.</a></li>
<li class="chapter" data-level="13.1.2" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#power."><i class="fa fa-check"></i><b>13.1.2</b> Power.</a></li>
<li class="chapter" data-level="13.1.3" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#sample-size."><i class="fa fa-check"></i><b>13.1.3</b> Sample size.</a></li>
<li class="chapter" data-level="13.1.4" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#other-expressions-of-goals."><i class="fa fa-check"></i><b>13.1.4</b> Other expressions of goals.</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#computing-power-and-sample-size"><i class="fa fa-check"></i><b>13.2</b> Computing power and sample size</a><ul>
<li class="chapter" data-level="13.2.1" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#when-the-goal-is-to-exclude-a-null-value."><i class="fa fa-check"></i><b>13.2.1</b> When the goal is to exclude a null value.</a></li>
<li class="chapter" data-level="13.2.2" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#formal-solution-and-implementation-in-r."><i class="fa fa-check"></i><b>13.2.2</b> Formal solution and implementation in R.</a></li>
<li class="chapter" data-level="13.2.3" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#when-the-goal-is-precision."><i class="fa fa-check"></i><b>13.2.3</b> When the goal is precision.</a></li>
<li class="chapter" data-level="13.2.4" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#monte-carlo-approximation-of-power."><i class="fa fa-check"></i><b>13.2.4</b> Monte Carlo approximation of power.</a></li>
<li class="chapter" data-level="13.2.5" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#power-from-idealized-or-actual-data."><i class="fa fa-check"></i><b>13.2.5</b> Power from idealized or actual data.</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#sequential-testing-and-the-goal-of-precision"><i class="fa fa-check"></i><b>13.3</b> Sequential testing and the goal of precision</a><ul>
<li class="chapter" data-level="13.3.1" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#examples-ofsequential-tests."><i class="fa fa-check"></i><b>13.3.1</b> Examples ofsequential tests.</a></li>
<li class="chapter" data-level="13.3.2" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#average-behavior-of-sequential-tests."><i class="fa fa-check"></i><b>13.3.2</b> Average behavior of sequential tests.</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#discussion"><i class="fa fa-check"></i><b>13.4</b> Discussion</a><ul>
<li class="chapter" data-level="13.4.1" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#power-and-multiple-comparisons."><i class="fa fa-check"></i><b>13.4.1</b> Power and multiple comparisons.</a></li>
<li class="chapter" data-level="13.4.2" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#power-prospective-retrospective-and-replication."><i class="fa fa-check"></i><b>13.4.2</b> Power: prospective, retrospective, and replication.</a></li>
<li class="chapter" data-level="13.4.3" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#power-analysis-requires-verisimilitude-of-simulated-data."><i class="fa fa-check"></i><b>13.4.3</b> Power analysis requires verisimilitude of simulated data.</a></li>
<li class="chapter" data-level="13.4.4" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#the-importance-of-planning."><i class="fa fa-check"></i><b>13.4.4</b> The importance of planning.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="goals-power-and-sample-size.html"><a href="goals-power-and-sample-size.html#session-info-12"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="stan.html"><a href="stan.html"><i class="fa fa-check"></i><b>14</b> Stan</a><ul>
<li class="chapter" data-level="14.1" data-path="stan.html"><a href="stan.html#hmc-sampling"><i class="fa fa-check"></i><b>14.1</b> HMC sampling</a></li>
<li class="chapter" data-level="14.2" data-path="stan.html"><a href="stan.html#installing-stan"><i class="fa fa-check"></i><b>14.2</b> Installing Stan</a></li>
<li class="chapter" data-level="14.3" data-path="stan.html"><a href="stan.html#a-complete-example-1"><i class="fa fa-check"></i><b>14.3</b> A Complete example</a><ul>
<li class="chapter" data-level="14.3.1" data-path="stan.html"><a href="stan.html#reusing-the-compiled-model."><i class="fa fa-check"></i><b>14.3.1</b> Reusing the compiled model.</a></li>
<li class="chapter" data-level="14.3.2" data-path="stan.html"><a href="stan.html#general-structure-of-stan-model-specification."><i class="fa fa-check"></i><b>14.3.2</b> General structure of Stan model specification.</a></li>
<li class="chapter" data-level="14.3.3" data-path="stan.html"><a href="stan.html#think-log-probability-to-think-like-stan."><i class="fa fa-check"></i><b>14.3.3</b> Think log probability to think like Stan.</a></li>
<li class="chapter" data-level="14.3.4" data-path="stan.html"><a href="stan.html#sampling-the-prior-in-stan."><i class="fa fa-check"></i><b>14.3.4</b> Sampling the prior in Stan.</a></li>
<li class="chapter" data-level="14.3.5" data-path="stan.html"><a href="stan.html#simplified-scripts-for-frequently-used-analyses."><i class="fa fa-check"></i><b>14.3.5</b> Simplified scripts for frequently used analyses.</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="stan.html"><a href="stan.html#specify-models-top-down-in-stan"><i class="fa fa-check"></i><b>14.4</b> Specify models top-down in Stan</a></li>
<li class="chapter" data-level="14.5" data-path="stan.html"><a href="stan.html#limitations-and-extras"><i class="fa fa-check"></i><b>14.5</b> Limitations and extras</a></li>
<li class="chapter" data-level="" data-path="stan.html"><a href="stan.html#session-info-13"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="overview-of-the-generalized-linear-model.html"><a href="overview-of-the-generalized-linear-model.html"><i class="fa fa-check"></i><b>15</b> Overview of the Generalized Linear Model</a><ul>
<li class="chapter" data-level="15.1" data-path="overview-of-the-generalized-linear-model.html"><a href="overview-of-the-generalized-linear-model.html#types-of-variables"><i class="fa fa-check"></i><b>15.1</b> Types of variables</a><ul>
<li class="chapter" data-level="15.1.1" data-path="overview-of-the-generalized-linear-model.html"><a href="overview-of-the-generalized-linear-model.html#predictor-and-predicted-variables."><i class="fa fa-check"></i><b>15.1.1</b> Predictor and predicted variables.</a></li>
<li class="chapter" data-level="15.1.2" data-path="overview-of-the-generalized-linear-model.html"><a href="overview-of-the-generalized-linear-model.html#scale-types-metric-ordinal-nominal-and-count."><i class="fa fa-check"></i><b>15.1.2</b> Scale types: metric, ordinal, nominal, and count.</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="overview-of-the-generalized-linear-model.html"><a href="overview-of-the-generalized-linear-model.html#linear-combination-of-predictors"><i class="fa fa-check"></i><b>15.2</b> Linear combination of predictors</a><ul>
<li class="chapter" data-level="15.2.1" data-path="overview-of-the-generalized-linear-model.html"><a href="overview-of-the-generalized-linear-model.html#linear-function-of-a-single-metric-predictor."><i class="fa fa-check"></i><b>15.2.1</b> Linear function of a single metric predictor.</a></li>
<li class="chapter" data-level="15.2.2" data-path="overview-of-the-generalized-linear-model.html"><a href="overview-of-the-generalized-linear-model.html#additive-combination-of-metric-predictors."><i class="fa fa-check"></i><b>15.2.2</b> Additive combination of metric predictors.</a></li>
<li class="chapter" data-level="15.2.3" data-path="overview-of-the-generalized-linear-model.html"><a href="overview-of-the-generalized-linear-model.html#nonadditive-interaction-of-metric-predictors."><i class="fa fa-check"></i><b>15.2.3</b> Nonadditive interaction of metric predictors.</a></li>
<li class="chapter" data-level="15.2.4" data-path="overview-of-the-generalized-linear-model.html"><a href="overview-of-the-generalized-linear-model.html#nominal-predictors."><i class="fa fa-check"></i><b>15.2.4</b> Nominal predictors.</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="overview-of-the-generalized-linear-model.html"><a href="overview-of-the-generalized-linear-model.html#linking-from-combined-predictors-to-noisy-predicted-data"><i class="fa fa-check"></i><b>15.3</b> Linking from combined predictors to noisy predicted data</a><ul>
<li class="chapter" data-level="15.3.1" data-path="overview-of-the-generalized-linear-model.html"><a href="overview-of-the-generalized-linear-model.html#from-predictors-to-predicted-central-tendency."><i class="fa fa-check"></i><b>15.3.1</b> From predictors to predicted central tendency.</a></li>
<li class="chapter" data-level="15.3.2" data-path="overview-of-the-generalized-linear-model.html"><a href="overview-of-the-generalized-linear-model.html#from-predicted-central-tendency-to-noisy-data."><i class="fa fa-check"></i><b>15.3.2</b> From predicted central tendency to noisy data.</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="overview-of-the-generalized-linear-model.html"><a href="overview-of-the-generalized-linear-model.html#formal-expression-of-the-glm"><i class="fa fa-check"></i><b>15.4</b> Formal expression of the GLM</a><ul>
<li class="chapter" data-level="15.4.1" data-path="overview-of-the-generalized-linear-model.html"><a href="overview-of-the-generalized-linear-model.html#cases-of-the-glm."><i class="fa fa-check"></i><b>15.4.1</b> Cases of the GLM.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="overview-of-the-generalized-linear-model.html"><a href="overview-of-the-generalized-linear-model.html#session-info-14"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="metric-predicted-variable-on-one-or-two-groups.html"><a href="metric-predicted-variable-on-one-or-two-groups.html"><i class="fa fa-check"></i><b>16</b> Metric-Predicted Variable on One or Two Groups</a><ul>
<li class="chapter" data-level="16.1" data-path="metric-predicted-variable-on-one-or-two-groups.html"><a href="metric-predicted-variable-on-one-or-two-groups.html#estimating-the-mean-and-standard-deviation-of-a-normal-distribution"><i class="fa fa-check"></i><b>16.1</b> Estimating the mean and standard deviation of a normal distribution</a><ul>
<li class="chapter" data-level="16.1.1" data-path="metric-predicted-variable-on-one-or-two-groups.html"><a href="metric-predicted-variable-on-one-or-two-groups.html#solution-by-mathematical-analysis-heads-up-on-precision."><i class="fa fa-check"></i><b>16.1.1</b> <del>Solution by mathematical analysis</del> Heads up on precision.</a></li>
<li class="chapter" data-level="16.1.2" data-path="metric-predicted-variable-on-one-or-two-groups.html"><a href="metric-predicted-variable-on-one-or-two-groups.html#approximation-by-mcmc-in-jags-hmc-in-brms."><i class="fa fa-check"></i><b>16.1.2</b> Approximation by <del>MCMC in JAGS</del> HMC in brms.</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="metric-predicted-variable-on-one-or-two-groups.html"><a href="metric-predicted-variable-on-one-or-two-groups.html#outliers-and-robust-estimation-the-t-distribution"><i class="fa fa-check"></i><b>16.2</b> Outliers and robust estimation: The <span class="math inline">\(t\)</span> distribution</a><ul>
<li class="chapter" data-level="16.2.1" data-path="metric-predicted-variable-on-one-or-two-groups.html"><a href="metric-predicted-variable-on-one-or-two-groups.html#using-the-t-distribution-in-jags-brms."><i class="fa fa-check"></i><b>16.2.1</b> Using the <span class="math inline">\(t\)</span> distribution in <del>JAGS</del> brms.</a></li>
<li class="chapter" data-level="16.2.2" data-path="metric-predicted-variable-on-one-or-two-groups.html"><a href="metric-predicted-variable-on-one-or-two-groups.html#using-the-t-distribution-in-stan."><i class="fa fa-check"></i><b>16.2.2</b> Using the <span class="math inline">\(t\)</span> distribution in Stan.</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="metric-predicted-variable-on-one-or-two-groups.html"><a href="metric-predicted-variable-on-one-or-two-groups.html#two-groups"><i class="fa fa-check"></i><b>16.3</b> Two groups</a><ul>
<li class="chapter" data-level="16.3.1" data-path="metric-predicted-variable-on-one-or-two-groups.html"><a href="metric-predicted-variable-on-one-or-two-groups.html#analysis-by-nhst."><i class="fa fa-check"></i><b>16.3.1</b> Analysis by NHST.</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="metric-predicted-variable-on-one-or-two-groups.html"><a href="metric-predicted-variable-on-one-or-two-groups.html#other-noise-distributions-and-transforming-data"><i class="fa fa-check"></i><b>16.4</b> Other noise distributions and transforming data</a></li>
<li class="chapter" data-level="" data-path="metric-predicted-variable-on-one-or-two-groups.html"><a href="metric-predicted-variable-on-one-or-two-groups.html#session-info-15"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="metric-predicted-variable-with-one-metric-predictor.html"><a href="metric-predicted-variable-with-one-metric-predictor.html"><i class="fa fa-check"></i><b>17</b> Metric Predicted Variable with One Metric Predictor</a><ul>
<li class="chapter" data-level="17.1" data-path="metric-predicted-variable-with-one-metric-predictor.html"><a href="metric-predicted-variable-with-one-metric-predictor.html#simple-linear-regression"><i class="fa fa-check"></i><b>17.1</b> Simple linear regression</a></li>
<li class="chapter" data-level="17.2" data-path="metric-predicted-variable-with-one-metric-predictor.html"><a href="metric-predicted-variable-with-one-metric-predictor.html#robust-linear-regression"><i class="fa fa-check"></i><b>17.2</b> Robust linear regression</a><ul>
<li class="chapter" data-level="17.2.1" data-path="metric-predicted-variable-with-one-metric-predictor.html"><a href="metric-predicted-variable-with-one-metric-predictor.html#robust-linear-regression-in-jags-brms."><i class="fa fa-check"></i><b>17.2.1</b> Robust linear regression in <del>JAGS</del> brms.</a></li>
<li class="chapter" data-level="17.2.2" data-path="metric-predicted-variable-with-one-metric-predictor.html"><a href="metric-predicted-variable-with-one-metric-predictor.html#robust-linear-regression-in-stan."><i class="fa fa-check"></i><b>17.2.2</b> Robust linear regression in Stan.</a></li>
<li class="chapter" data-level="17.2.3" data-path="metric-predicted-variable-with-one-metric-predictor.html"><a href="metric-predicted-variable-with-one-metric-predictor.html#stan-or-jags"><i class="fa fa-check"></i><b>17.2.3</b> Stan or JAGS?</a></li>
<li class="chapter" data-level="17.2.4" data-path="metric-predicted-variable-with-one-metric-predictor.html"><a href="metric-predicted-variable-with-one-metric-predictor.html#interpreting-the-posterior-distribution."><i class="fa fa-check"></i><b>17.2.4</b> Interpreting the posterior distribution.</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="metric-predicted-variable-with-one-metric-predictor.html"><a href="metric-predicted-variable-with-one-metric-predictor.html#hierarchical-regression-on-individuals-within-groups"><i class="fa fa-check"></i><b>17.3</b> Hierarchical regression on individuals within groups</a><ul>
<li class="chapter" data-level="17.3.1" data-path="metric-predicted-variable-with-one-metric-predictor.html"><a href="metric-predicted-variable-with-one-metric-predictor.html#the-model-and-implementation-in-jags-brms."><i class="fa fa-check"></i><b>17.3.1</b> The model and implementation in <del>JAGS</del> brms.</a></li>
<li class="chapter" data-level="17.3.2" data-path="metric-predicted-variable-with-one-metric-predictor.html"><a href="metric-predicted-variable-with-one-metric-predictor.html#the-posterior-distribution-shrinkage-and-prediction."><i class="fa fa-check"></i><b>17.3.2</b> The posterior distribution: Shrinkage and prediction.</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="metric-predicted-variable-with-one-metric-predictor.html"><a href="metric-predicted-variable-with-one-metric-predictor.html#quadratic-trend-and-weighted-data"><i class="fa fa-check"></i><b>17.4</b> Quadratic trend and weighted data</a><ul>
<li class="chapter" data-level="17.4.1" data-path="metric-predicted-variable-with-one-metric-predictor.html"><a href="metric-predicted-variable-with-one-metric-predictor.html#results-and-interpretation."><i class="fa fa-check"></i><b>17.4.1</b> Results and interpretation.</a></li>
<li class="chapter" data-level="17.4.2" data-path="metric-predicted-variable-with-one-metric-predictor.html"><a href="metric-predicted-variable-with-one-metric-predictor.html#further-extensions."><i class="fa fa-check"></i><b>17.4.2</b> Further extensions.</a></li>
</ul></li>
<li class="chapter" data-level="17.5" data-path="metric-predicted-variable-with-one-metric-predictor.html"><a href="metric-predicted-variable-with-one-metric-predictor.html#procedure-and-perils-for-expanding-a-model"><i class="fa fa-check"></i><b>17.5</b> Procedure and perils for expanding a model</a></li>
<li class="chapter" data-level="" data-path="metric-predicted-variable-with-one-metric-predictor.html"><a href="metric-predicted-variable-with-one-metric-predictor.html#session-info-16"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="metric-predicted-variable-with-multiple-metric-predictors.html"><a href="metric-predicted-variable-with-multiple-metric-predictors.html"><i class="fa fa-check"></i><b>18</b> Metric Predicted Variable with Multiple Metric Predictors</a><ul>
<li class="chapter" data-level="18.1" data-path="metric-predicted-variable-with-multiple-metric-predictors.html"><a href="metric-predicted-variable-with-multiple-metric-predictors.html#multiple-linear-regression"><i class="fa fa-check"></i><b>18.1</b> Multiple linear regression</a><ul>
<li class="chapter" data-level="18.1.1" data-path="metric-predicted-variable-with-multiple-metric-predictors.html"><a href="metric-predicted-variable-with-multiple-metric-predictors.html#the-perils-of-correlated-predictors."><i class="fa fa-check"></i><b>18.1.1</b> The perils of correlated predictors.</a></li>
<li class="chapter" data-level="18.1.2" data-path="metric-predicted-variable-with-multiple-metric-predictors.html"><a href="metric-predicted-variable-with-multiple-metric-predictors.html#the-model-and-implementation."><i class="fa fa-check"></i><b>18.1.2</b> The model and implementation.</a></li>
<li class="chapter" data-level="18.1.3" data-path="metric-predicted-variable-with-multiple-metric-predictors.html"><a href="metric-predicted-variable-with-multiple-metric-predictors.html#the-posterior-distribution."><i class="fa fa-check"></i><b>18.1.3</b> The posterior distribution.</a></li>
<li class="chapter" data-level="18.1.4" data-path="metric-predicted-variable-with-multiple-metric-predictors.html"><a href="metric-predicted-variable-with-multiple-metric-predictors.html#redundant-predictors."><i class="fa fa-check"></i><b>18.1.4</b> Redundant predictors.</a></li>
<li class="chapter" data-level="18.1.5" data-path="metric-predicted-variable-with-multiple-metric-predictors.html"><a href="metric-predicted-variable-with-multiple-metric-predictors.html#informative-priors-sparse-data-and-correlated-predictors."><i class="fa fa-check"></i><b>18.1.5</b> Informative priors, sparse data, and correlated predictors.</a></li>
</ul></li>
<li class="chapter" data-level="18.2" data-path="metric-predicted-variable-with-multiple-metric-predictors.html"><a href="metric-predicted-variable-with-multiple-metric-predictors.html#multiplicative-interaction-of-metric-predictors"><i class="fa fa-check"></i><b>18.2</b> Multiplicative interaction of metric predictors</a><ul>
<li class="chapter" data-level="18.2.1" data-path="metric-predicted-variable-with-multiple-metric-predictors.html"><a href="metric-predicted-variable-with-multiple-metric-predictors.html#an-example."><i class="fa fa-check"></i><b>18.2.1</b> An example.</a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="metric-predicted-variable-with-multiple-metric-predictors.html"><a href="metric-predicted-variable-with-multiple-metric-predictors.html#shrinkage-of-regression-coefficients"><i class="fa fa-check"></i><b>18.3</b> Shrinkage of regression coefficients</a></li>
<li class="chapter" data-level="18.4" data-path="metric-predicted-variable-with-multiple-metric-predictors.html"><a href="metric-predicted-variable-with-multiple-metric-predictors.html#variable-selection"><i class="fa fa-check"></i><b>18.4</b> Variable selection</a><ul>
<li class="chapter" data-level="18.4.1" data-path="metric-predicted-variable-with-multiple-metric-predictors.html"><a href="metric-predicted-variable-with-multiple-metric-predictors.html#inclusion-probability-is-strongly-affected-by-vagueness-of-prior."><i class="fa fa-check"></i><b>18.4.1</b> Inclusion probability is strongly affected by vagueness of prior.</a></li>
<li class="chapter" data-level="18.4.2" data-path="metric-predicted-variable-with-multiple-metric-predictors.html"><a href="metric-predicted-variable-with-multiple-metric-predictors.html#variable-selection-with-hierarchical-shrinkage."><i class="fa fa-check"></i><b>18.4.2</b> Variable selection with hierarchical shrinkage.</a></li>
<li class="chapter" data-level="18.4.3" data-path="metric-predicted-variable-with-multiple-metric-predictors.html"><a href="metric-predicted-variable-with-multiple-metric-predictors.html#what-to-report-and-what-to-conclude."><i class="fa fa-check"></i><b>18.4.3</b> What to report and what to conclude.</a></li>
<li class="chapter" data-level="18.4.4" data-path="metric-predicted-variable-with-multiple-metric-predictors.html"><a href="metric-predicted-variable-with-multiple-metric-predictors.html#caution-computational-methods."><i class="fa fa-check"></i><b>18.4.4</b> Caution: Computational methods.</a></li>
<li class="chapter" data-level="18.4.5" data-path="metric-predicted-variable-with-multiple-metric-predictors.html"><a href="metric-predicted-variable-with-multiple-metric-predictors.html#caution-interaction-variables."><i class="fa fa-check"></i><b>18.4.5</b> Caution: Interaction variables.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="metric-predicted-variable-with-multiple-metric-predictors.html"><a href="metric-predicted-variable-with-multiple-metric-predictors.html#session-info-17"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="metric-predicted-variable-with-one-nominal-predictor.html"><a href="metric-predicted-variable-with-one-nominal-predictor.html"><i class="fa fa-check"></i><b>19</b> Metric Predicted Variable with One Nominal Predictor</a><ul>
<li class="chapter" data-level="19.1" data-path="metric-predicted-variable-with-one-nominal-predictor.html"><a href="metric-predicted-variable-with-one-nominal-predictor.html#describing-multiple-groups-of-metric-data"><i class="fa fa-check"></i><b>19.1</b> Describing multiple groups of metric data</a></li>
<li class="chapter" data-level="19.2" data-path="metric-predicted-variable-with-one-nominal-predictor.html"><a href="metric-predicted-variable-with-one-nominal-predictor.html#traditional-analysis-of-variance"><i class="fa fa-check"></i><b>19.2</b> Traditional analysis of variance</a></li>
<li class="chapter" data-level="19.3" data-path="metric-predicted-variable-with-one-nominal-predictor.html"><a href="metric-predicted-variable-with-one-nominal-predictor.html#hierarchical-bayesian-approach"><i class="fa fa-check"></i><b>19.3</b> Hierarchical Bayesian approach</a><ul>
<li class="chapter" data-level="19.3.1" data-path="metric-predicted-variable-with-one-nominal-predictor.html"><a href="metric-predicted-variable-with-one-nominal-predictor.html#implementation-in-jags-brms."><i class="fa fa-check"></i><b>19.3.1</b> Implementation in <del>JAGS</del> brms.</a></li>
<li class="chapter" data-level="19.3.2" data-path="metric-predicted-variable-with-one-nominal-predictor.html"><a href="metric-predicted-variable-with-one-nominal-predictor.html#example-sex-and-death."><i class="fa fa-check"></i><b>19.3.2</b> Example: Sex and death.</a></li>
<li class="chapter" data-level="19.3.3" data-path="metric-predicted-variable-with-one-nominal-predictor.html"><a href="metric-predicted-variable-with-one-nominal-predictor.html#contrasts."><i class="fa fa-check"></i><b>19.3.3</b> Contrasts.</a></li>
<li class="chapter" data-level="19.3.4" data-path="metric-predicted-variable-with-one-nominal-predictor.html"><a href="metric-predicted-variable-with-one-nominal-predictor.html#multiple-comparisons-and-shrinkage."><i class="fa fa-check"></i><b>19.3.4</b> Multiple comparisons and shrinkage.</a></li>
<li class="chapter" data-level="19.3.5" data-path="metric-predicted-variable-with-one-nominal-predictor.html"><a href="metric-predicted-variable-with-one-nominal-predictor.html#the-two-group-case."><i class="fa fa-check"></i><b>19.3.5</b> The two-group case.</a></li>
</ul></li>
<li class="chapter" data-level="19.4" data-path="metric-predicted-variable-with-one-nominal-predictor.html"><a href="metric-predicted-variable-with-one-nominal-predictor.html#including-a-metric-predictor"><i class="fa fa-check"></i><b>19.4</b> Including a metric predictor</a><ul>
<li class="chapter" data-level="19.4.1" data-path="metric-predicted-variable-with-one-nominal-predictor.html"><a href="metric-predicted-variable-with-one-nominal-predictor.html#example-sex-death-and-size."><i class="fa fa-check"></i><b>19.4.1</b> Example: Sex, death, and size.</a></li>
<li class="chapter" data-level="19.4.2" data-path="metric-predicted-variable-with-one-nominal-predictor.html"><a href="metric-predicted-variable-with-one-nominal-predictor.html#analogous-to-traditional-ancova."><i class="fa fa-check"></i><b>19.4.2</b> Analogous to traditional ANCOVA.</a></li>
<li class="chapter" data-level="19.4.3" data-path="metric-predicted-variable-with-one-nominal-predictor.html"><a href="metric-predicted-variable-with-one-nominal-predictor.html#relation-to-hierarchical-linear-regression."><i class="fa fa-check"></i><b>19.4.3</b> Relation to hierarchical linear regression.</a></li>
</ul></li>
<li class="chapter" data-level="19.5" data-path="metric-predicted-variable-with-one-nominal-predictor.html"><a href="metric-predicted-variable-with-one-nominal-predictor.html#heterogeneous-variances-and-robustness-against-outliers"><i class="fa fa-check"></i><b>19.5</b> Heterogeneous variances and robustness against outliers</a><ul>
<li class="chapter" data-level="19.5.1" data-path="metric-predicted-variable-with-one-nominal-predictor.html"><a href="metric-predicted-variable-with-one-nominal-predictor.html#example-contrast-of-means-with-different-variances."><i class="fa fa-check"></i><b>19.5.1</b> Example: Contrast of means with different variances.</a></li>
</ul></li>
<li class="chapter" data-level="19.6" data-path="metric-predicted-variable-with-one-nominal-predictor.html"><a href="metric-predicted-variable-with-one-nominal-predictor.html#exercises-walk-out-an-effect-size"><i class="fa fa-check"></i><b>19.6</b> <del>Exercises</del> Walk out an effect size</a><ul>
<li class="chapter" data-level="19.6.1" data-path="metric-predicted-variable-with-one-nominal-predictor.html"><a href="metric-predicted-variable-with-one-nominal-predictor.html#populations-and-samples."><i class="fa fa-check"></i><b>19.6.1</b> Populations and samples.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="metric-predicted-variable-with-one-nominal-predictor.html"><a href="metric-predicted-variable-with-one-nominal-predictor.html#session-info-18"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="metric-predicted-variable-with-multiple-nominal-predictors.html"><a href="metric-predicted-variable-with-multiple-nominal-predictors.html"><i class="fa fa-check"></i><b>20</b> Metric Predicted Variable with Multiple Nominal Predictors</a><ul>
<li class="chapter" data-level="20.1" data-path="metric-predicted-variable-with-multiple-nominal-predictors.html"><a href="metric-predicted-variable-with-multiple-nominal-predictors.html#describing-groups-of-metric-data-with-multiple-nominal-predictors"><i class="fa fa-check"></i><b>20.1</b> Describing groups of metric data with multiple nominal predictors</a><ul>
<li class="chapter" data-level="20.1.1" data-path="metric-predicted-variable-with-multiple-nominal-predictors.html"><a href="metric-predicted-variable-with-multiple-nominal-predictors.html#interaction."><i class="fa fa-check"></i><b>20.1.1</b> Interaction.</a></li>
<li class="chapter" data-level="20.1.2" data-path="metric-predicted-variable-with-multiple-nominal-predictors.html"><a href="metric-predicted-variable-with-multiple-nominal-predictors.html#traditional-anova."><i class="fa fa-check"></i><b>20.1.2</b> Traditional ANOVA.</a></li>
</ul></li>
<li class="chapter" data-level="20.2" data-path="metric-predicted-variable-with-multiple-nominal-predictors.html"><a href="metric-predicted-variable-with-multiple-nominal-predictors.html#hierarchical-bayesian-approach-1"><i class="fa fa-check"></i><b>20.2</b> Hierarchical Bayesian approach</a><ul>
<li class="chapter" data-level="20.2.1" data-path="metric-predicted-variable-with-multiple-nominal-predictors.html"><a href="metric-predicted-variable-with-multiple-nominal-predictors.html#implementation-in-jags-brms.-1"><i class="fa fa-check"></i><b>20.2.1</b> Implementation in <del>JAGS</del> brms.</a></li>
<li class="chapter" data-level="20.2.2" data-path="metric-predicted-variable-with-multiple-nominal-predictors.html"><a href="metric-predicted-variable-with-multiple-nominal-predictors.html#example-its-only-money."><i class="fa fa-check"></i><b>20.2.2</b> Example: It’s only money.</a></li>
<li class="chapter" data-level="20.2.3" data-path="metric-predicted-variable-with-multiple-nominal-predictors.html"><a href="metric-predicted-variable-with-multiple-nominal-predictors.html#main-effect-contrasts."><i class="fa fa-check"></i><b>20.2.3</b> Main effect contrasts.</a></li>
<li class="chapter" data-level="20.2.4" data-path="metric-predicted-variable-with-multiple-nominal-predictors.html"><a href="metric-predicted-variable-with-multiple-nominal-predictors.html#interaction-contrasts-and-simple-effects."><i class="fa fa-check"></i><b>20.2.4</b> Interaction contrasts and simple effects.</a></li>
</ul></li>
<li class="chapter" data-level="20.3" data-path="metric-predicted-variable-with-multiple-nominal-predictors.html"><a href="metric-predicted-variable-with-multiple-nominal-predictors.html#rescaling-can-change-interactions-homogeneity-and-normality"><i class="fa fa-check"></i><b>20.3</b> Rescaling can change interactions, homogeneity, and normality</a></li>
<li class="chapter" data-level="20.4" data-path="metric-predicted-variable-with-multiple-nominal-predictors.html"><a href="metric-predicted-variable-with-multiple-nominal-predictors.html#heterogeneous-variances-and-robustness-against-outliers-1"><i class="fa fa-check"></i><b>20.4</b> Heterogeneous variances and robustness against outliers</a></li>
<li class="chapter" data-level="20.5" data-path="metric-predicted-variable-with-multiple-nominal-predictors.html"><a href="metric-predicted-variable-with-multiple-nominal-predictors.html#within-subject-designs"><i class="fa fa-check"></i><b>20.5</b> Within-subject designs</a><ul>
<li class="chapter" data-level="20.5.1" data-path="metric-predicted-variable-with-multiple-nominal-predictors.html"><a href="metric-predicted-variable-with-multiple-nominal-predictors.html#why-use-a-within-subject-design-and-why-not"><i class="fa fa-check"></i><b>20.5.1</b> Why use a within-subject design? And why not?</a></li>
<li class="chapter" data-level="20.5.2" data-path="metric-predicted-variable-with-multiple-nominal-predictors.html"><a href="metric-predicted-variable-with-multiple-nominal-predictors.html#split-plot-design."><i class="fa fa-check"></i><b>20.5.2</b> Split-plot design.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="metric-predicted-variable-with-multiple-nominal-predictors.html"><a href="metric-predicted-variable-with-multiple-nominal-predictors.html#session-info-19"><i class="fa fa-check"></i>Session info</a></li>
<li class="chapter" data-level="" data-path="metric-predicted-variable-with-multiple-nominal-predictors.html"><a href="metric-predicted-variable-with-multiple-nominal-predictors.html#footnote"><i class="fa fa-check"></i>Footnote</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="dichotomous-predicted-variable.html"><a href="dichotomous-predicted-variable.html"><i class="fa fa-check"></i><b>21</b> Dichotomous Predicted Variable</a><ul>
<li class="chapter" data-level="21.1" data-path="dichotomous-predicted-variable.html"><a href="dichotomous-predicted-variable.html#multiple-metric-predictors"><i class="fa fa-check"></i><b>21.1</b> Multiple metric predictors</a><ul>
<li class="chapter" data-level="21.1.1" data-path="dichotomous-predicted-variable.html"><a href="dichotomous-predicted-variable.html#the-model-and-implementation-in-jags-brms.-1"><i class="fa fa-check"></i><b>21.1.1</b> The model and implementation in <del>JAGS</del> brms.</a></li>
<li class="chapter" data-level="21.1.2" data-path="dichotomous-predicted-variable.html"><a href="dichotomous-predicted-variable.html#example-height-weight-and-gender."><i class="fa fa-check"></i><b>21.1.2</b> Example: Height, weight, and gender.</a></li>
</ul></li>
<li class="chapter" data-level="21.2" data-path="dichotomous-predicted-variable.html"><a href="dichotomous-predicted-variable.html#interpreting-the-regression-coefficients"><i class="fa fa-check"></i><b>21.2</b> Interpreting the regression coefficients</a><ul>
<li class="chapter" data-level="21.2.1" data-path="dichotomous-predicted-variable.html"><a href="dichotomous-predicted-variable.html#log-odds."><i class="fa fa-check"></i><b>21.2.1</b> Log odds.</a></li>
<li class="chapter" data-level="21.2.2" data-path="dichotomous-predicted-variable.html"><a href="dichotomous-predicted-variable.html#when-there-are-few-1s-or-0s-in-the-data."><i class="fa fa-check"></i><b>21.2.2</b> When there are few 1’s or 0’s in the data.</a></li>
<li class="chapter" data-level="21.2.3" data-path="dichotomous-predicted-variable.html"><a href="dichotomous-predicted-variable.html#correlated-predictors."><i class="fa fa-check"></i><b>21.2.3</b> Correlated predictors.</a></li>
<li class="chapter" data-level="21.2.4" data-path="dichotomous-predicted-variable.html"><a href="dichotomous-predicted-variable.html#interaction-of-metric-predictors."><i class="fa fa-check"></i><b>21.2.4</b> Interaction of metric predictors.</a></li>
</ul></li>
<li class="chapter" data-level="21.3" data-path="dichotomous-predicted-variable.html"><a href="dichotomous-predicted-variable.html#robust-logistic-regression"><i class="fa fa-check"></i><b>21.3</b> Robust logistic regression</a></li>
<li class="chapter" data-level="21.4" data-path="dichotomous-predicted-variable.html"><a href="dichotomous-predicted-variable.html#nominal-predictors"><i class="fa fa-check"></i><b>21.4</b> Nominal predictors</a><ul>
<li class="chapter" data-level="21.4.1" data-path="dichotomous-predicted-variable.html"><a href="dichotomous-predicted-variable.html#single-group."><i class="fa fa-check"></i><b>21.4.1</b> Single group.</a></li>
<li class="chapter" data-level="21.4.2" data-path="dichotomous-predicted-variable.html"><a href="dichotomous-predicted-variable.html#multiple-groups."><i class="fa fa-check"></i><b>21.4.2</b> Multiple groups.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="dichotomous-predicted-variable.html"><a href="dichotomous-predicted-variable.html#session-info-20"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="nominal-predicted-variable.html"><a href="nominal-predicted-variable.html"><i class="fa fa-check"></i><b>22</b> Nominal Predicted Variable</a><ul>
<li class="chapter" data-level="22.1" data-path="nominal-predicted-variable.html"><a href="nominal-predicted-variable.html#softmax-regression"><i class="fa fa-check"></i><b>22.1</b> Softmax regression</a><ul>
<li class="chapter" data-level="22.1.1" data-path="nominal-predicted-variable.html"><a href="nominal-predicted-variable.html#softmax-reduces-to-logistic-for-two-outcomes."><i class="fa fa-check"></i><b>22.1.1</b> Softmax reduces to logistic for two outcomes.</a></li>
<li class="chapter" data-level="22.1.2" data-path="nominal-predicted-variable.html"><a href="nominal-predicted-variable.html#independence-from-irrelevant-attributes."><i class="fa fa-check"></i><b>22.1.2</b> Independence from irrelevant attributes.</a></li>
</ul></li>
<li class="chapter" data-level="22.2" data-path="nominal-predicted-variable.html"><a href="nominal-predicted-variable.html#conditional-logistic-regression"><i class="fa fa-check"></i><b>22.2</b> Conditional logistic regression</a></li>
<li class="chapter" data-level="22.3" data-path="nominal-predicted-variable.html"><a href="nominal-predicted-variable.html#implementation-in-jags-brms"><i class="fa fa-check"></i><b>22.3</b> Implementation in <del>JAGS</del> brms</a><ul>
<li class="chapter" data-level="22.3.1" data-path="nominal-predicted-variable.html"><a href="nominal-predicted-variable.html#softmax-model."><i class="fa fa-check"></i><b>22.3.1</b> Softmax model.</a></li>
<li class="chapter" data-level="22.3.2" data-path="nominal-predicted-variable.html"><a href="nominal-predicted-variable.html#conditional-logistic-model."><i class="fa fa-check"></i><b>22.3.2</b> Conditional logistic model.</a></li>
<li class="chapter" data-level="22.3.3" data-path="nominal-predicted-variable.html"><a href="nominal-predicted-variable.html#results-interpreting-the-regression-coefficients."><i class="fa fa-check"></i><b>22.3.3</b> Results: Interpreting the regression coefficients.</a></li>
</ul></li>
<li class="chapter" data-level="22.4" data-path="nominal-predicted-variable.html"><a href="nominal-predicted-variable.html#generalizations-and-variations-of-the-models"><i class="fa fa-check"></i><b>22.4</b> Generalizations and variations of the models</a></li>
<li class="chapter" data-level="" data-path="nominal-predicted-variable.html"><a href="nominal-predicted-variable.html#session-info-21"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="23" data-path="ordinal-predicted-variable.html"><a href="ordinal-predicted-variable.html"><i class="fa fa-check"></i><b>23</b> Ordinal Predicted Variable</a><ul>
<li class="chapter" data-level="23.1" data-path="ordinal-predicted-variable.html"><a href="ordinal-predicted-variable.html#modeling-ordinal-data-with-an-underlying-metric-variable"><i class="fa fa-check"></i><b>23.1</b> Modeling ordinal data with an underlying metric variable</a></li>
<li class="chapter" data-level="23.2" data-path="ordinal-predicted-variable.html"><a href="ordinal-predicted-variable.html#the-case-of-a-single-group"><i class="fa fa-check"></i><b>23.2</b> The case of a single group</a><ul>
<li class="chapter" data-level="23.2.1" data-path="ordinal-predicted-variable.html"><a href="ordinal-predicted-variable.html#implementation-in-jags-brms.-3"><i class="fa fa-check"></i><b>23.2.1</b> Implementation in <del>JAGS</del> <strong>brms</strong>.</a></li>
<li class="chapter" data-level="23.2.2" data-path="ordinal-predicted-variable.html"><a href="ordinal-predicted-variable.html#examples-bayesian-estimation-recovers-true-parameter-values."><i class="fa fa-check"></i><b>23.2.2</b> Examples: Bayesian estimation recovers true parameter values.</a></li>
</ul></li>
<li class="chapter" data-level="23.3" data-path="ordinal-predicted-variable.html"><a href="ordinal-predicted-variable.html#the-case-of-two-groups"><i class="fa fa-check"></i><b>23.3</b> The case of two groups</a><ul>
<li class="chapter" data-level="23.3.1" data-path="ordinal-predicted-variable.html"><a href="ordinal-predicted-variable.html#implementation-in-jags-brms.-4"><i class="fa fa-check"></i><b>23.3.1</b> Implementation in <del>JAGS</del> <strong>brms</strong>.</a></li>
<li class="chapter" data-level="23.3.2" data-path="ordinal-predicted-variable.html"><a href="ordinal-predicted-variable.html#examples-not-funny."><i class="fa fa-check"></i><b>23.3.2</b> Examples: Not funny.</a></li>
</ul></li>
<li class="chapter" data-level="23.4" data-path="ordinal-predicted-variable.html"><a href="ordinal-predicted-variable.html#the-case-of-metric-predictors"><i class="fa fa-check"></i><b>23.4</b> The Case of metric predictors</a><ul>
<li class="chapter" data-level="23.4.1" data-path="ordinal-predicted-variable.html"><a href="ordinal-predicted-variable.html#implementation-in-jags-brms.-5"><i class="fa fa-check"></i><b>23.4.1</b> Implementation in <del>JAGS</del> brms.</a></li>
<li class="chapter" data-level="23.4.2" data-path="ordinal-predicted-variable.html"><a href="ordinal-predicted-variable.html#example-happiness-and-money."><i class="fa fa-check"></i><b>23.4.2</b> Example: Happiness and money.</a></li>
<li class="chapter" data-level="23.4.3" data-path="ordinal-predicted-variable.html"><a href="ordinal-predicted-variable.html#example-moviesthey-dont-make-em-like-they-used-to."><i class="fa fa-check"></i><b>23.4.3</b> Example: Movies–They don’t make ’em like they used to.</a></li>
<li class="chapter" data-level="23.4.4" data-path="ordinal-predicted-variable.html"><a href="ordinal-predicted-variable.html#why-are-some-thresholds-outside-the-data"><i class="fa fa-check"></i><b>23.4.4</b> Why are some thresholds outside the data?</a></li>
</ul></li>
<li class="chapter" data-level="23.5" data-path="ordinal-predicted-variable.html"><a href="ordinal-predicted-variable.html#posterior-prediction"><i class="fa fa-check"></i><b>23.5</b> Posterior prediction</a></li>
<li class="chapter" data-level="23.6" data-path="ordinal-predicted-variable.html"><a href="ordinal-predicted-variable.html#generalizations-and-extensions"><i class="fa fa-check"></i><b>23.6</b> Generalizations and extensions</a></li>
<li class="chapter" data-level="" data-path="ordinal-predicted-variable.html"><a href="ordinal-predicted-variable.html#session-info-22"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="count-predicted-variable.html"><a href="count-predicted-variable.html"><i class="fa fa-check"></i><b>24</b> Count Predicted Variable</a><ul>
<li class="chapter" data-level="24.1" data-path="count-predicted-variable.html"><a href="count-predicted-variable.html#poisson-exponential-model"><i class="fa fa-check"></i><b>24.1</b> Poisson exponential model</a><ul>
<li class="chapter" data-level="24.1.1" data-path="count-predicted-variable.html"><a href="count-predicted-variable.html#data-structure."><i class="fa fa-check"></i><b>24.1.1</b> Data structure.</a></li>
<li class="chapter" data-level="24.1.2" data-path="count-predicted-variable.html"><a href="count-predicted-variable.html#exponential-link-function."><i class="fa fa-check"></i><b>24.1.2</b> Exponential link function.</a></li>
<li class="chapter" data-level="24.1.3" data-path="count-predicted-variable.html"><a href="count-predicted-variable.html#poisson-noise-distribution."><i class="fa fa-check"></i><b>24.1.3</b> Poisson noise distribution.</a></li>
<li class="chapter" data-level="24.1.4" data-path="count-predicted-variable.html"><a href="count-predicted-variable.html#the-complete-model-and-implementation-in-jags-brms."><i class="fa fa-check"></i><b>24.1.4</b> The complete model and implementation in <del>JAGS</del> brms.</a></li>
</ul></li>
<li class="chapter" data-level="24.2" data-path="count-predicted-variable.html"><a href="count-predicted-variable.html#example-hair-eye-go-again"><i class="fa fa-check"></i><b>24.2</b> Example: Hair eye go again</a></li>
<li class="chapter" data-level="24.3" data-path="count-predicted-variable.html"><a href="count-predicted-variable.html#example-interaction-contrasts-shrinkage-and-omnibus-test"><i class="fa fa-check"></i><b>24.3</b> Example: Interaction contrasts, shrinkage, and omnibus test</a></li>
<li class="chapter" data-level="24.4" data-path="count-predicted-variable.html"><a href="count-predicted-variable.html#log-linear-models-for-contingency-tables-bonus-alternative-parameterization"><i class="fa fa-check"></i><b>24.4</b> <del>Log-linear models for contingency tables</del> Bonus: Alternative parameterization</a></li>
<li class="chapter" data-level="" data-path="count-predicted-variable.html"><a href="count-predicted-variable.html#session-info-23"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="25" data-path="tools-in-the-trunk.html"><a href="tools-in-the-trunk.html"><i class="fa fa-check"></i><b>25</b> Tools in the Trunk</a><ul>
<li class="chapter" data-level="25.1" data-path="tools-in-the-trunk.html"><a href="tools-in-the-trunk.html#reporting-a-bayesian-analysis"><i class="fa fa-check"></i><b>25.1</b> Reporting a Bayesian analysis</a><ul>
<li class="chapter" data-level="25.1.1" data-path="tools-in-the-trunk.html"><a href="tools-in-the-trunk.html#essential-points."><i class="fa fa-check"></i><b>25.1.1</b> Essential points.</a></li>
<li class="chapter" data-level="25.1.2" data-path="tools-in-the-trunk.html"><a href="tools-in-the-trunk.html#optional-points."><i class="fa fa-check"></i><b>25.1.2</b> Optional points.</a></li>
<li class="chapter" data-level="25.1.3" data-path="tools-in-the-trunk.html"><a href="tools-in-the-trunk.html#helpful-points."><i class="fa fa-check"></i><b>25.1.3</b> Helpful points.</a></li>
</ul></li>
<li class="chapter" data-level="25.2" data-path="tools-in-the-trunk.html"><a href="tools-in-the-trunk.html#functions-for-computing-highest-density-intervals"><i class="fa fa-check"></i><b>25.2</b> Functions for computing highest density intervals</a><ul>
<li class="chapter" data-level="25.2.1" data-path="tools-in-the-trunk.html"><a href="tools-in-the-trunk.html#r-code-for-computing-hdi-of-a-grid-approximation."><i class="fa fa-check"></i><b>25.2.1</b> R code for computing HDI of a grid approximation.</a></li>
<li class="chapter" data-level="25.2.2" data-path="tools-in-the-trunk.html"><a href="tools-in-the-trunk.html#hdi-of-unimodal-distribution-is-shortest-interval."><i class="fa fa-check"></i><b>25.2.2</b> HDI of unimodal distribution is shortest interval.</a></li>
<li class="chapter" data-level="25.2.3" data-path="tools-in-the-trunk.html"><a href="tools-in-the-trunk.html#r-code-for-computing-hdi-of-a-mcmc-sample."><i class="fa fa-check"></i><b>25.2.3</b> R code for computing HDI of a MCMC sample.</a></li>
<li class="chapter" data-level="25.2.4" data-path="tools-in-the-trunk.html"><a href="tools-in-the-trunk.html#r-code-for-computing-hdi-of-a-function."><i class="fa fa-check"></i><b>25.2.4</b> R code for computing HDI of a function.</a></li>
</ul></li>
<li class="chapter" data-level="25.3" data-path="tools-in-the-trunk.html"><a href="tools-in-the-trunk.html#reparameterization"><i class="fa fa-check"></i><b>25.3</b> Reparameterization</a></li>
<li class="chapter" data-level="25.4" data-path="tools-in-the-trunk.html"><a href="tools-in-the-trunk.html#censored-data-in-jags-brms"><i class="fa fa-check"></i><b>25.4</b> Censored Data in <del>JAGS</del> brms</a></li>
<li class="chapter" data-level="25.5" data-path="tools-in-the-trunk.html"><a href="tools-in-the-trunk.html#what-next"><i class="fa fa-check"></i><b>25.5</b> What Next?</a></li>
<li class="chapter" data-level="" data-path="tools-in-the-trunk.html"><a href="tools-in-the-trunk.html#session-info-24"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"><em>Doing Bayesian Data Analysis</em> in brms and the tidyverse</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="tools-in-the-trunk" class="section level1">
<h1><span class="header-section-number">25</span> Tools in the Trunk</h1>
<p>“This chapter includes some important topics that apply to many different models throughout the book… The sections can be read independently of each other and at any time” <span class="citation">(Kruschke, <a href="#ref-kruschkeDoingBayesianData2015">2015</a>, p. 721)</span>.</p>
<div id="reporting-a-bayesian-analysis" class="section level2">
<h2><span class="header-section-number">25.1</span> Reporting a Bayesian analysis</h2>
<blockquote>
<p>Bayesian data analyses are not yet standard procedure in many fields of research, and no conventional format for reporting them has been established. Therefore, the researcher who reports a Bayesian analysis must be sensitive to the background knowledge of his or her specific audience, and must frame the description accordingly. (p. 721)</p>
</blockquote>
<p>At the time of this writing (early 2020), this is still the case. See <span class="citation">Aczel et al. (<a href="#ref-aczelDiscussionPointsBayesian2020">2020</a>)</span>, <a href="https://www.researchgate.net/publication/338849264_Discussion_points_for_Bayesian_inference"><em>Discussion points for Bayesian inference</em></a>, for a recent discussion from several Bayesian scholars.</p>
<div id="essential-points." class="section level3">
<h3><span class="header-section-number">25.1.1</span> Essential points.</h3>
<blockquote>
<p>Recall the basic steps of a Bayesian analysis from Section 2.3 (p. 25): Identify the data, define a descriptive model, specify a prior, compute the posterior distribution, interpret the posterior distribution, and, check that the model is a reasonable description of the data. Those steps are in logical order, with each step building on the previous step. That logical order should be preserved in the report of the analysis. (p. 722)</p>
</blockquote>
<p>Kruschke then gave recommendations for motivating Bayesian inference. His <span class="citation">(<a href="#ref-kruschkeBayesianNewStatistics2018">2018</a>)</span> paper with Liddell, <a href="https://link.springer.com/content/pdf/10.3758/s13423-016-1221-4.pdf"><em>The Bayesian New Statistics: Hypothesis testing, estimation, meta-analysis, and power analysis from a Bayesian perspective</em></a>, might be helpful in this regard. Many of the other points Kruschke made in this section (e.g., adequately reporting the data structure, the priors, evidence for convergence) can be handled by adopting open science practices.</p>
<p>If your data and research questions are simple and straightforward, you might find it easy to detail these and other concerns in the primary manuscript. The harsh reality is many journals place tight constraints on word and/or page limits. If your projects are not of the simple and straightforward type, supplemental materials are your friend. Regardless of a journal’s policy on hosting supplemental materials on the official journal website, you can detail your data, priors, MCMC diagnostics, and all the other fine-grained details of your analysis in supplemental documents hosted in publicly-accessible repositories like the <a href="https://osf.io/">Open Science Framework (OSF)</a>. If possible, do consider making your data openly available. Regardless of the status of your data, please consider making all your <strong>R</strong> scripts available as supplementary material. To reiterate from Chapter 3, I strongly recommend checking out <a href="https://bookdown.org/yihui/rmarkdown/notebook.html">R Notebooks</a> for that purpose. They are a type of R Markdown document with augmentations that make them more useful for working scientists. You can learn more about them <a href="https://rstudio-pubs-static.s3.amazonaws.com/256225_63ebef4029dd40ef8e3679f6cf200a5a.html">here</a> and <a href="https://www.r-bloggers.com/why-i-love-r-notebooks-2/">here</a>. And for a more comprehensive overview, check out Xie, Allaire, and Grolemund’s <span class="citation">(<a href="#ref-xieMarkdownDefinitiveGuide2020">2020</a>)</span> <a href="https://bookdown.org/yihui/rmarkdown/"><em>R markdown: The definitive guide</em></a>.</p>
</div>
<div id="optional-points." class="section level3">
<h3><span class="header-section-number">25.1.2</span> Optional points.</h3>
<p>For more thoughts on robustness checks, check out a couple Gelman’s blog posts, <a href="https://statmodeling.stat.columbia.edu/2017/11/29/whats-point-robustness-check/"><em>What’s the point of a robustness check?</em></a> and <a href="https://statmodeling.stat.columbia.edu/2018/11/14/robustness-checks-joke/"><em>Robustness checks are a joke</em></a>, along with the action in the comments section.</p>
<p>In addition to posterior predictive checks, which are great <span class="citation">(see Kruschke, <a href="#ref-kruschkePosteriorPredictiveChecks2013">2013</a>)</span>, consider prior predictive checks, too. For a great introduction to the topic, check out Gabry, Simpson, Vehtari, Betancourt, and Gelman’s <span class="citation">(<a href="#ref-gabry2019visualization">2019</a>)</span> <a href="https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/rssa.12378"><em>Visualization in Bayesian workflow</em></a>.</p>
</div>
<div id="helpful-points." class="section level3">
<h3><span class="header-section-number">25.1.3</span> Helpful points.</h3>
<p>For more ideas on open data, check out Rouder’s <span class="citation">(<a href="#ref-rouderWhatWhyHow2016">2016</a>)</span> <a href="https://link.springer.com/article/10.3758/s13428-015-0630-z"><em>The what, why, and how of born-open data</em></a>. You might also check out Klein and colleagues’ <span class="citation">(<a href="#ref-kleinPracticalGuideTransparency2018">2018</a>)</span> <a href="https://lirias.kuleuven.be/1999530?limo=0"><em>A practical guide for transparency in psychological science</em></a> and Martone, Garcia-Castro, and VandenBos’s <span class="citation">(<a href="#ref-martoneDataSharingPsychology2018">2018</a>)</span> <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5920518/pdf/nihms935471.pdf"><em>Data sharing in psychology</em></a>.</p>
<p>As to posting your model fits, this could be done in any number of ways, including as official supplemental materials hosted by the journal, on GitHub, or on the OSF. At a base level, this means saving your fits as external files. We’ve already been modeling this with our <code>brm()</code> code throughout this book. With the <code>save</code> argument, we saved the model fits within the <a href="https://github.com/ASKurz/Doing-Bayesian-Data-Analysis-in-brms-and-the-tidyverse/tree/master/fits"><code>fits</code> folder on GitHub</a>. You might adopt a similar approach. But do be warned: <strong>brms</strong> fit objects contain a copy of the data used to create them. For example, here’s how we might reload <code>fit24.1</code> from last chapter.</p>
<div class="sourceCode" id="cb2293"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2293-1" data-line-number="1">fit24<span class="fl">.1</span> &lt;-<span class="st"> </span><span class="kw">readRDS</span>(<span class="st">&quot;fits/fit24.01.rds&quot;</span>)</a></code></pre></div>
<p>By indexing the fit object with <code>$data</code>, you can see the data.</p>
<div class="sourceCode" id="cb2294"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2294-1" data-line-number="1"><span class="kw">library</span>(tidyverse)</a>
<a class="sourceLine" id="cb2294-2" data-line-number="2"><span class="kw">library</span>(brms)</a>
<a class="sourceLine" id="cb2294-3" data-line-number="3"></a>
<a class="sourceLine" id="cb2294-4" data-line-number="4">fit24<span class="fl">.1</span><span class="op">$</span>data <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb2294-5" data-line-number="5"><span class="st">  </span><span class="kw">glimpse</span>()</a></code></pre></div>
<pre><code>## Rows: 16
## Columns: 4
## $ Count      &lt;dbl&gt; 20, 68, 5, 15, 94, 7, 16, 10, 84, 119, 29, 54, 17, 26, 14,…
## $ Hair       &lt;fct&gt; Black, Black, Black, Black, Blond, Blond, Blond, Blond, Br…
## $ Eye        &lt;chr&gt; &quot;Blue&quot;, &quot;Brown&quot;, &quot;Green&quot;, &quot;Hazel&quot;, &quot;Blue&quot;, &quot;Brown&quot;, &quot;Green…
## $ `Hair:Eye` &lt;chr&gt; &quot;Black_Blue&quot;, &quot;Black_Brown&quot;, &quot;Black_Green&quot;, &quot;Black_Hazel&quot;,…</code></pre>
<p>Here’s a quick way to remove the data from the fit object.</p>
<div class="sourceCode" id="cb2296"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2296-1" data-line-number="1">fit24<span class="fl">.1</span><span class="op">$</span>data &lt;-<span class="st"> </span><span class="ot">NULL</span></a></code></pre></div>
<p>Confirm it worked.</p>
<div class="sourceCode" id="cb2297"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2297-1" data-line-number="1">fit24<span class="fl">.1</span><span class="op">$</span>data</a></code></pre></div>
<pre><code>## NULL</code></pre>
<p>Happily, the rest of the information is still there for you. E.g., here’s the summary.</p>
<div class="sourceCode" id="cb2299"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2299-1" data-line-number="1"><span class="kw">print</span>(fit24<span class="fl">.1</span>)</a></code></pre></div>
<pre><code>##  Family: poisson 
##   Links: mu = log 
## Formula: Count ~ 1 + (1 | Hair) + (1 | Eye) + (1 | Hair:Eye) 
##    Data: my_data (Number of observations: ) 
## Samples: 4 chains, each with iter = 3000; warmup = 1000; thin = 1;
##          total post-warmup samples = 8000
## 
## Group-Level Effects: 
## ~Eye (Number of levels: 4) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     1.83      1.62     0.29     6.37 1.00     3494     5176
## 
## ~Hair (Number of levels: 4) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     1.93      1.57     0.36     6.16 1.00     3326     5218
## 
## ~Hair:Eye (Number of levels: 16) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.94      0.29     0.54     1.63 1.00     3344     5137
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept     3.22      1.54    -0.04     6.49 1.00     4685     4300
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
</div>
</div>
<div id="functions-for-computing-highest-density-intervals" class="section level2">
<h2><span class="header-section-number">25.2</span> Functions for computing highest density intervals</h2>
<p>You can find a copy of Kruschke’s scripts, including <code>DBDA2E-utilities.R</code>, at <a href="https://github.com/ASKurz/Doing-Bayesian-Data-Analysis-in-brms-and-the-tidyverse/tree/master/data.R">https://github.com/ASKurz/Doing-Bayesian-Data-Analysis-in-brms-and-the-tidyverse/tree/master/data.R</a>.</p>
<div id="r-code-for-computing-hdi-of-a-grid-approximation." class="section level3">
<h3><span class="header-section-number">25.2.1</span> R code for computing HDI of a grid approximation.</h3>
<blockquote>
<p>We can imagine the grid approximation of a distribution as a landscape of poles sticking up from each point on the parameter grid, with the height of each pole indicating the probability mass at that discrete point. We can imagine the highest density region by visualizing a rising tide: We gradually flood the landscape, monitoring the total mass of the poles that protrude above water, stopping the flood when 95% (say) of the mass remains protruding. The waterline at that moment defines the highest density region <span class="citation">(e.g., Hyndman, <a href="#ref-hyndmanComputingGraphingHighest1996">1996</a>)</span>. (p. 725)</p>
</blockquote>
<div class="sourceCode" id="cb2301"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2301-1" data-line-number="1">HDIofGrid &lt;-<span class="st"> </span><span class="cf">function</span>(probMassVec, <span class="dt">credMass =</span> <span class="fl">0.95</span>) {</a>
<a class="sourceLine" id="cb2301-2" data-line-number="2">  </a>
<a class="sourceLine" id="cb2301-3" data-line-number="3">  <span class="co"># Arguments:</span></a>
<a class="sourceLine" id="cb2301-4" data-line-number="4">  <span class="co">#   probMassVec is a vector of probability masses at each grid point.</span></a>
<a class="sourceLine" id="cb2301-5" data-line-number="5">  <span class="co">#   credMass is the desired mass of the HDI region.</span></a>
<a class="sourceLine" id="cb2301-6" data-line-number="6">  <span class="co"># Return value:</span></a>
<a class="sourceLine" id="cb2301-7" data-line-number="7">  <span class="co">#   A list with components:</span></a>
<a class="sourceLine" id="cb2301-8" data-line-number="8">  <span class="co">#   indices is a vector of indices that are in the HDI</span></a>
<a class="sourceLine" id="cb2301-9" data-line-number="9">  <span class="co">#   mass is the total mass of the included indices</span></a>
<a class="sourceLine" id="cb2301-10" data-line-number="10">    <span class="co">#   height is the smallest component probability mass in the HDI</span></a>
<a class="sourceLine" id="cb2301-11" data-line-number="11">  <span class="co"># Example of use: For determining HDI of a beta(30,12) distribution</span></a>
<a class="sourceLine" id="cb2301-12" data-line-number="12">  <span class="co">#   approximated on a grid:</span></a>
<a class="sourceLine" id="cb2301-13" data-line-number="13">  <span class="co">#   &gt; probDensityVec = dbeta( seq(0,1,length=201) , 30 , 12 )</span></a>
<a class="sourceLine" id="cb2301-14" data-line-number="14">  <span class="co">#   &gt; probMassVec = probDensityVec / sum( probDensityVec )</span></a>
<a class="sourceLine" id="cb2301-15" data-line-number="15">  <span class="co">#   &gt; HDIinfo = HDIofGrid( probMassVec )</span></a>
<a class="sourceLine" id="cb2301-16" data-line-number="16">  <span class="co">#   &gt; show( HDIinfo )</span></a>
<a class="sourceLine" id="cb2301-17" data-line-number="17">  </a>
<a class="sourceLine" id="cb2301-18" data-line-number="18">  sortedProbMass &lt;-<span class="st"> </span><span class="kw">sort</span>(probMassVec, <span class="dt">decreasing =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb2301-19" data-line-number="19">  HDIheightIdx &lt;-<span class="st"> </span><span class="kw">min</span>(<span class="kw">which</span>(<span class="kw">cumsum</span>(sortedProbMass) <span class="op">&gt;=</span><span class="st"> </span>credMass))</a>
<a class="sourceLine" id="cb2301-20" data-line-number="20">  HDIheight &lt;-<span class="st"> </span>sortedProbMass[HDIheightIdx]</a>
<a class="sourceLine" id="cb2301-21" data-line-number="21">  HDImass &lt;-<span class="st"> </span><span class="kw">sum</span>(probMassVec[probMassVec <span class="op">&gt;=</span><span class="st"> </span>HDIheight])</a>
<a class="sourceLine" id="cb2301-22" data-line-number="22">  </a>
<a class="sourceLine" id="cb2301-23" data-line-number="23">  <span class="kw">return</span>(<span class="kw">list</span>(<span class="dt">indices =</span> <span class="kw">which</span>(probMassVec <span class="op">&gt;=</span><span class="st"> </span>HDIheight),</a>
<a class="sourceLine" id="cb2301-24" data-line-number="24">              <span class="dt">mass    =</span> HDImass, <span class="dt">height =</span> HDIheight))</a>
<a class="sourceLine" id="cb2301-25" data-line-number="25">  </a>
<a class="sourceLine" id="cb2301-26" data-line-number="26">}</a></code></pre></div>
<p>I found Kruschke’s description of his <code>HDIofGrid()</code> a bit opaque. Happily, we can understand this function with a little help from an example posted at <a href="https://rdrr.io/github/kyusque/DBDA2E-utilities/man/HDIofGrid.html">https://rdrr.io/github/kyusque/DBDA2E-utilities/man/HDIofGrid.html</a>.</p>
<div class="sourceCode" id="cb2302"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2302-1" data-line-number="1">prob_density_vec &lt;-<span class="st"> </span><span class="kw">dbeta</span>(<span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">length =</span> <span class="dv">201</span>), <span class="dv">30</span>, <span class="dv">12</span>)</a>
<a class="sourceLine" id="cb2302-2" data-line-number="2">prob_mass_vec    &lt;-<span class="st"> </span>prob_density_vec <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(prob_density_vec)</a>
<a class="sourceLine" id="cb2302-3" data-line-number="3">HDI_info         &lt;-<span class="st"> </span><span class="kw">HDIofGrid</span>(prob_mass_vec)</a>
<a class="sourceLine" id="cb2302-4" data-line-number="4"></a>
<a class="sourceLine" id="cb2302-5" data-line-number="5"><span class="kw">show</span>(HDI_info)</a></code></pre></div>
<pre><code>## $indices
##  [1] 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135
## [20] 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154
## [39] 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170
## 
## $mass
## [1] 0.9528232
## 
## $height
## [1] 0.004448336</code></pre>
<p>To walk that through a bit, <code>prob_density_vec</code> is a vector of density values for <span class="math inline">\(\operatorname{beta} (30, 12)\)</span> based on 201 evenly-spaced values spanning the parameter space for <span class="math inline">\(\theta\)</span> (i.e., from 0 to 1). In the second line, we converted those density values to the probability metric by dividing each by their sum, which we then saved as <code>prob_mass_vec</code>. In the third line we shoved those probability values into Kruschke’s <code>HDIofGrid()</code> and saved the results as <code>HDI_info</code>. The output of the fourth line, <code>show(HDI_info)</code>, showed us the results (i.e., the contents of <code>HDI_info</code>).</p>
<p>As to those results, the values in saved as <code>$indices</code> are the row numbers for all cases in <code>prob_mass_vec</code> that were within the HDI. The value in <code>$mass</code> showed the actual width of the HDI. Because we’re only working with finite samples (i.e., <code>length = 201</code>), we won’t likely get a perfect 95% HDI. The value in <code>$height</code> is the density value for <em>the waterline that defines the highest density region</em>. A plot might make that less abstract.</p>
<div class="sourceCode" id="cb2304"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2304-1" data-line-number="1"><span class="co"># wrangle</span></a>
<a class="sourceLine" id="cb2304-2" data-line-number="2"><span class="kw">tibble</span>(<span class="dt">row     =</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(prob_density_vec),</a>
<a class="sourceLine" id="cb2304-3" data-line-number="3">       <span class="dt">theta   =</span> <span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">length =</span> <span class="kw">length</span>(prob_density_vec)),</a>
<a class="sourceLine" id="cb2304-4" data-line-number="4">       <span class="dt">density =</span> prob_mass_vec,</a>
<a class="sourceLine" id="cb2304-5" data-line-number="5">       <span class="dt">cred    =</span> <span class="kw">if_else</span>(row <span class="op">%in%</span><span class="st"> </span>HDI_info<span class="op">$</span>indices, <span class="dv">1</span>, <span class="dv">0</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb2304-6" data-line-number="6"><span class="st">  </span></a>
<a class="sourceLine" id="cb2304-7" data-line-number="7"><span class="st">  </span><span class="co"># plot</span></a>
<a class="sourceLine" id="cb2304-8" data-line-number="8"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> theta, <span class="dt">y =</span> density)) <span class="op">+</span></a>
<a class="sourceLine" id="cb2304-9" data-line-number="9"><span class="st">  </span><span class="co"># HDI</span></a>
<a class="sourceLine" id="cb2304-10" data-line-number="10"><span class="st">  </span><span class="kw">geom_ribbon</span>(<span class="dt">data =</span> . <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb2304-11" data-line-number="11"><span class="st">                </span><span class="kw">filter</span>(cred <span class="op">==</span><span class="st"> </span><span class="dv">1</span>),</a>
<a class="sourceLine" id="cb2304-12" data-line-number="12">              <span class="kw">aes</span>(<span class="dt">ymin =</span> <span class="dv">0</span>, <span class="dt">ymax =</span> density),</a>
<a class="sourceLine" id="cb2304-13" data-line-number="13">              <span class="dt">fill =</span> <span class="st">&quot;grey50&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb2304-14" data-line-number="14"><span class="st">  </span><span class="co"># density line</span></a>
<a class="sourceLine" id="cb2304-15" data-line-number="15"><span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">color =</span> <span class="st">&quot;grey33&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb2304-16" data-line-number="16"><span class="st">  </span><span class="co"># waterline</span></a>
<a class="sourceLine" id="cb2304-17" data-line-number="17"><span class="st">  </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> HDI_info<span class="op">$</span>height, <span class="dt">linetype =</span> <span class="dv">2</span>, <span class="dt">color =</span> <span class="st">&quot;skyblue&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb2304-18" data-line-number="18"><span class="st">  </span><span class="co"># fluff</span></a>
<a class="sourceLine" id="cb2304-19" data-line-number="19"><span class="st">  </span><span class="kw">annotate</span>(<span class="dt">geom =</span> <span class="st">&quot;text&quot;</span>, <span class="dt">x =</span> <span class="fl">.2</span>, <span class="dt">y =</span> <span class="fl">0.0046</span>,</a>
<a class="sourceLine" id="cb2304-20" data-line-number="20">           <span class="dt">label =</span> <span class="st">&#39;&quot;waterline&quot; that defines all points</span><span class="ch">\n</span><span class="st">inside the highest density region&#39;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb2304-21" data-line-number="21"><span class="st">  </span><span class="kw">annotate</span>(<span class="dt">geom =</span> <span class="st">&quot;text&quot;</span>, <span class="dt">x =</span> <span class="fl">.715</span>, <span class="dt">y =</span> <span class="fl">0.01</span>,</a>
<a class="sourceLine" id="cb2304-22" data-line-number="22">           <span class="dt">label =</span> <span class="st">&quot;95.28% HDI&quot;</span>, <span class="dt">color =</span> <span class="st">&quot;grey92&quot;</span>, <span class="dt">size =</span> <span class="dv">5</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb2304-23" data-line-number="23"><span class="st">  </span><span class="kw">xlab</span>(<span class="kw">expression</span>(theta)) <span class="op">+</span></a>
<a class="sourceLine" id="cb2304-24" data-line-number="24"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>())</a></code></pre></div>
<p><img src="25_files/figure-gfm/unnamed-chunk-9-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="hdi-of-unimodal-distribution-is-shortest-interval." class="section level3">
<h3><span class="header-section-number">25.2.2</span> HDI of unimodal distribution is shortest interval.</h3>
<blockquote>
<p>The algorithms [in the next sections] find the HDI by searching among candidate intervals of mass <span class="math inline">\(M\)</span>. The shortest one found is declared to be the HDI. It is an approximation, of course. See <span class="citation">Chen &amp; Shao (<a href="#ref-chenMonteCarloEstimation1999">1999</a>)</span> for more details, and Chen, He, Shao, and Xu <span class="citation">(<a href="#ref-chenMonteCarloGap2003">2003</a>)</span> for dealing with the unusual situation of multimodal distributions. (p. 727)</p>
</blockquote>
</div>
<div id="r-code-for-computing-hdi-of-a-mcmc-sample." class="section level3">
<h3><span class="header-section-number">25.2.3</span> R code for computing HDI of a MCMC sample.</h3>
<p>In this section, Kruschke provided the code for his <code>HDIofMCMC()</code> function. We recreate it, below, with a few mild formatting changes.</p>
<div class="sourceCode" id="cb2305"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2305-1" data-line-number="1">HDIofMCMC &lt;-<span class="st"> </span><span class="cf">function</span>(sampleVec, <span class="dt">credMass =</span> <span class="fl">.95</span>) {</a>
<a class="sourceLine" id="cb2305-2" data-line-number="2">  </a>
<a class="sourceLine" id="cb2305-3" data-line-number="3">  <span class="co"># Computes highest density interval from a sample of representative values,</span></a>
<a class="sourceLine" id="cb2305-4" data-line-number="4">  <span class="co">#   estimated as shortest credible interval.</span></a>
<a class="sourceLine" id="cb2305-5" data-line-number="5">  <span class="co"># Arguments:</span></a>
<a class="sourceLine" id="cb2305-6" data-line-number="6">  <span class="co">#   sampleVec</span></a>
<a class="sourceLine" id="cb2305-7" data-line-number="7">  <span class="co">#     is a vector of representative values from a probability distribution.</span></a>
<a class="sourceLine" id="cb2305-8" data-line-number="8">  <span class="co">#   credMass</span></a>
<a class="sourceLine" id="cb2305-9" data-line-number="9">  <span class="co">#     is a scalar between 0 and 1, indicating the mass within the credible</span></a>
<a class="sourceLine" id="cb2305-10" data-line-number="10">  <span class="co">#     interval that is to be estimated.</span></a>
<a class="sourceLine" id="cb2305-11" data-line-number="11">  <span class="co"># Value:</span></a>
<a class="sourceLine" id="cb2305-12" data-line-number="12">  <span class="co">#   HDIlim is a vector containing the limits of the HDI</span></a>
<a class="sourceLine" id="cb2305-13" data-line-number="13">  </a>
<a class="sourceLine" id="cb2305-14" data-line-number="14">  sortedPts &lt;-<span class="st"> </span><span class="kw">sort</span>(sampleVec)</a>
<a class="sourceLine" id="cb2305-15" data-line-number="15">  ciIdxInc &lt;-<span class="st"> </span><span class="kw">ceiling</span>(credMass <span class="op">*</span><span class="st"> </span><span class="kw">length</span>(sortedPts))</a>
<a class="sourceLine" id="cb2305-16" data-line-number="16">  nCIs &lt;-<span class="st"> </span><span class="kw">length</span>(sortedPts) <span class="op">-</span><span class="st"> </span>ciIdxInc</a>
<a class="sourceLine" id="cb2305-17" data-line-number="17">  ciWidth &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, nCIs)</a>
<a class="sourceLine" id="cb2305-18" data-line-number="18">  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>nCIs) {</a>
<a class="sourceLine" id="cb2305-19" data-line-number="19">    ciWidth[i] &lt;-<span class="st"> </span>sortedPts[i <span class="op">+</span><span class="st"> </span>ciIdxInc] <span class="op">-</span><span class="st"> </span>sortedPts[i]</a>
<a class="sourceLine" id="cb2305-20" data-line-number="20">  }</a>
<a class="sourceLine" id="cb2305-21" data-line-number="21">  HDImin &lt;-<span class="st"> </span>sortedPts[<span class="kw">which.min</span>(ciWidth)]</a>
<a class="sourceLine" id="cb2305-22" data-line-number="22">  HDImax &lt;-<span class="st"> </span>sortedPts[<span class="kw">which.min</span>(ciWidth) <span class="op">+</span><span class="st"> </span>ciIdxInc]</a>
<a class="sourceLine" id="cb2305-23" data-line-number="23">  HDIlim &lt;-<span class="st"> </span><span class="kw">c</span>(HDImin, HDImax)</a>
<a class="sourceLine" id="cb2305-24" data-line-number="24">  </a>
<a class="sourceLine" id="cb2305-25" data-line-number="25">  <span class="kw">return</span>(HDIlim)</a>
<a class="sourceLine" id="cb2305-26" data-line-number="26">  </a>
<a class="sourceLine" id="cb2305-27" data-line-number="27">}</a></code></pre></div>
<p>Let’s continue working with <code>fit24.1</code> to see how Kruschke’s <code>HDIofMCMC()</code> works. First we need to extract the posterior draws.</p>
<div class="sourceCode" id="cb2306"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2306-1" data-line-number="1">post &lt;-<span class="st"> </span><span class="kw">posterior_samples</span>(fit24<span class="fl">.1</span>)</a></code></pre></div>
<p>Here’s how you might use the function to get the HDIs for the first hierarchical variance parameter.</p>
<div class="sourceCode" id="cb2307"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2307-1" data-line-number="1"><span class="kw">HDIofMCMC</span>(post<span class="op">$</span>sd_Eye__Intercept)</a></code></pre></div>
<pre><code>## [1] 0.07972936 5.02625928</code></pre>
<p>Kruschke’s <code>HDIofMCMC()</code> works very much the same as the summary functions from <strong>tidybayes</strong>. For example, here’s good old <code>tidybayes::mode_hdi()</code>.</p>
<div class="sourceCode" id="cb2309"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2309-1" data-line-number="1"><span class="kw">library</span>(tidybayes)</a>
<a class="sourceLine" id="cb2309-2" data-line-number="2"></a>
<a class="sourceLine" id="cb2309-3" data-line-number="3"><span class="kw">mode_hdi</span>(post<span class="op">$</span>sd_Eye__Intercept)</a></code></pre></div>
<pre><code>##           y       ymin     ymax .width .point .interval
## 1 0.8320875 0.07972936 5.026259   0.95   mode       hdi</code></pre>
<p>If you’d like to use <strong>tidybayes</strong> to just pull the HDIs without the extra information, just use the <code>hdi()</code> function.</p>
<div class="sourceCode" id="cb2311"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2311-1" data-line-number="1"><span class="kw">hdi</span>(post<span class="op">$</span>sd_Eye__Intercept)</a></code></pre></div>
<pre><code>##            [,1]     [,2]
## [1,] 0.07972936 5.026259</code></pre>
<p>Just in case you’re curious, Kruschke’s <code>HDIofMCMC()</code> function returns the same information as <code>tidybayes::hdi()</code>. Let’s confirm.</p>
<div class="sourceCode" id="cb2313"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2313-1" data-line-number="1"><span class="kw">HDIofMCMC</span>(post<span class="op">$</span>sd_Eye__Intercept) <span class="op">==</span><span class="st"> </span><span class="kw">hdi</span>(post<span class="op">$</span>sd_Eye__Intercept)</a></code></pre></div>
<pre><code>##      [,1] [,2]
## [1,] TRUE TRUE</code></pre>
<p>Identical.</p>
</div>
<div id="r-code-for-computing-hdi-of-a-function." class="section level3">
<h3><span class="header-section-number">25.2.4</span> R code for computing HDI of a function.</h3>
<blockquote>
<p>The function described in this section finds the HDI of a unimodal probability density function that is specified mathematically in R. For example, the function can find HDI’s of normal densities or of beta densities or of gamma densities, because those densities are specified as functions in R. (p. 728).</p>
</blockquote>
<p>If you recall, we’ve been using this funciton off and on since Chapter 4. Here is it, again, with mildly reformated code and parameter names.</p>
<div class="sourceCode" id="cb2315"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2315-1" data-line-number="1">hdi_of_icdf &lt;-<span class="st"> </span><span class="cf">function</span>(name, <span class="dt">width =</span> <span class="fl">.95</span>, <span class="dt">tol =</span> <span class="fl">1e-8</span>, ... ) {</a>
<a class="sourceLine" id="cb2315-2" data-line-number="2">  </a>
<a class="sourceLine" id="cb2315-3" data-line-number="3">  <span class="co"># Arguments:</span></a>
<a class="sourceLine" id="cb2315-4" data-line-number="4">  <span class="co">#   `name` is R&#39;s name for the inverse cumulative density function</span></a>
<a class="sourceLine" id="cb2315-5" data-line-number="5">  <span class="co">#   of the distribution.</span></a>
<a class="sourceLine" id="cb2315-6" data-line-number="6">  <span class="co">#   `width` is the desired mass of the HDI region.</span></a>
<a class="sourceLine" id="cb2315-7" data-line-number="7">  <span class="co">#   `tol` is passed to R&#39;s optimize function.</span></a>
<a class="sourceLine" id="cb2315-8" data-line-number="8">  <span class="co"># Return value:</span></a>
<a class="sourceLine" id="cb2315-9" data-line-number="9">  <span class="co">#   Highest density iterval (HDI) limits in a vector.</span></a>
<a class="sourceLine" id="cb2315-10" data-line-number="10">  <span class="co"># Example of use: For determining HDI of a beta(30, 12) distribution, type</span></a>
<a class="sourceLine" id="cb2315-11" data-line-number="11">  <span class="co">#   `hdi_of_icdf(qbeta, shape1 = 30, shape2 = 12)`</span></a>
<a class="sourceLine" id="cb2315-12" data-line-number="12">  <span class="co">#   Notice that the parameters of the `name` must be explicitly stated;</span></a>
<a class="sourceLine" id="cb2315-13" data-line-number="13">  <span class="co">#   e.g., `hdi_of_icdf(qbeta, 30, 12)` does not work.</span></a>
<a class="sourceLine" id="cb2315-14" data-line-number="14">  <span class="co"># Adapted and corrected from Greg Snow&#39;s TeachingDemos package.</span></a>
<a class="sourceLine" id="cb2315-15" data-line-number="15">  </a>
<a class="sourceLine" id="cb2315-16" data-line-number="16">  incredible_mass &lt;-<span class="st">  </span><span class="fl">1.0</span> <span class="op">-</span><span class="st"> </span>width</a>
<a class="sourceLine" id="cb2315-17" data-line-number="17">  interval_width &lt;-<span class="st"> </span><span class="cf">function</span>(low_tail_prob, name, width, ...) {</a>
<a class="sourceLine" id="cb2315-18" data-line-number="18">    <span class="kw">name</span>(width <span class="op">+</span><span class="st"> </span>low_tail_prob, ...) <span class="op">-</span><span class="st"> </span><span class="kw">name</span>(low_tail_prob, ...)</a>
<a class="sourceLine" id="cb2315-19" data-line-number="19">  }</a>
<a class="sourceLine" id="cb2315-20" data-line-number="20">  opt_info &lt;-<span class="st"> </span><span class="kw">optimize</span>(interval_width, <span class="kw">c</span>(<span class="dv">0</span>, incredible_mass), </a>
<a class="sourceLine" id="cb2315-21" data-line-number="21">                       <span class="dt">name =</span> name, <span class="dt">width =</span> width, </a>
<a class="sourceLine" id="cb2315-22" data-line-number="22">                       <span class="dt">tol =</span> tol, ...)</a>
<a class="sourceLine" id="cb2315-23" data-line-number="23">  hdi_lower_tail_prob &lt;-<span class="st"> </span>opt_info<span class="op">$</span>minimum</a>
<a class="sourceLine" id="cb2315-24" data-line-number="24">  </a>
<a class="sourceLine" id="cb2315-25" data-line-number="25">  <span class="kw">return</span>(<span class="kw">c</span>(<span class="kw">name</span>(hdi_lower_tail_prob, ...),</a>
<a class="sourceLine" id="cb2315-26" data-line-number="26">           <span class="kw">name</span>(width <span class="op">+</span><span class="st"> </span>hdi_lower_tail_prob, ...)))</a>
<a class="sourceLine" id="cb2315-27" data-line-number="27">  </a>
<a class="sourceLine" id="cb2315-28" data-line-number="28">}</a></code></pre></div>
<p>Here’s how it works for the standard normal distribution.</p>
<div class="sourceCode" id="cb2316"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2316-1" data-line-number="1"><span class="kw">hdi_of_icdf</span>(qnorm, <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd =</span> <span class="dv">1</span>)</a></code></pre></div>
<pre><code>## [1] -1.959964  1.959964</code></pre>
<p>By default, it returns 95% HDIs. Here’s how it’d work if you wanted the 80% intervals for <span class="math inline">\(\operatorname{beta}(2, 2)\)</span>.</p>
<div class="sourceCode" id="cb2318"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2318-1" data-line-number="1"><span class="kw">hdi_of_icdf</span>(qbeta, <span class="dt">shape1 =</span> <span class="dv">2</span>, <span class="dt">shape2 =</span> <span class="dv">2</span>, <span class="dt">width =</span> <span class="fl">.8</span>)</a></code></pre></div>
<pre><code>## [1] 0.1958001 0.8041999</code></pre>
</div>
</div>
<div id="reparameterization" class="section level2">
<h2><span class="header-section-number">25.3</span> Reparameterization</h2>
<blockquote>
<p>There are situations in which one parameterization is intuitive to express a distribution, but a different parameterization is required for mathematical convenience. For example, we may think intuitively of the standard deviation of a normal distribution, but have to parameterize the distribution in terms of the precision (i.e., reciprocal of the variance). (p. 729)</p>
</blockquote>
<p>The details in the rest of this section are beyond the scope of this project.</p>
</div>
<div id="censored-data-in-jags-brms" class="section level2">
<h2><span class="header-section-number">25.4</span> Censored Data in <del>JAGS</del> brms</h2>
<p>“In many situations some data are censored, which means that their values are known only within a certain range” (p. 732) Happily, <strong>brms</strong> is capable of handling censored variables. The setup is a little different from how Kruschke described for JAGS. From the <code>brmsformula</code> section of the <a href="https://CRAN.R-project.org/package=brms/brms.pdf"><strong>brms</strong> reference manual</a> <span class="citation">(Bürkner, <a href="#ref-brms2020RM">2020</a><a href="#ref-brms2020RM">g</a>)</span>, we read:</p>
<blockquote>
<p>With the exception of categorical, ordinal, and mixture families, left, right, and interval censoring can be modeled through <code>y | cens(censored) ~ predictors</code>. The censoring variable (named <code>censored</code> in this example) should contain the values <code>'left'</code>, <code>'none'</code>, <code>'right'</code>, and <code>'interval'</code> (or equivalently <code>-1</code>, <code>0</code>, <code>1</code>, and <code>2</code>) to indicate that the corresponding observation is left censored, not censored, right censored, or interval censored. For interval censored data, a second variable (let’s call it <code>y2</code>) has to be passed to <code>cens</code>. In this case, the formula has the structure <code>y | cens(censored,y2) ~ predictors</code>. While the lower bounds are given in <code>y</code>, the upper bounds are given in <code>y2</code> for interval censored data. Intervals are assumed to be open on the left and closed on the right: <code>(y,y2]</code>.</p>
</blockquote>
<p>We’ll make sense of all this in just a moment. First, let’s see how Kruschke described the example in the text.</p>
<blockquote>
<p>To illustrate why it is important to include censored data in the analysis, consider a case in which <span class="math inline">\(N = 500\)</span> values are generated randomly from a normal distribution with <span class="math inline">\(\mu = 100\)</span> and <span class="math inline">\(\sigma = 15\)</span>. Suppose that values above 106 are censored, as are values in the interval between 94 and 100. For the censored values, all we know is the interval in which they occurred, but not their exact value. (p. 732)</p>
</blockquote>
<p>I’m now aware that we have access to Kruschke’s censored data, so we’ll just make our own based on his description. We’ll start off by simulating the idealized uncensored data, <code>y</code>, based on <span class="math inline">\(\operatorname{Normal} (100, 15)\)</span>.</p>
<div class="sourceCode" id="cb2320"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2320-1" data-line-number="1">n &lt;-<span class="st"> </span><span class="dv">500</span></a>
<a class="sourceLine" id="cb2320-2" data-line-number="2"></a>
<a class="sourceLine" id="cb2320-3" data-line-number="3"><span class="kw">set.seed</span>(<span class="dv">25</span>)</a>
<a class="sourceLine" id="cb2320-4" data-line-number="4"></a>
<a class="sourceLine" id="cb2320-5" data-line-number="5">d &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">y =</span> <span class="kw">rnorm</span>(n, <span class="dt">mean =</span> <span class="dv">100</span>, <span class="dt">sd =</span> <span class="dv">15</span>))</a></code></pre></div>
<p>To repeat, Kruschke described two kinds of censoring:</p>
<ul>
<li>“values above 106 are censored”,</li>
<li>“as are values in the interval between 94 and 100.”</li>
</ul>
<p>This leaves us with three thresholds. For simplicity, we’ll just name them <code>t1</code>, <code>t2</code> and <code>t3</code>, with their order based on their numeric values.</p>
<div class="sourceCode" id="cb2321"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2321-1" data-line-number="1">t1 &lt;-<span class="st">  </span><span class="dv">94</span></a>
<a class="sourceLine" id="cb2321-2" data-line-number="2">t2 &lt;-<span class="st"> </span><span class="dv">100</span></a>
<a class="sourceLine" id="cb2321-3" data-line-number="3">t3 &lt;-<span class="st"> </span><span class="dv">106</span></a></code></pre></div>
<p>In the last sentence in the block quote from the <strong>brms</strong> reference manual, we learned “intervals are assumed to be open on the left and closed on the right: <code>(y,y2]</code>.” It’s a little unclear, to me, if this is how Kruschke defined his intervals, but since we’re working with <strong>brms</strong> we’ll just use this convention. Thus, we will define “values in the interval between 94 and 100” as <code>y &gt;= t1 &amp; y &lt; t2</code>. We will define “values above 106” as <code>y &gt; t3</code>.</p>
<div class="sourceCode" id="cb2322"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2322-1" data-line-number="1">d &lt;-</a>
<a class="sourceLine" id="cb2322-2" data-line-number="2"><span class="st">  </span>d <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb2322-3" data-line-number="3"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">y1  =</span> <span class="kw">if_else</span>(y <span class="op">&gt;=</span><span class="st"> </span>t1 <span class="op">&amp;</span><span class="st"> </span>y <span class="op">&lt;</span><span class="st"> </span>t2, t1,</a>
<a class="sourceLine" id="cb2322-4" data-line-number="4">                       <span class="kw">if_else</span>(y <span class="op">&gt;</span><span class="st"> </span>t3, t3, y)),</a>
<a class="sourceLine" id="cb2322-5" data-line-number="5">         <span class="dt">y2  =</span> <span class="kw">if_else</span>(y <span class="op">&gt;=</span><span class="st"> </span>t1 <span class="op">&amp;</span><span class="st"> </span>y <span class="op">&lt;</span><span class="st"> </span>t2, t2, y),</a>
<a class="sourceLine" id="cb2322-6" data-line-number="6">         <span class="dt">cen =</span> <span class="kw">if_else</span>(y <span class="op">&gt;=</span><span class="st"> </span>t1 <span class="op">&amp;</span><span class="st"> </span>y <span class="op">&lt;</span><span class="st"> </span>t2, <span class="st">&quot;interval&quot;</span>,</a>
<a class="sourceLine" id="cb2322-7" data-line-number="7">                       <span class="kw">if_else</span>(y <span class="op">&gt;</span><span class="st"> </span>t3, <span class="st">&quot;right&quot;</span>, <span class="st">&quot;none&quot;</span>)))</a>
<a class="sourceLine" id="cb2322-8" data-line-number="8"></a>
<a class="sourceLine" id="cb2322-9" data-line-number="9">d</a></code></pre></div>
<pre><code>## # A tibble: 500 x 4
##        y    y1    y2 cen     
##    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;   
##  1  96.8  94   100   interval
##  2  84.4  84.4  84.4 none    
##  3  82.7  82.7  82.7 none    
##  4 105.  105.  105.  none    
##  5  77.5  77.5  77.5 none    
##  6  93.3  93.3  93.3 none    
##  7 126.  106   126.  right   
##  8 108.  106   108.  right   
##  9 101.  101.  101.  none    
## 10  99.1  94   100   interval
## # … with 490 more rows</code></pre>
<p>First look at the new <code>cen</code> column. When the values in <code>y</code> are not censored, we see <code>&quot;none&quot;</code>. Otherwise, <code>cen</code> indicates if they are right censored (i.e., <code>&quot;right&quot;</code>) or interval censored (i.e., <code>&quot;interval&quot;</code>). We used those exact terms based on the block quote from the <strong>brms</strong> reference manual. Now look at <code>y1</code>. When <code>cen == &quot;interval&quot;</code>, those values are the same as the original column <code>y</code>. The same goes for <code>y2</code>. Otherwise, the <code>y1</code> column contains the relevant lower thresholds values. That is, when <code>cen == &quot;interval&quot;</code>, we see the value for <code>t1</code> (i.e., 94). When <code>cen == &quot;right&quot;</code>, we see the value for <code>t3</code> (i.e., 106). For the interval-censored rows, the values in <code>y2</code> contain the values for the upper threshold (i.e., <code>t2</code>, which is 100). But when the rows are right censored, the values in <code>y2</code> are simply the same as the original <code>y</code> values. In the rows where <code>cen == &quot;right&quot;</code>, it really doesn’t matter what values you put in the <code>y2</code> column as long as they aren’t <code>NA</code>. This is because <strong>brms</strong> will only reference them for rows in which <code>cen == &quot;interval&quot;</code>.</p>
<p>I would not spend any time trying to equate this with Kruschke’s exposition at the top of page 734. This is a different coding method from what you might use for JAGS. Let’s make one more data change. Here we’ll make a new variable, <code>y_na</code>, that only has values for which <code>cen == &quot;none&quot;</code>.</p>
<div class="sourceCode" id="cb2324"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2324-1" data-line-number="1">d &lt;-</a>
<a class="sourceLine" id="cb2324-2" data-line-number="2"><span class="st">  </span>d <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb2324-3" data-line-number="3"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">y_na  =</span> <span class="kw">ifelse</span>(cen <span class="op">==</span><span class="st"> &quot;none&quot;</span>, y, <span class="ot">NA</span>))</a>
<a class="sourceLine" id="cb2324-4" data-line-number="4"></a>
<a class="sourceLine" id="cb2324-5" data-line-number="5">d</a></code></pre></div>
<pre><code>## # A tibble: 500 x 5
##        y    y1    y2 cen       y_na
##    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;
##  1  96.8  94   100   interval  NA  
##  2  84.4  84.4  84.4 none      84.4
##  3  82.7  82.7  82.7 none      82.7
##  4 105.  105.  105.  none     105. 
##  5  77.5  77.5  77.5 none      77.5
##  6  93.3  93.3  93.3 none      93.3
##  7 126.  106   126.  right     NA  
##  8 108.  106   108.  right     NA  
##  9 101.  101.  101.  none     101. 
## 10  99.1  94   100   interval  NA  
## # … with 490 more rows</code></pre>
<p>In the text, Kruschke reported he had 255 uncensored values (p. 732). Here’s the breakdown of our data.</p>
<div class="sourceCode" id="cb2326"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2326-1" data-line-number="1">d <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb2326-2" data-line-number="2"><span class="st">  </span><span class="kw">count</span>(cen)</a></code></pre></div>
<pre><code>## # A tibble: 3 x 2
##   cen          n
##   &lt;chr&gt;    &lt;int&gt;
## 1 interval    76
## 2 none       257
## 3 right      167</code></pre>
<p>We got really close! Let’s look at what we’ve done with a couple histograms.</p>
<div class="sourceCode" id="cb2328"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2328-1" data-line-number="1">d <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb2328-2" data-line-number="2"><span class="st">  </span><span class="kw">pivot_longer</span>(<span class="kw">c</span>(y, y_na)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb2328-3" data-line-number="3"><span class="st">  </span></a>
<a class="sourceLine" id="cb2328-4" data-line-number="4"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> value)) <span class="op">+</span></a>
<a class="sourceLine" id="cb2328-5" data-line-number="5"><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">size =</span> <span class="fl">.25</span>, <span class="dt">binwidth =</span> <span class="fl">2.5</span>, <span class="dt">fill =</span> <span class="st">&quot;grey67&quot;</span>, <span class="dt">color =</span> <span class="st">&quot;grey92&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb2328-6" data-line-number="6"><span class="st">  </span><span class="kw">xlab</span>(<span class="ot">NULL</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb2328-7" data-line-number="7"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>()) <span class="op">+</span></a>
<a class="sourceLine" id="cb2328-8" data-line-number="8"><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>name, <span class="dt">ncol =</span> <span class="dv">2</span>)</a></code></pre></div>
<p><img src="25_files/figure-gfm/unnamed-chunk-24-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>Here’s how to fit the first model, which only uses the uncensored values.</p>
<div class="sourceCode" id="cb2329"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2329-1" data-line-number="1"><span class="co"># define the stanvars</span></a>
<a class="sourceLine" id="cb2329-2" data-line-number="2">mean_y &lt;-<span class="st"> </span><span class="kw">mean</span>(d<span class="op">$</span>y_na, <span class="dt">na.rm =</span> T)</a>
<a class="sourceLine" id="cb2329-3" data-line-number="3">sd_y   &lt;-<span class="st"> </span><span class="kw">sd</span>(d<span class="op">$</span>y_na, <span class="dt">na.rm =</span> T)</a>
<a class="sourceLine" id="cb2329-4" data-line-number="4"></a>
<a class="sourceLine" id="cb2329-5" data-line-number="5">stanvars &lt;-<span class="st"> </span></a>
<a class="sourceLine" id="cb2329-6" data-line-number="6"><span class="st">  </span><span class="kw">stanvar</span>(mean_y, <span class="dt">name =</span> <span class="st">&quot;mean_y&quot;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb2329-7" data-line-number="7"><span class="st">  </span><span class="kw">stanvar</span>(sd_y,   <span class="dt">name =</span> <span class="st">&quot;sd_y&quot;</span>)</a>
<a class="sourceLine" id="cb2329-8" data-line-number="8"></a>
<a class="sourceLine" id="cb2329-9" data-line-number="9"><span class="co"># fit the model</span></a>
<a class="sourceLine" id="cb2329-10" data-line-number="10">fit25<span class="fl">.1</span> &lt;-</a>
<a class="sourceLine" id="cb2329-11" data-line-number="11"><span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> d,</a>
<a class="sourceLine" id="cb2329-12" data-line-number="12">      <span class="dt">family =</span> gaussian,</a>
<a class="sourceLine" id="cb2329-13" data-line-number="13">      y_na <span class="op">~</span><span class="st"> </span><span class="dv">1</span>,</a>
<a class="sourceLine" id="cb2329-14" data-line-number="14">      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(mean_y, sd_y <span class="op">*</span><span class="st"> </span><span class="dv">100</span>), <span class="dt">class =</span> Intercept),</a>
<a class="sourceLine" id="cb2329-15" data-line-number="15">                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, sd_y), <span class="dt">class =</span> sigma)),</a>
<a class="sourceLine" id="cb2329-16" data-line-number="16">      <span class="dt">chains =</span> <span class="dv">4</span>, <span class="dt">cores =</span> <span class="dv">4</span>,</a>
<a class="sourceLine" id="cb2329-17" data-line-number="17">      <span class="dt">stanvars =</span> stanvars, </a>
<a class="sourceLine" id="cb2329-18" data-line-number="18">      <span class="dt">file =</span> <span class="st">&quot;fits/fit25.01.rds&quot;</span>)</a></code></pre></div>
<p>Check the summary for the naïve model.</p>
<div class="sourceCode" id="cb2330"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2330-1" data-line-number="1"><span class="kw">print</span>(fit25<span class="fl">.1</span>)</a></code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: y_na ~ 1 
##    Data: d (Number of observations: 257) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept    89.87      0.64    88.62    91.14 1.00     2840     2566
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma    10.14      0.45     9.30    11.07 1.00     3860     2727
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>Relative to the true data-generating process for the original variable <code>y</code>, those parameters look pretty biased. Now let’s practice fitting censored model.</p>
<p>This model is one of the rare occasions where we’ll set out initial values for the model intercept. In my first few attempts, <code>brm()</code> had great difficulty initializing the chains using the default initial values. We’ll help it out by setting them at <code>mean_y</code>. Recall that when you set custom initial values in <strong>brms</strong>, you save them in a list with the number of lists equaling the number of HMC chains. Because we’re using the default <code>chains = 4</code>, well need four lists of intercept start values, <code>mean_y</code>. You can set them to different values, if you’d like.</p>
<div class="sourceCode" id="cb2332"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2332-1" data-line-number="1">inits &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">Intercept =</span> mean_y)</a>
<a class="sourceLine" id="cb2332-2" data-line-number="2"></a>
<a class="sourceLine" id="cb2332-3" data-line-number="3">inits_list &lt;-<span class="st"> </span><span class="kw">list</span>(inits, inits, inits, inits)</a>
<a class="sourceLine" id="cb2332-4" data-line-number="4"></a>
<a class="sourceLine" id="cb2332-5" data-line-number="5">fit25<span class="fl">.2</span> &lt;-</a>
<a class="sourceLine" id="cb2332-6" data-line-number="6"><span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> d,</a>
<a class="sourceLine" id="cb2332-7" data-line-number="7">      <span class="dt">family =</span> gaussian,</a>
<a class="sourceLine" id="cb2332-8" data-line-number="8">      y1 <span class="op">|</span><span class="st"> </span><span class="kw">cens</span>(cen, y2) <span class="op">~</span><span class="st"> </span><span class="dv">1</span>,</a>
<a class="sourceLine" id="cb2332-9" data-line-number="9">      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(mean_y, sd_y <span class="op">*</span><span class="st"> </span><span class="dv">100</span>), <span class="dt">class =</span> Intercept),</a>
<a class="sourceLine" id="cb2332-10" data-line-number="10">                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, sd_y), <span class="dt">class =</span> sigma)),</a>
<a class="sourceLine" id="cb2332-11" data-line-number="11">      <span class="dt">chains =</span> <span class="dv">4</span>, <span class="dt">cores =</span> <span class="dv">4</span>,</a>
<a class="sourceLine" id="cb2332-12" data-line-number="12">      <span class="dt">stanvars =</span> stanvars, </a>
<a class="sourceLine" id="cb2332-13" data-line-number="13">      <span class="dt">inits =</span> inits_list,  <span class="co"># here we insert our start values for the intercept</span></a>
<a class="sourceLine" id="cb2332-14" data-line-number="14">      <span class="dt">file =</span> <span class="st">&quot;fits/fit25.02.rds&quot;</span>)</a></code></pre></div>
<p>Now check the summary for the model accounting for the censoring.</p>
<div class="sourceCode" id="cb2333"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2333-1" data-line-number="1"><span class="kw">print</span>(fit25<span class="fl">.2</span>)</a></code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: y1 | cens(cen, y2) ~ 1 
##    Data: d (Number of observations: 500) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept    99.46      0.73    98.04   100.90 1.00     2392     2387
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma    14.29      0.60    13.18    15.53 1.00     2411     2049
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>All 500 cases were used (<code>Number of observations: 500</code>) and the model did a great job capturing the data-generating parameters. Before we can make our version of Figure 25.4, we’ll need to extract the posterior draws. We’ll start with <code>fit25.1</code>.</p>
<div class="sourceCode" id="cb2335"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2335-1" data-line-number="1">post &lt;-<span class="st"> </span></a>
<a class="sourceLine" id="cb2335-2" data-line-number="2"><span class="st">  </span><span class="kw">posterior_samples</span>(fit25<span class="fl">.1</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb2335-3" data-line-number="3"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">mu =</span> b_Intercept,</a>
<a class="sourceLine" id="cb2335-4" data-line-number="4">         <span class="st">`</span><span class="dt">(mu-100)/sigma</span><span class="st">`</span> =<span class="st"> </span>(b_Intercept <span class="op">-</span><span class="st"> </span><span class="dv">100</span>) <span class="op">/</span><span class="st"> </span>sigma)</a>
<a class="sourceLine" id="cb2335-5" data-line-number="5"></a>
<a class="sourceLine" id="cb2335-6" data-line-number="6"><span class="kw">head</span>(post)</a></code></pre></div>
<pre><code>##   b_Intercept     sigma      lp__       mu (mu-100)/sigma
## 1    89.01128 10.902672 -969.3481 89.01128     -1.0078924
## 2    89.78891  9.650831 -967.5287 89.78891     -1.0580531
## 3    89.96439  9.786381 -967.2537 89.96439     -1.0254674
## 4    90.20543  9.740210 -967.4664 90.20543     -1.0055812
## 5    90.07634 10.064154 -967.0646 90.07634     -0.9860402
## 6    90.43041  9.762487 -967.6899 90.43041     -0.9802415</code></pre>
<p>These subplots look a lot like those from back in Section 16.2. Since this is the last plot of the book, it seems like we should make the effort to stitch all the subplots together with <strong>patchwork</strong>. To reduce some of the code redundancy with the six subplots of the marginal posteriors, we’ll make a custom geom, <code>geom_hist()</code>.</p>
<div class="sourceCode" id="cb2337"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2337-1" data-line-number="1">geom_hist &lt;-<span class="st"> </span><span class="cf">function</span>(<span class="dt">xintercept =</span> xintercept, <span class="dt">binwidth =</span> binwidth, ...) {</a>
<a class="sourceLine" id="cb2337-2" data-line-number="2">  </a>
<a class="sourceLine" id="cb2337-3" data-line-number="3">  <span class="kw">list</span>(</a>
<a class="sourceLine" id="cb2337-4" data-line-number="4">    <span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> xintercept, <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>, <span class="dt">size =</span> <span class="dv">1</span>),</a>
<a class="sourceLine" id="cb2337-5" data-line-number="5">    <span class="kw">geom_histogram</span>(<span class="dt">fill =</span> <span class="st">&quot;grey67&quot;</span>, <span class="dt">color =</span> <span class="st">&quot;grey92&quot;</span>, <span class="dt">size =</span> <span class="fl">.2</span>, <span class="dt">binwidth =</span> binwidth),</a>
<a class="sourceLine" id="cb2337-6" data-line-number="6">    <span class="kw">stat_pointintervalh</span>(<span class="kw">aes</span>(<span class="dt">y =</span> <span class="dv">0</span>), <span class="dt">point_interval =</span> mode_hdi, <span class="dt">.width =</span> <span class="fl">.95</span>),</a>
<a class="sourceLine" id="cb2337-7" data-line-number="7">    <span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>),</a>
<a class="sourceLine" id="cb2337-8" data-line-number="8">    <span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>())</a>
<a class="sourceLine" id="cb2337-9" data-line-number="9">  )</a>
<a class="sourceLine" id="cb2337-10" data-line-number="10">  </a>
<a class="sourceLine" id="cb2337-11" data-line-number="11">}</a></code></pre></div>
<p>Now we have our <code>geom_hist()</code>, here are the first three histograms for the marginal posteriors from <code>fit25.1</code>.</p>
<div class="sourceCode" id="cb2338"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2338-1" data-line-number="1">p1 &lt;-</a>
<a class="sourceLine" id="cb2338-2" data-line-number="2"><span class="st">  </span>post <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb2338-3" data-line-number="3"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> mu)) <span class="op">+</span></a>
<a class="sourceLine" id="cb2338-4" data-line-number="4"><span class="st">  </span><span class="kw">geom_hist</span>(<span class="dt">xintercept =</span> <span class="dv">100</span>, <span class="dt">binwidth =</span> <span class="fl">0.25</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb2338-5" data-line-number="5"><span class="st">  </span><span class="kw">xlab</span>(<span class="kw">expression</span>(mu))</a>
<a class="sourceLine" id="cb2338-6" data-line-number="6"></a>
<a class="sourceLine" id="cb2338-7" data-line-number="7">p3 &lt;-</a>
<a class="sourceLine" id="cb2338-8" data-line-number="8"><span class="st">  </span>post <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb2338-9" data-line-number="9"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> sigma)) <span class="op">+</span></a>
<a class="sourceLine" id="cb2338-10" data-line-number="10"><span class="st">  </span><span class="kw">geom_hist</span>(<span class="dt">xintercept =</span> <span class="dv">15</span>, <span class="dt">binwidth =</span> <span class="fl">0.1</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb2338-11" data-line-number="11"><span class="st">  </span><span class="kw">xlab</span>(<span class="kw">expression</span>(sigma))</a>
<a class="sourceLine" id="cb2338-12" data-line-number="12"></a>
<a class="sourceLine" id="cb2338-13" data-line-number="13">p4 &lt;-</a>
<a class="sourceLine" id="cb2338-14" data-line-number="14"><span class="st">  </span>post <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb2338-15" data-line-number="15"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> <span class="st">`</span><span class="dt">(mu-100)/sigma</span><span class="st">`</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb2338-16" data-line-number="16"><span class="st">  </span><span class="kw">geom_hist</span>(<span class="dt">xintercept =</span> <span class="dv">0</span>, <span class="dt">binwidth =</span> <span class="fl">0.025</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb2338-17" data-line-number="17"><span class="st">  </span><span class="kw">xlab</span>(<span class="kw">expression</span>((mu<span class="dv">-100</span>)<span class="op">/</span>sigma))</a></code></pre></div>
<p>The histogram of the censored data with the posterior predictive density curves superimposed will take a little more work.</p>
<div class="sourceCode" id="cb2339"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2339-1" data-line-number="1">n_lines &lt;-<span class="st"> </span><span class="dv">50</span></a>
<a class="sourceLine" id="cb2339-2" data-line-number="2"></a>
<a class="sourceLine" id="cb2339-3" data-line-number="3">p2 &lt;-</a>
<a class="sourceLine" id="cb2339-4" data-line-number="4"><span class="st">  </span>post <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb2339-5" data-line-number="5"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">iter =</span> <span class="dv">1</span><span class="op">:</span><span class="kw">n</span>()) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb2339-6" data-line-number="6"><span class="st">  </span><span class="kw">slice</span>(<span class="dv">1</span><span class="op">:</span>n_lines) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb2339-7" data-line-number="7"><span class="st">  </span><span class="kw">expand</span>(<span class="kw">nesting</span>(mu, sigma, iter),</a>
<a class="sourceLine" id="cb2339-8" data-line-number="8">         <span class="dt">y_na =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">40</span>, <span class="dt">to =</span> <span class="dv">120</span>, <span class="dt">by =</span> <span class="dv">1</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb2339-9" data-line-number="9"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">density =</span> <span class="kw">dnorm</span>(<span class="dt">x =</span> y_na, <span class="dt">mean =</span> mu, <span class="dt">sd =</span> sigma)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb2339-10" data-line-number="10"><span class="st">  </span></a>
<a class="sourceLine" id="cb2339-11" data-line-number="11"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> y_na)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb2339-12" data-line-number="12"><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">data =</span> d, </a>
<a class="sourceLine" id="cb2339-13" data-line-number="13">                 <span class="kw">aes</span>(<span class="dt">y =</span> <span class="kw">stat</span>(density)),</a>
<a class="sourceLine" id="cb2339-14" data-line-number="14">                 <span class="dt">color =</span> <span class="st">&quot;grey92&quot;</span>, <span class="dt">fill =</span> <span class="st">&quot;grey67&quot;</span>,</a>
<a class="sourceLine" id="cb2339-15" data-line-number="15">                 <span class="dt">size =</span> <span class="fl">.2</span>, <span class="dt">binwidth =</span> <span class="fl">2.5</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb2339-16" data-line-number="16"><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y =</span> density, <span class="dt">group =</span> iter),</a>
<a class="sourceLine" id="cb2339-17" data-line-number="17">            <span class="dt">size  =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">4</span>, <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">3</span>, <span class="dt">color =</span> <span class="st">&quot;grey25&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb2339-18" data-line-number="18"><span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="st">&quot;data with posterior predictive lines&quot;</span>, <span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">40</span>, <span class="dv">110</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb2339-19" data-line-number="19"><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb2339-20" data-line-number="20"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>())</a></code></pre></div>
<p>Now extract the posterior draws from our censored model, <code>fit25.2</code>, and repeat the process.</p>
<div class="sourceCode" id="cb2340"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2340-1" data-line-number="1">post &lt;-<span class="st"> </span></a>
<a class="sourceLine" id="cb2340-2" data-line-number="2"><span class="st">  </span><span class="kw">posterior_samples</span>(fit25<span class="fl">.2</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb2340-3" data-line-number="3"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">mu =</span> b_Intercept,</a>
<a class="sourceLine" id="cb2340-4" data-line-number="4">         <span class="st">`</span><span class="dt">(mu-100)/sigma</span><span class="st">`</span> =<span class="st"> </span>(b_Intercept <span class="op">-</span><span class="st"> </span><span class="dv">100</span>) <span class="op">/</span><span class="st"> </span>sigma)</a>
<a class="sourceLine" id="cb2340-5" data-line-number="5"></a>
<a class="sourceLine" id="cb2340-6" data-line-number="6">p5 &lt;-</a>
<a class="sourceLine" id="cb2340-7" data-line-number="7"><span class="st">  </span>post <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb2340-8" data-line-number="8"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> mu)) <span class="op">+</span></a>
<a class="sourceLine" id="cb2340-9" data-line-number="9"><span class="st">  </span><span class="kw">geom_hist</span>(<span class="dt">xintercept =</span> <span class="dv">100</span>, <span class="dt">binwidth =</span> <span class="fl">0.15</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb2340-10" data-line-number="10"><span class="st">  </span><span class="kw">xlab</span>(<span class="kw">expression</span>(mu))</a>
<a class="sourceLine" id="cb2340-11" data-line-number="11"></a>
<a class="sourceLine" id="cb2340-12" data-line-number="12">p7 &lt;-</a>
<a class="sourceLine" id="cb2340-13" data-line-number="13"><span class="st">  </span>post <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb2340-14" data-line-number="14"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> sigma)) <span class="op">+</span></a>
<a class="sourceLine" id="cb2340-15" data-line-number="15"><span class="st">  </span><span class="kw">geom_hist</span>(<span class="dt">xintercept =</span> <span class="dv">15</span>, <span class="dt">binwidth =</span> <span class="fl">0.1</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb2340-16" data-line-number="16"><span class="st">  </span><span class="kw">xlab</span>(<span class="kw">expression</span>(sigma))</a>
<a class="sourceLine" id="cb2340-17" data-line-number="17"></a>
<a class="sourceLine" id="cb2340-18" data-line-number="18">p8 &lt;-</a>
<a class="sourceLine" id="cb2340-19" data-line-number="19"><span class="st">  </span>post <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb2340-20" data-line-number="20"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> <span class="st">`</span><span class="dt">(mu-100)/sigma</span><span class="st">`</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb2340-21" data-line-number="21"><span class="st">  </span><span class="kw">geom_hist</span>(<span class="dt">xintercept =</span> <span class="dv">0</span>, <span class="dt">binwidth =</span> <span class="fl">0.01</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb2340-22" data-line-number="22"><span class="st">  </span><span class="kw">xlab</span>(<span class="kw">expression</span>((mu<span class="dv">-100</span>)<span class="op">/</span>sigma))</a>
<a class="sourceLine" id="cb2340-23" data-line-number="23"></a>
<a class="sourceLine" id="cb2340-24" data-line-number="24">p6 &lt;-</a>
<a class="sourceLine" id="cb2340-25" data-line-number="25"><span class="st">  </span>post <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb2340-26" data-line-number="26"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">iter =</span> <span class="dv">1</span><span class="op">:</span><span class="kw">n</span>()) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb2340-27" data-line-number="27"><span class="st">  </span><span class="kw">slice</span>(<span class="dv">1</span><span class="op">:</span>n_lines) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb2340-28" data-line-number="28"><span class="st">  </span><span class="kw">expand</span>(<span class="kw">nesting</span>(mu, sigma, iter),</a>
<a class="sourceLine" id="cb2340-29" data-line-number="29">         <span class="dt">y_na =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">40</span>, <span class="dt">to =</span> <span class="dv">120</span>, <span class="dt">by =</span> <span class="dv">1</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb2340-30" data-line-number="30"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">density =</span> <span class="kw">dnorm</span>(<span class="dt">x =</span> y_na, <span class="dt">mean =</span> mu, <span class="dt">sd =</span> sigma)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb2340-31" data-line-number="31"><span class="st">  </span></a>
<a class="sourceLine" id="cb2340-32" data-line-number="32"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> y_na)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb2340-33" data-line-number="33"><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">data =</span> d, </a>
<a class="sourceLine" id="cb2340-34" data-line-number="34">                 <span class="kw">aes</span>(<span class="dt">y =</span> <span class="kw">stat</span>(density)),</a>
<a class="sourceLine" id="cb2340-35" data-line-number="35">                 <span class="dt">color =</span> <span class="st">&quot;grey92&quot;</span>, <span class="dt">fill =</span> <span class="st">&quot;grey67&quot;</span>,</a>
<a class="sourceLine" id="cb2340-36" data-line-number="36">                 <span class="dt">size =</span> <span class="fl">.2</span>, <span class="dt">binwidth =</span> <span class="fl">2.5</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb2340-37" data-line-number="37"><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y =</span> density, <span class="dt">group =</span> iter),</a>
<a class="sourceLine" id="cb2340-38" data-line-number="38">            <span class="dt">size  =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">4</span>, <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">3</span>, <span class="dt">color =</span> <span class="st">&quot;grey25&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb2340-39" data-line-number="39"><span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="st">&quot;data with posterior predictive lines&quot;</span>, <span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">40</span>, <span class="dv">110</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb2340-40" data-line-number="40"><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb2340-41" data-line-number="41"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>())</a></code></pre></div>
<p>Load <strong>patchwork</strong>, combine the subplots, and annotate a bit.</p>
<div class="sourceCode" id="cb2341"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2341-1" data-line-number="1"><span class="kw">library</span>(patchwork)</a>
<a class="sourceLine" id="cb2341-2" data-line-number="2"></a>
<a class="sourceLine" id="cb2341-3" data-line-number="3">((p1 <span class="op">|</span><span class="st"> </span>p2) <span class="op">/</span><span class="st"> </span>(p3 <span class="op">|</span><span class="st"> </span>p4) <span class="op">/</span><span class="st"> </span>(p5 <span class="op">|</span><span class="st"> </span>p6) <span class="op">/</span><span class="st"> </span>(p7 <span class="op">|</span><span class="st"> </span>p8)) <span class="op">+</span></a>
<a class="sourceLine" id="cb2341-4" data-line-number="4"><span class="st">  </span><span class="kw">plot_annotation</span>(<span class="dt">title =</span> <span class="st">&quot;This is our final plot, together.&quot;</span>,</a>
<a class="sourceLine" id="cb2341-5" data-line-number="5">                  <span class="dt">caption =</span> <span class="kw">expression</span>(<span class="kw">atop</span>(<span class="kw">italic</span>(<span class="st">&quot;Upper quartet&quot;</span>)<span class="op">*</span><span class="st">&quot;: Censored data omitted from analysis; parameter estimates are too small.  &quot;</span>, <span class="kw">italic</span>(<span class="st">&quot;Lower quartet&quot;</span>)<span class="op">*</span><span class="st">&quot;: Censored data imputed in known bins; parameter estimates are accurate.&quot;</span>))) <span class="op">&amp;</span></a>
<a class="sourceLine" id="cb2341-6" data-line-number="6"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">plot.caption =</span> <span class="kw">element_text</span>(<span class="dt">hjust =</span> <span class="dv">0</span>))</a></code></pre></div>
<p><img src="25_files/figure-gfm/unnamed-chunk-32-1.png" width="576" style="display: block; margin: auto;" /></p>
</div>
<div id="what-next" class="section level2">
<h2><span class="header-section-number">25.5</span> What Next?</h2>
<p>“If you have made it this far and you are looking for more, you might peruse posts at [Kruschke’s] blog, <a href="https://doingbayesiandataanalysis.blogspot.com/">[https://doingbayesiandataanalysis.blogspot.com/]</a>, and search there for topics that interest you.” In addition to the other references Kruschke mentioned, you might also check out McElreath’s <span class="citation">(<a href="#ref-mcelreathStatisticalRethinkingBayesian2015">2015</a>)</span> <a href="https://xcelab.net/rm/statistical-rethinking/"><em>Statistical rethinking</em></a>. The first edition came out in 2015 and the second was released sometime in early 2020. Much like this project, I have recoded <em>Statistical rethinking</em> in a <strong>bookdown</strong> form, <a href="https://bookdown.org/content/3890/">here</a> <span class="citation">(Kurz, <a href="#ref-kurzStatisticalRethinkingBrms2020">2020</a>)</span>. You can also find other tutorial material at my academic blog, <a href="https://solomonkurz.netlify.com/post/">https://solomonkurz.netlify.com/post/</a>.</p>
</div>
<div id="session-info-24" class="section level2 unnumbered">
<h2>Session info</h2>
<div class="sourceCode" id="cb2342"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2342-1" data-line-number="1"><span class="kw">sessionInfo</span>()</a></code></pre></div>
<pre><code>## R version 3.6.3 (2020-02-29)
## Platform: x86_64-apple-darwin15.6.0 (64-bit)
## Running under: macOS Catalina 10.15.3
## 
## Matrix products: default
## BLAS:   /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRblas.0.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] patchwork_1.0.0      tidybayes_2.0.3.9000 brms_2.12.0         
##  [4] Rcpp_1.0.4.6         forcats_0.5.0        stringr_1.4.0       
##  [7] dplyr_0.8.5          purrr_0.3.4          readr_1.3.1         
## [10] tidyr_1.0.2          tibble_3.0.1         ggplot2_3.3.0       
## [13] tidyverse_1.3.0     
## 
## loaded via a namespace (and not attached):
##   [1] colorspace_1.4-1     ellipsis_0.3.0       ggridges_0.5.2      
##   [4] rsconnect_0.8.16     markdown_1.1         base64enc_0.1-3     
##   [7] fs_1.4.1             rstudioapi_0.11      farver_2.0.3        
##  [10] rstan_2.19.3         svUnit_1.0.3         DT_0.13             
##  [13] fansi_0.4.1          mvtnorm_1.1-0        lubridate_1.7.8     
##  [16] xml2_1.3.1           bridgesampling_1.0-0 knitr_1.28          
##  [19] shinythemes_1.1.2    bayesplot_1.7.1      jsonlite_1.6.1      
##  [22] broom_0.5.5          dbplyr_1.4.2         shiny_1.4.0.2       
##  [25] compiler_3.6.3       httr_1.4.1           backports_1.1.6     
##  [28] assertthat_0.2.1     Matrix_1.2-18        fastmap_1.0.1       
##  [31] cli_2.0.2            later_1.0.0          htmltools_0.4.0     
##  [34] prettyunits_1.1.1    tools_3.6.3          igraph_1.2.5        
##  [37] coda_0.19-3          gtable_0.3.0         glue_1.4.0          
##  [40] reshape2_1.4.4       cellranger_1.1.0     vctrs_0.3.0         
##  [43] nlme_3.1-144         crosstalk_1.1.0.1    xfun_0.13           
##  [46] ps_1.3.3             rvest_0.3.5          mime_0.9            
##  [49] miniUI_0.1.1.1       lifecycle_0.2.0      gtools_3.8.2        
##  [52] zoo_1.8-7            scales_1.1.1         colourpicker_1.0    
##  [55] hms_0.5.3            promises_1.1.0       Brobdingnag_1.2-6   
##  [58] parallel_3.6.3       inline_0.3.15        shinystan_2.5.0     
##  [61] yaml_2.2.1           gridExtra_2.3        loo_2.2.0           
##  [64] StanHeaders_2.21.0-1 stringi_1.4.6        dygraphs_1.1.1.6    
##  [67] pkgbuild_1.0.8       rlang_0.4.6          pkgconfig_2.0.3     
##  [70] matrixStats_0.56.0   HDInterval_0.2.0     evaluate_0.14       
##  [73] lattice_0.20-38      rstantools_2.0.0     htmlwidgets_1.5.1   
##  [76] labeling_0.3         processx_3.4.2       tidyselect_1.0.0    
##  [79] plyr_1.8.6           magrittr_1.5         bookdown_0.18       
##  [82] R6_2.4.1             generics_0.0.2       DBI_1.1.0           
##  [85] pillar_1.4.4         haven_2.2.0          withr_2.2.0         
##  [88] xts_0.12-0           abind_1.4-5          modelr_0.1.6        
##  [91] crayon_1.3.4         arrayhelpers_1.1-0   utf8_1.1.4          
##  [94] rmarkdown_2.1        grid_3.6.3           readxl_1.3.1        
##  [97] callr_3.4.3          threejs_0.3.3        reprex_0.3.0        
## [100] digest_0.6.25        xtable_1.8-4         httpuv_1.5.2        
## [103] stats4_3.6.3         munsell_0.5.0        shinyjs_1.1</code></pre>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-aczelDiscussionPointsBayesian2020">
<p>Aczel, B., Hoekstra, R., Gelman, A., Wagenmakers, E.-J., Klugkist, I. G., Rouder, J. N., Vandekerckhove, J., Lee, M. D., Morey, R. D., Vanpaemel, W., Dienes, Z., &amp; van Ravenzwaaij, D. (2020). Discussion points for Bayesian inference. <em>Nature Human Behaviour</em>, 1–3. <a href="https://doi.org/10.1038/s41562-019-0807-z">https://doi.org/10.1038/s41562-019-0807-z</a></p>
</div>
<div id="ref-brms2020RM">
<p>Bürkner, P.-C. (2020g). <em>brms reference manual, Version 2.12.0</em>. <a href="https://CRAN.R-project.org/package=brms/brms.pdf">https://CRAN.R-project.org/package=brms/brms.pdf</a></p>
</div>
<div id="ref-chenMonteCarloGap2003">
<p>Chen, M.-H., He, X., Shao, Q.-M., &amp; Xu, H. (2003). A Monte Carlo gap test in computing HPD regions. In <em>Development of Modern Statistics and Related Topics: Vol. Volume 1</em> (pp. 38–52). World Scientific. <a href="https://doi.org/10.1142/9789812796707_0004">https://doi.org/10.1142/9789812796707_0004</a></p>
</div>
<div id="ref-chenMonteCarloEstimation1999">
<p>Chen, M.-H., &amp; Shao, Q.-M. (1999). Monte Carlo estimation of Bayesian credible and HPD intervals. <em>Journal of Computational and Graphical Statistics</em>, <em>8</em>(1), 69–92. <a href="https://doi.org/10.1080/10618600.1999.10474802">https://doi.org/10.1080/10618600.1999.10474802</a></p>
</div>
<div id="ref-gabry2019visualization">
<p>Gabry, J., Simpson, D., Vehtari, A., Betancourt, M., &amp; Gelman, A. (2019). Visualization in Bayesian workflow. <em>Journal of the Royal Statistical Society: Series A (Statistics in Society)</em>, <em>182</em>(2), 389–402. <a href="https://doi.org/10.1111/rssa.12378">https://doi.org/10.1111/rssa.12378</a></p>
</div>
<div id="ref-hyndmanComputingGraphingHighest1996">
<p>Hyndman, R. J. (1996). Computing and graphing highest density regions. <em>The American Statistician</em>, <em>50</em>(2), 120–126. <a href="https://doi.org/10.1080/00031305.1996.10474359">https://doi.org/10.1080/00031305.1996.10474359</a></p>
</div>
<div id="ref-kleinPracticalGuideTransparency2018">
<p>Klein, O., Hardwicke, T. E., Aust, F., Breuer, J., Danielsson, H., Hofelich Mohr, A., IJzerman, H., Nilsonne, G., Vanpaemel, W., &amp; Frank, M. C. (2018). A practical guide for transparency in psychological science. <em>Collabra: Psychology</em>, <em>4</em>(1), 1–15. <a href="https://doi.org/10.1525/collabra.158">https://doi.org/10.1525/collabra.158</a></p>
</div>
<div id="ref-kruschkePosteriorPredictiveChecks2013">
<p>Kruschke, J. K. (2013). Posterior predictive checks can and should be Bayesian: Comment on Gelman and Shalizi, “Philosophy and the practice of Bayesian statistics”. <em>British Journal of Mathematical and Statistical Psychology</em>, <em>66</em>(1), 45–56. <a href="https://doi.org/10.1111/j.2044-8317.2012.02063.x">https://doi.org/10.1111/j.2044-8317.2012.02063.x</a></p>
</div>
<div id="ref-kruschkeDoingBayesianData2015">
<p>Kruschke, J. K. (2015). <em>Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan</em>. Academic Press. <a href="https://sites.google.com/site/doingbayesiandataanalysis/">https://sites.google.com/site/doingbayesiandataanalysis/</a></p>
</div>
<div id="ref-kruschkeBayesianNewStatistics2018">
<p>Kruschke, J. K., &amp; Liddell, T. M. (2018). The Bayesian New Statistics: Hypothesis testing, estimation, meta-analysis, and power analysis from a Bayesian perspective. <em>Psychonomic Bulletin &amp; Review</em>, <em>25</em>(1), 178–206. <a href="https://doi.org/10.3758/s13423-016-1221-4">https://doi.org/10.3758/s13423-016-1221-4</a></p>
</div>
<div id="ref-kurzStatisticalRethinkingBrms2020">
<p>Kurz, A. S. (2020). <em>Statistical rethinking with brms, ggplot2, and the tidyverse</em>. <a href="https://doi.org/10.5281/zenodo.3693202.svg">https://doi.org/10.5281/zenodo.3693202.svg</a></p>
</div>
<div id="ref-martoneDataSharingPsychology2018">
<p>Martone, M. E., Garcia-Castro, A., &amp; VandenBos, G. R. (2018). Data sharing in psychology. <em>The American Psychologist</em>, <em>73</em>(2), 111–125. <a href="https://doi.org/10.1037/amp0000242">https://doi.org/10.1037/amp0000242</a></p>
</div>
<div id="ref-mcelreathStatisticalRethinkingBayesian2015">
<p>McElreath, R. (2015). <em>Statistical rethinking: A Bayesian course with examples in R and Stan</em>. CRC press. <a href="https://xcelab.net/rm/statistical-rethinking/">https://xcelab.net/rm/statistical-rethinking/</a></p>
</div>
<div id="ref-rouderWhatWhyHow2016">
<p>Rouder, J. N. (2016). The what, why, and how of born-open data. <em>Behavior Research Methods</em>, <em>48</em>(3), 1062–1069. <a href="https://doi.org/10.3758/s13428-015-0630-z">https://doi.org/10.3758/s13428-015-0630-z</a></p>
</div>
<div id="ref-xieMarkdownDefinitiveGuide2020">
<p>Xie, Y., Allaire, J. J., &amp; Grolemund, G. (2020). <em>R markdown: The definitive guide</em>. Chapman and Hall/CRC. <a href="https://bookdown.org/yihui/rmarkdown/">https://bookdown.org/yihui/rmarkdown/</a></p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="count-predicted-variable.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="references.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
